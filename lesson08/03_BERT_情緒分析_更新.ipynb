{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‰ª•TransformersÂ•ó‰ª∂ÈÄ≤Ë°åÊÉÖÁ∑íÂàÜÊûê(Sentiment analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\elsa\\anaconda3\\envs\\py12_0518\\lib\\site-packages (4.42.3)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.42.4-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.6 kB ? eta -:--:--\n",
      "     ----------------- -------------------- 20.5/43.6 kB 682.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 43.6/43.6 kB 428.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\elsa\\anaconda3\\envs\\py12_0518\\lib\\site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\elsa\\anaconda3\\envs\\py12_0518\\lib\\site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in c:\\users\\elsa\\anaconda3\\envs\\py12_0518\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\elsa\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\elsa\\anaconda3\\envs\\py12_0518\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\elsa\\anaconda3\\envs\\py12_0518\\lib\\site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\users\\elsa\\anaconda3\\envs\\py12_0518\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\elsa\\anaconda3\\envs\\py12_0518\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\elsa\\anaconda3\\envs\\py12_0518\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\elsa\\anaconda3\\envs\\py12_0518\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\elsa\\anaconda3\\envs\\py12_0518\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\elsa\\anaconda3\\envs\\py12_0518\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\elsa\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\elsa\\anaconda3\\envs\\py12_0518\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\elsa\\anaconda3\\envs\\py12_0518\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\elsa\\anaconda3\\envs\\py12_0518\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\elsa\\anaconda3\\envs\\py12_0518\\lib\\site-packages (from requests->transformers) (2024.6.2)\n",
      "Downloading transformers-4.42.4-py3-none-any.whl (9.3 MB)\n",
      "   ---------------------------------------- 0.0/9.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/9.3 MB 3.2 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.4/9.3 MB 5.1 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.0/9.3 MB 8.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.4/9.3 MB 14.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.4/9.3 MB 24.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.1/9.3 MB 34.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.3/9.3 MB 31.4 MB/s eta 0:00:00\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.42.3\n",
      "    Uninstalling transformers-4.42.3:\n",
      "      Successfully uninstalled transformers-4.42.3\n",
      "Successfully installed transformers-4.42.4\n"
     ]
    }
   ],
   "source": [
    "#!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/transformers/index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 23:44:56.528451: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-04 23:44:56.539880: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730735096.552348   36793 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730735096.557794   36793 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-04 23:44:56.575587: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# ËºâÂÖ•Áõ∏ÈóúÂ•ó‰ª∂\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÊÉÖÁ∑íÂàÜÊûê(Sentiment analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english\n",
    "https://huggingface.co/docs/transformers/main_classes/pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "# ËºâÂÖ•Ê®°Âûã, Âü∫Á§éËß£Á¢ºÊú™Á¥∞Ë™ø-sst-2Áâà\n",
    "classifier = pipeline(\n",
    "    \"sentiment-analysis\", \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")\n",
    "# https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9997795224189758}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9996869564056396}]\n",
      "[{'label': 'POSITIVE', 'score': 0.999536395072937}]\n",
      "[{'label': 'POSITIVE', 'score': 0.5919747352600098}]\n"
     ]
    }
   ],
   "source": [
    "# Ê≠£Èù¢\n",
    "print(classifier(\"We are very happy to show you the ü§ó Transformers library.\"))\n",
    "\n",
    "# Ë≤†Èù¢\n",
    "print(classifier(\"I hate this movie.\"))\n",
    "\n",
    "# Âê¶ÂÆöÂè•‰πüÂèØ‰ª•Ê≠£Á¢∫ÂàÜÈ°û\n",
    "print(classifier(\"the movie is not bad.\"))\n",
    "print(classifier(\"I have to work\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: POSITIVE, with score: 0.9999\n",
      "label: NEGATIVE, with score: 0.5309\n"
     ]
    }
   ],
   "source": [
    "# ‰∏ÄÊ¨°Ê∏¨Ë©¶Â§öÁ≠Ü\n",
    "results = classifier([\"We are very happy.\", \"We hope you don't hate it.\"])\n",
    "for result in results:\n",
    "    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a526573548f4e8582f0b060534f5a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/953 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaeaeafc0fbc49e99ae1cacea07e1371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/669M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chesterxalan/github/Classwork/Classwork-PythonDLApplicationDevelopment/.venv/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e1d4aa69c349b38cfe52a6322c7b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/39.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d179d8dce98f4cb8a8cd6f31403ae4e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7450cd277e8478bbd6ef7058a180b4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ef85f34b0b423da97c3754ec7605d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/669M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ËºâÂÖ•Â§öË™ûÁ≥ªÊ®°ÂûãÔºåÊîØÊè¥ English, French, Dutch, German, Italian, Spanish\n",
    "classifier = pipeline(\n",
    "    \"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': '1 star', 'score': 0.4615822732448578}]\n",
      "[{'label': '3 stars', 'score': 0.6274548172950745}]\n"
     ]
    }
   ],
   "source": [
    "# Ë•øÁè≠ÁâôÊñá(Spanish)\n",
    "# Ë≤†Èù¢, I hate this movie\n",
    "print(classifier(\"Odio esta pelicula.\"))\n",
    "\n",
    "# the movie is not bad.\n",
    "print(classifier(\"la pelicula no esta mal.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': '1 star', 'score': 0.6311177611351013}]\n",
      "[{'label': '3 stars', 'score': 0.5710768103599548}]\n"
     ]
    }
   ],
   "source": [
    "# Ê≥ïÊñá(French)\n",
    "# Ë≤†Èù¢, I hate this movie\n",
    "print(classifier(\"Je d√©teste ce film.\"))\n",
    "\n",
    "# the movie is not bad.\n",
    "print(classifier(\"le film n'est pas mal.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
