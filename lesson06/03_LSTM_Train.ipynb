{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 循環神經網絡 LSTM (長短期記憶)來學習字母表順序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型 1. 用LSTM學習一個字符到一個字符映射"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP1. 匯入 Keras 及相關模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 10:01:37.696424: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-26 10:01:37.707425: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1729908097.725210   10699 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1729908097.728873   10699 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-26 10:01:37.741147: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import tensorflow.keras.utils as np_utils\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 給定隨機的種子, 以便讓大家跑起來的結果是相同的\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義序列數據集\n",
    "alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "\n",
    "# 創建字符映射到整數（0 - 25)和反相的查詢字典物件\n",
    "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(alphabet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "字母對應到數字編號: \n",
      " {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25}\n",
      "\n",
      "\n",
      "數字編號對應到字母: \n",
      " {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J', 10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z'}\n"
     ]
    }
   ],
   "source": [
    "print(\"字母對應到數字編號: \\n\", char_to_int)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"數字編號對應到字母: \\n\", int_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A -> B\n",
      "B -> C\n",
      "C -> D\n",
      "D -> E\n",
      "E -> F\n",
      "F -> G\n",
      "G -> H\n",
      "H -> I\n",
      "I -> J\n",
      "J -> K\n",
      "K -> L\n",
      "L -> M\n",
      "M -> N\n",
      "N -> O\n",
      "O -> P\n",
      "P -> Q\n",
      "Q -> R\n",
      "R -> S\n",
      "S -> T\n",
      "T -> U\n",
      "U -> V\n",
      "V -> W\n",
      "W -> X\n",
      "X -> Y\n",
      "Y -> Z\n"
     ]
    }
   ],
   "source": [
    "# 準備輸入數據集\n",
    "seq_length = 1\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, len(alphabet) - seq_length, 1):\n",
    "    seq_in = alphabet[i : i + seq_length]\n",
    "    seq_out = alphabet[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])  # 輸入:A~Y(25個字)\n",
    "    dataY.append(char_to_int[seq_out])  # 輸出:B~Z\n",
    "    print(seq_in, \"->\", seq_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料預處理\n",
    "我們需要將NumPy數組重塑為LSTM網絡所期望的格式，也就是: (samples, time_steps, features)。\n",
    "同時我們將進行資料的歸一化(normalize)來讓資料的值落於0到1之間。並對標籤值進行one-hot的編碼。\n",
    "\n",
    "\n",
    "> ABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
    "\n",
    "> 例如: \n",
    "\n",
    "> 給 J -> 預測 K\n",
    "\n",
    "> 給 X -> 預測 Y\n",
    "\n",
    "\n",
    "目標訓練張量結構: (samples, time_steps, features) -> (n , **1**, **1** )\n",
    "\n",
    "請特別注意, 這裡的1個字符會變成1個時間步裡頭的1個element的\"feature\"向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (25, 1, 1)\n",
      "y shape:  (25, 26)\n"
     ]
    }
   ],
   "source": [
    "# 重塑 X 資料的維度成為 (samples, time_steps, features)\n",
    "X = numpy.reshape(dataX, (len(dataX), seq_length, 1))  # 25組,1個字,1個特徵\n",
    "\n",
    "# 歸一化\n",
    "X = X / float(len(alphabet))\n",
    "\n",
    "# one-hot 編碼輸出變量\n",
    "y = np_utils.to_categorical(dataY)\n",
    "\n",
    "print(\"X shape: \", X.shape)  # (25筆samples, \"1\"個時間步長, 1個feature)\n",
    "print(\"y shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP5. 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729908112.524295   10699 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "/home/chesterxalan/github/Classwork/Classwork-PythonDLApplicationDevelopment/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">858</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │           \u001b[38;5;34m858\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,210</span> (20.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,210\u001b[0m (20.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,210</span> (20.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,210\u001b[0m (20.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 創建模型\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dense(y.shape[1], activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP6. 定義訓練並進行訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729908120.304245   10912 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 - 2s - 64ms/step - accuracy: 0.0000e+00 - loss: 3.2661\n",
      "Epoch 2/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0400 - loss: 3.2585\n",
      "Epoch 3/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.0000e+00 - loss: 3.2561\n",
      "Epoch 4/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0000e+00 - loss: 3.2532\n",
      "Epoch 5/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0000e+00 - loss: 3.2508\n",
      "Epoch 6/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0000e+00 - loss: 3.2481\n",
      "Epoch 7/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0400 - loss: 3.2453\n",
      "Epoch 8/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0000e+00 - loss: 3.2426\n",
      "Epoch 9/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.0400 - loss: 3.2396\n",
      "Epoch 10/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0400 - loss: 3.2367\n",
      "Epoch 11/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.0400 - loss: 3.2335\n",
      "Epoch 12/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.0400 - loss: 3.2298\n",
      "Epoch 13/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0400 - loss: 3.2263\n",
      "Epoch 14/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0400 - loss: 3.2223\n",
      "Epoch 15/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0400 - loss: 3.2180\n",
      "Epoch 16/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0400 - loss: 3.2140\n",
      "Epoch 17/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0400 - loss: 3.2083\n",
      "Epoch 18/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.0400 - loss: 3.2031\n",
      "Epoch 19/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.0400 - loss: 3.1973\n",
      "Epoch 20/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0400 - loss: 3.1917\n",
      "Epoch 21/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0400 - loss: 3.1845\n",
      "Epoch 22/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.0400 - loss: 3.1777\n",
      "Epoch 23/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0400 - loss: 3.1710\n",
      "Epoch 24/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.0400 - loss: 3.1628\n",
      "Epoch 25/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.0400 - loss: 3.1552\n",
      "Epoch 26/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0400 - loss: 3.1468\n",
      "Epoch 27/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 3.1385\n",
      "Epoch 28/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.0800 - loss: 3.1293\n",
      "Epoch 29/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 3.1204\n",
      "Epoch 30/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 3.1113\n",
      "Epoch 31/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 3.1011\n",
      "Epoch 32/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 3.0900\n",
      "Epoch 33/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 3.0799\n",
      "Epoch 34/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 3.0703\n",
      "Epoch 35/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 3.0575\n",
      "Epoch 36/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 3.0458\n",
      "Epoch 37/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 3.0352\n",
      "Epoch 38/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 3.0228\n",
      "Epoch 39/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 3.0087\n",
      "Epoch 40/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 2.9963\n",
      "Epoch 41/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 2.9830\n",
      "Epoch 42/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 2.9717\n",
      "Epoch 43/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 2.9560\n",
      "Epoch 44/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.0800 - loss: 2.9427\n",
      "Epoch 45/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 2.9301\n",
      "Epoch 46/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.0800 - loss: 2.9166\n",
      "Epoch 47/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 2.9029\n",
      "Epoch 48/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0400 - loss: 2.8900\n",
      "Epoch 49/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 2.8756\n",
      "Epoch 50/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.0800 - loss: 2.8633\n",
      "Epoch 51/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0400 - loss: 2.8511\n",
      "Epoch 52/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.0800 - loss: 2.8375\n",
      "Epoch 53/500\n",
      "25/25 - 0s - 7ms/step - accuracy: 0.0400 - loss: 2.8256\n",
      "Epoch 54/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.1200 - loss: 2.8127\n",
      "Epoch 55/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.0800 - loss: 2.8016\n",
      "Epoch 56/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 2.7898\n",
      "Epoch 57/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 2.7783\n",
      "Epoch 58/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 2.7680\n",
      "Epoch 59/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.0800 - loss: 2.7581\n",
      "Epoch 60/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 2.7481\n",
      "Epoch 61/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0400 - loss: 2.7379\n",
      "Epoch 62/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 2.7284\n",
      "Epoch 63/500\n",
      "25/25 - 0s - 7ms/step - accuracy: 0.0400 - loss: 2.7195\n",
      "Epoch 64/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 2.7097\n",
      "Epoch 65/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 2.7013\n",
      "Epoch 66/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0400 - loss: 2.6938\n",
      "Epoch 67/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 2.6847\n",
      "Epoch 68/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 2.6772\n",
      "Epoch 69/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.0400 - loss: 2.6700\n",
      "Epoch 70/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0400 - loss: 2.6633\n",
      "Epoch 71/500\n",
      "25/25 - -0s - -16981us/step - accuracy: 0.0800 - loss: 2.6548\n",
      "Epoch 72/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 2.6485\n",
      "Epoch 73/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.0400 - loss: 2.6419\n",
      "Epoch 74/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 2.6335\n",
      "Epoch 75/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.0400 - loss: 2.6281\n",
      "Epoch 76/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0400 - loss: 2.6220\n",
      "Epoch 77/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 2.6156\n",
      "Epoch 78/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0400 - loss: 2.6102\n",
      "Epoch 79/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 2.6025\n",
      "Epoch 80/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0400 - loss: 2.5978\n",
      "Epoch 81/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 2.5917\n",
      "Epoch 82/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 2.5861\n",
      "Epoch 83/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0400 - loss: 2.5799\n",
      "Epoch 84/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1200 - loss: 2.5749\n",
      "Epoch 85/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.0400 - loss: 2.5688\n",
      "Epoch 86/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0800 - loss: 2.5647\n",
      "Epoch 87/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1200 - loss: 2.5592\n",
      "Epoch 88/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.0400 - loss: 2.5540\n",
      "Epoch 89/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1200 - loss: 2.5478\n",
      "Epoch 90/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.1200 - loss: 2.5431\n",
      "Epoch 91/500\n",
      "25/25 - 0s - 4ms/step - accuracy: 0.0800 - loss: 2.5385\n",
      "Epoch 92/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.1200 - loss: 2.5334\n",
      "Epoch 93/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1200 - loss: 2.5279\n",
      "Epoch 94/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1200 - loss: 2.5225\n",
      "Epoch 95/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1200 - loss: 2.5175\n",
      "Epoch 96/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1200 - loss: 2.5120\n",
      "Epoch 97/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.1200 - loss: 2.5087\n",
      "Epoch 98/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1200 - loss: 2.5027\n",
      "Epoch 99/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1200 - loss: 2.4991\n",
      "Epoch 100/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1200 - loss: 2.4926\n",
      "Epoch 101/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1200 - loss: 2.4885\n",
      "Epoch 102/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1200 - loss: 2.4847\n",
      "Epoch 103/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1600 - loss: 2.4780\n",
      "Epoch 104/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.1600 - loss: 2.4733\n",
      "Epoch 105/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1600 - loss: 2.4679\n",
      "Epoch 106/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1600 - loss: 2.4648\n",
      "Epoch 107/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1600 - loss: 2.4606\n",
      "Epoch 108/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1600 - loss: 2.4547\n",
      "Epoch 109/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1600 - loss: 2.4497\n",
      "Epoch 110/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.1600 - loss: 2.4457\n",
      "Epoch 111/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1600 - loss: 2.4408\n",
      "Epoch 112/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1600 - loss: 2.4378\n",
      "Epoch 113/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1600 - loss: 2.4321\n",
      "Epoch 114/500\n",
      "25/25 - 0s - 4ms/step - accuracy: 0.1600 - loss: 2.4277\n",
      "Epoch 115/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1600 - loss: 2.4228\n",
      "Epoch 116/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1600 - loss: 2.4185\n",
      "Epoch 117/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1600 - loss: 2.4137\n",
      "Epoch 118/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1600 - loss: 2.4097\n",
      "Epoch 119/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1600 - loss: 2.4058\n",
      "Epoch 120/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.1600 - loss: 2.4022\n",
      "Epoch 121/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.1600 - loss: 2.3964\n",
      "Epoch 122/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1600 - loss: 2.3916\n",
      "Epoch 123/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1600 - loss: 2.3883\n",
      "Epoch 124/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.1600 - loss: 2.3850\n",
      "Epoch 125/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1600 - loss: 2.3801\n",
      "Epoch 126/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.1600 - loss: 2.3764\n",
      "Epoch 127/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1600 - loss: 2.3730\n",
      "Epoch 128/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.1600 - loss: 2.3678\n",
      "Epoch 129/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.1600 - loss: 2.3641\n",
      "Epoch 130/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1200 - loss: 2.3603\n",
      "Epoch 131/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.1600 - loss: 2.3589\n",
      "Epoch 132/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2000 - loss: 2.3529\n",
      "Epoch 133/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.1600 - loss: 2.3502\n",
      "Epoch 134/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.1600 - loss: 2.3442\n",
      "Epoch 135/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1600 - loss: 2.3422\n",
      "Epoch 136/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.2000 - loss: 2.3375\n",
      "Epoch 137/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2000 - loss: 2.3335\n",
      "Epoch 138/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.2400 - loss: 2.3296\n",
      "Epoch 139/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.2400 - loss: 2.3280\n",
      "Epoch 140/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2000 - loss: 2.3230\n",
      "Epoch 141/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1600 - loss: 2.3205\n",
      "Epoch 142/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1200 - loss: 2.3157\n",
      "Epoch 143/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1600 - loss: 2.3131\n",
      "Epoch 144/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2000 - loss: 2.3107\n",
      "Epoch 145/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2000 - loss: 2.3054\n",
      "Epoch 146/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.2400 - loss: 2.3028\n",
      "Epoch 147/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2000 - loss: 2.2986\n",
      "Epoch 148/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2400 - loss: 2.2951\n",
      "Epoch 149/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.2000 - loss: 2.2928\n",
      "Epoch 150/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1600 - loss: 2.2893\n",
      "Epoch 151/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1600 - loss: 2.2857\n",
      "Epoch 152/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2000 - loss: 2.2826\n",
      "Epoch 153/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2000 - loss: 2.2791\n",
      "Epoch 154/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2400 - loss: 2.2760\n",
      "Epoch 155/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.2400 - loss: 2.2728\n",
      "Epoch 156/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2400 - loss: 2.2706\n",
      "Epoch 157/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2400 - loss: 2.2677\n",
      "Epoch 158/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.2400 - loss: 2.2654\n",
      "Epoch 159/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2000 - loss: 2.2611\n",
      "Epoch 160/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2000 - loss: 2.2582\n",
      "Epoch 161/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.2400 - loss: 2.2547\n",
      "Epoch 162/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.2400 - loss: 2.2508\n",
      "Epoch 163/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.1200 - loss: 2.2492\n",
      "Epoch 164/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2400 - loss: 2.2452\n",
      "Epoch 165/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2400 - loss: 2.2423\n",
      "Epoch 166/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2800 - loss: 2.2391\n",
      "Epoch 167/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1600 - loss: 2.2379\n",
      "Epoch 168/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2400 - loss: 2.2334\n",
      "Epoch 169/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.1600 - loss: 2.2321\n",
      "Epoch 170/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2400 - loss: 2.2275\n",
      "Epoch 171/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.2400 - loss: 2.2239\n",
      "Epoch 172/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.3200 - loss: 2.2229\n",
      "Epoch 173/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2000 - loss: 2.2203\n",
      "Epoch 174/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.2800 - loss: 2.2165\n",
      "Epoch 175/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.2400 - loss: 2.2131\n",
      "Epoch 176/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2800 - loss: 2.2111\n",
      "Epoch 177/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2000 - loss: 2.2074\n",
      "Epoch 178/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.2400 - loss: 2.2061\n",
      "Epoch 179/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2800 - loss: 2.2035\n",
      "Epoch 180/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.2000 - loss: 2.2003\n",
      "Epoch 181/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.3600 - loss: 2.1980\n",
      "Epoch 182/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.3200 - loss: 2.1951\n",
      "Epoch 183/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.2000 - loss: 2.1916\n",
      "Epoch 184/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2400 - loss: 2.1894\n",
      "Epoch 185/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.2400 - loss: 2.1880\n",
      "Epoch 186/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2800 - loss: 2.1838\n",
      "Epoch 187/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.2800 - loss: 2.1809\n",
      "Epoch 188/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.2400 - loss: 2.1792\n",
      "Epoch 189/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2000 - loss: 2.1771\n",
      "Epoch 190/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2400 - loss: 2.1745\n",
      "Epoch 191/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.1600 - loss: 2.1740\n",
      "Epoch 192/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.1600 - loss: 2.1688\n",
      "Epoch 193/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.3200 - loss: 2.1667\n",
      "Epoch 194/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2000 - loss: 2.1653\n",
      "Epoch 195/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.3600 - loss: 2.1613\n",
      "Epoch 196/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2800 - loss: 2.1585\n",
      "Epoch 197/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.3200 - loss: 2.1564\n",
      "Epoch 198/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.3200 - loss: 2.1563\n",
      "Epoch 199/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.3200 - loss: 2.1526\n",
      "Epoch 200/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.2800 - loss: 2.1502\n",
      "Epoch 201/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.4000 - loss: 2.1465\n",
      "Epoch 202/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.2400 - loss: 2.1453\n",
      "Epoch 203/500\n",
      "25/25 - 0s - 4ms/step - accuracy: 0.3200 - loss: 2.1430\n",
      "Epoch 204/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.3600 - loss: 2.1400\n",
      "Epoch 205/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.3200 - loss: 2.1378\n",
      "Epoch 206/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.3600 - loss: 2.1356\n",
      "Epoch 207/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.2800 - loss: 2.1335\n",
      "Epoch 208/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.3600 - loss: 2.1312\n",
      "Epoch 209/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4000 - loss: 2.1291\n",
      "Epoch 210/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.3600 - loss: 2.1269\n",
      "Epoch 211/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.3200 - loss: 2.1250\n",
      "Epoch 212/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.3600 - loss: 2.1228\n",
      "Epoch 213/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4400 - loss: 2.1192\n",
      "Epoch 214/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.3200 - loss: 2.1186\n",
      "Epoch 215/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.3200 - loss: 2.1150\n",
      "Epoch 216/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.3600 - loss: 2.1134\n",
      "Epoch 217/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4400 - loss: 2.1107\n",
      "Epoch 218/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4400 - loss: 2.1087\n",
      "Epoch 219/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.3600 - loss: 2.1058\n",
      "Epoch 220/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.3200 - loss: 2.1035\n",
      "Epoch 221/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4000 - loss: 2.1025\n",
      "Epoch 222/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.3200 - loss: 2.1002\n",
      "Epoch 223/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4000 - loss: 2.0981\n",
      "Epoch 224/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.4000 - loss: 2.0938\n",
      "Epoch 225/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.3200 - loss: 2.0950\n",
      "Epoch 226/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4400 - loss: 2.0908\n",
      "Epoch 227/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.3200 - loss: 2.0890\n",
      "Epoch 228/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4000 - loss: 2.0874\n",
      "Epoch 229/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.3200 - loss: 2.0847\n",
      "Epoch 230/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.3200 - loss: 2.0822\n",
      "Epoch 231/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4000 - loss: 2.0812\n",
      "Epoch 232/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4400 - loss: 2.0769\n",
      "Epoch 233/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4000 - loss: 2.0751\n",
      "Epoch 234/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4400 - loss: 2.0746\n",
      "Epoch 235/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.4400 - loss: 2.0729\n",
      "Epoch 236/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.4800 - loss: 2.0719\n",
      "Epoch 237/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.4000 - loss: 2.0680\n",
      "Epoch 238/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.4000 - loss: 2.0668\n",
      "Epoch 239/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4400 - loss: 2.0631\n",
      "Epoch 240/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.3600 - loss: 2.0627\n",
      "Epoch 241/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4400 - loss: 2.0599\n",
      "Epoch 242/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4400 - loss: 2.0578\n",
      "Epoch 243/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.4400 - loss: 2.0572\n",
      "Epoch 244/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4800 - loss: 2.0545\n",
      "Epoch 245/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4400 - loss: 2.0526\n",
      "Epoch 246/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.4000 - loss: 2.0514\n",
      "Epoch 247/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.4800 - loss: 2.0485\n",
      "Epoch 248/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.3200 - loss: 2.0476\n",
      "Epoch 249/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4800 - loss: 2.0444\n",
      "Epoch 250/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.3600 - loss: 2.0423\n",
      "Epoch 251/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.5200 - loss: 2.0391\n",
      "Epoch 252/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4000 - loss: 2.0395\n",
      "Epoch 253/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5200 - loss: 2.0365\n",
      "Epoch 254/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5200 - loss: 2.0331\n",
      "Epoch 255/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5200 - loss: 2.0326\n",
      "Epoch 256/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.2800 - loss: 2.0310\n",
      "Epoch 257/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5200 - loss: 2.0302\n",
      "Epoch 258/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4000 - loss: 2.0271\n",
      "Epoch 259/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.4400 - loss: 2.0245\n",
      "Epoch 260/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4800 - loss: 2.0222\n",
      "Epoch 261/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4400 - loss: 2.0208\n",
      "Epoch 262/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.4400 - loss: 2.0189\n",
      "Epoch 263/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5200 - loss: 2.0193\n",
      "Epoch 264/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4000 - loss: 2.0163\n",
      "Epoch 265/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4000 - loss: 2.0154\n",
      "Epoch 266/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4000 - loss: 2.0121\n",
      "Epoch 267/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4800 - loss: 2.0095\n",
      "Epoch 268/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.5600 - loss: 2.0076\n",
      "Epoch 269/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5200 - loss: 2.0072\n",
      "Epoch 270/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4800 - loss: 2.0057\n",
      "Epoch 271/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4800 - loss: 2.0039\n",
      "Epoch 272/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4800 - loss: 2.0008\n",
      "Epoch 273/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5200 - loss: 2.0005\n",
      "Epoch 274/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4400 - loss: 1.9991\n",
      "Epoch 275/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4400 - loss: 1.9959\n",
      "Epoch 276/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4800 - loss: 1.9934\n",
      "Epoch 277/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.6000 - loss: 1.9916\n",
      "Epoch 278/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.5200 - loss: 1.9899\n",
      "Epoch 279/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4800 - loss: 1.9894\n",
      "Epoch 280/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.5600 - loss: 1.9866\n",
      "Epoch 281/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5600 - loss: 1.9854\n",
      "Epoch 282/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5200 - loss: 1.9834\n",
      "Epoch 283/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5200 - loss: 1.9819\n",
      "Epoch 284/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.4400 - loss: 1.9805\n",
      "Epoch 285/500\n",
      "25/25 - 0s - 4ms/step - accuracy: 0.4800 - loss: 1.9786\n",
      "Epoch 286/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5600 - loss: 1.9761\n",
      "Epoch 287/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4800 - loss: 1.9747\n",
      "Epoch 288/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4400 - loss: 1.9749\n",
      "Epoch 289/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4800 - loss: 1.9728\n",
      "Epoch 290/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4400 - loss: 1.9684\n",
      "Epoch 291/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4400 - loss: 1.9674\n",
      "Epoch 292/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4400 - loss: 1.9676\n",
      "Epoch 293/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4000 - loss: 1.9634\n",
      "Epoch 294/500\n",
      "25/25 - 0s - 7ms/step - accuracy: 0.4800 - loss: 1.9633\n",
      "Epoch 295/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.6000 - loss: 1.9607\n",
      "Epoch 296/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4400 - loss: 1.9617\n",
      "Epoch 297/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.5600 - loss: 1.9588\n",
      "Epoch 298/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5200 - loss: 1.9555\n",
      "Epoch 299/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5600 - loss: 1.9550\n",
      "Epoch 300/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.4800 - loss: 1.9499\n",
      "Epoch 301/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5600 - loss: 1.9509\n",
      "Epoch 302/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6000 - loss: 1.9494\n",
      "Epoch 303/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.6400 - loss: 1.9471\n",
      "Epoch 304/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.6000 - loss: 1.9480\n",
      "Epoch 305/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.4800 - loss: 1.9433\n",
      "Epoch 306/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6400 - loss: 1.9427\n",
      "Epoch 307/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6400 - loss: 1.9406\n",
      "Epoch 308/500\n",
      "25/25 - -0s - -16985us/step - accuracy: 0.4800 - loss: 1.9401\n",
      "Epoch 309/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4000 - loss: 1.9376\n",
      "Epoch 310/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.5600 - loss: 1.9373\n",
      "Epoch 311/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.5200 - loss: 1.9336\n",
      "Epoch 312/500\n",
      "25/25 - 0s - 7ms/step - accuracy: 0.5600 - loss: 1.9343\n",
      "Epoch 313/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5200 - loss: 1.9326\n",
      "Epoch 314/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4800 - loss: 1.9304\n",
      "Epoch 315/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5600 - loss: 1.9292\n",
      "Epoch 316/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4400 - loss: 1.9268\n",
      "Epoch 317/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5200 - loss: 1.9245\n",
      "Epoch 318/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6000 - loss: 1.9254\n",
      "Epoch 319/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.4800 - loss: 1.9240\n",
      "Epoch 320/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4800 - loss: 1.9211\n",
      "Epoch 321/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4800 - loss: 1.9192\n",
      "Epoch 322/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.4800 - loss: 1.9191\n",
      "Epoch 323/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5600 - loss: 1.9151\n",
      "Epoch 324/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5200 - loss: 1.9158\n",
      "Epoch 325/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5200 - loss: 1.9134\n",
      "Epoch 326/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6400 - loss: 1.9123\n",
      "Epoch 327/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6000 - loss: 1.9118\n",
      "Epoch 328/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5600 - loss: 1.9083\n",
      "Epoch 329/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5600 - loss: 1.9075\n",
      "Epoch 330/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6400 - loss: 1.9068\n",
      "Epoch 331/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6000 - loss: 1.9040\n",
      "Epoch 332/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.4800 - loss: 1.9026\n",
      "Epoch 333/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.5600 - loss: 1.9001\n",
      "Epoch 334/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6400 - loss: 1.9011\n",
      "Epoch 335/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6400 - loss: 1.8977\n",
      "Epoch 336/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.6000 - loss: 1.8964\n",
      "Epoch 337/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6400 - loss: 1.8951\n",
      "Epoch 338/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.4400 - loss: 1.8951\n",
      "Epoch 339/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5600 - loss: 1.8902\n",
      "Epoch 340/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.5600 - loss: 1.8912\n",
      "Epoch 341/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.4800 - loss: 1.8893\n",
      "Epoch 342/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5600 - loss: 1.8870\n",
      "Epoch 343/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.4800 - loss: 1.8867\n",
      "Epoch 344/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5200 - loss: 1.8857\n",
      "Epoch 345/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.6000 - loss: 1.8833\n",
      "Epoch 346/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6000 - loss: 1.8825\n",
      "Epoch 347/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5600 - loss: 1.8816\n",
      "Epoch 348/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6400 - loss: 1.8793\n",
      "Epoch 349/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6000 - loss: 1.8802\n",
      "Epoch 350/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6000 - loss: 1.8756\n",
      "Epoch 351/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5600 - loss: 1.8754\n",
      "Epoch 352/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.5600 - loss: 1.8742\n",
      "Epoch 353/500\n",
      "25/25 - 0s - 14ms/step - accuracy: 0.6400 - loss: 1.8705\n",
      "Epoch 354/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.6400 - loss: 1.8697\n",
      "Epoch 355/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6000 - loss: 1.8695\n",
      "Epoch 356/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5600 - loss: 1.8679\n",
      "Epoch 357/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.6000 - loss: 1.8668\n",
      "Epoch 358/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.6400 - loss: 1.8673\n",
      "Epoch 359/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.6000 - loss: 1.8648\n",
      "Epoch 360/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7200 - loss: 1.8638\n",
      "Epoch 361/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5600 - loss: 1.8617\n",
      "Epoch 362/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6800 - loss: 1.8609\n",
      "Epoch 363/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6000 - loss: 1.8589\n",
      "Epoch 364/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6400 - loss: 1.8578\n",
      "Epoch 365/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6400 - loss: 1.8582\n",
      "Epoch 366/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5600 - loss: 1.8532\n",
      "Epoch 367/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.5600 - loss: 1.8512\n",
      "Epoch 368/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7200 - loss: 1.8522\n",
      "Epoch 369/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.6000 - loss: 1.8514\n",
      "Epoch 370/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.6000 - loss: 1.8514\n",
      "Epoch 371/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7600 - loss: 1.8479\n",
      "Epoch 372/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.6800 - loss: 1.8465\n",
      "Epoch 373/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.6000 - loss: 1.8447\n",
      "Epoch 374/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6000 - loss: 1.8436\n",
      "Epoch 375/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.5600 - loss: 1.8442\n",
      "Epoch 376/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6800 - loss: 1.8409\n",
      "Epoch 377/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.5600 - loss: 1.8400\n",
      "Epoch 378/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6800 - loss: 1.8380\n",
      "Epoch 379/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6400 - loss: 1.8381\n",
      "Epoch 380/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7200 - loss: 1.8354\n",
      "Epoch 381/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6000 - loss: 1.8363\n",
      "Epoch 382/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.6400 - loss: 1.8329\n",
      "Epoch 383/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6400 - loss: 1.8327\n",
      "Epoch 384/500\n",
      "25/25 - 0s - 4ms/step - accuracy: 0.5600 - loss: 1.8310\n",
      "Epoch 385/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6400 - loss: 1.8304\n",
      "Epoch 386/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7200 - loss: 1.8300\n",
      "Epoch 387/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6400 - loss: 1.8272\n",
      "Epoch 388/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.6800 - loss: 1.8249\n",
      "Epoch 389/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6000 - loss: 1.8242\n",
      "Epoch 390/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6800 - loss: 1.8248\n",
      "Epoch 391/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6000 - loss: 1.8217\n",
      "Epoch 392/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.6000 - loss: 1.8206\n",
      "Epoch 393/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.6800 - loss: 1.8195\n",
      "Epoch 394/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6800 - loss: 1.8176\n",
      "Epoch 395/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6400 - loss: 1.8170\n",
      "Epoch 396/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.7200 - loss: 1.8171\n",
      "Epoch 397/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7200 - loss: 1.8152\n",
      "Epoch 398/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6800 - loss: 1.8145\n",
      "Epoch 399/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7200 - loss: 1.8125\n",
      "Epoch 400/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.6400 - loss: 1.8129\n",
      "Epoch 401/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7200 - loss: 1.8108\n",
      "Epoch 402/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.6400 - loss: 1.8107\n",
      "Epoch 403/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6800 - loss: 1.8081\n",
      "Epoch 404/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.6000 - loss: 1.8062\n",
      "Epoch 405/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6000 - loss: 1.8042\n",
      "Epoch 406/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7200 - loss: 1.8048\n",
      "Epoch 407/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7200 - loss: 1.8038\n",
      "Epoch 408/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7200 - loss: 1.8018\n",
      "Epoch 409/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6400 - loss: 1.8024\n",
      "Epoch 410/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.7200 - loss: 1.8002\n",
      "Epoch 411/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6800 - loss: 1.7969\n",
      "Epoch 412/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6800 - loss: 1.7983\n",
      "Epoch 413/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6800 - loss: 1.7973\n",
      "Epoch 414/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7600 - loss: 1.7949\n",
      "Epoch 415/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.7600 - loss: 1.7925\n",
      "Epoch 416/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7200 - loss: 1.7912\n",
      "Epoch 417/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6400 - loss: 1.7907\n",
      "Epoch 418/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6800 - loss: 1.7910\n",
      "Epoch 419/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.6800 - loss: 1.7887\n",
      "Epoch 420/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6000 - loss: 1.7889\n",
      "Epoch 421/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.6800 - loss: 1.7877\n",
      "Epoch 422/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6800 - loss: 1.7849\n",
      "Epoch 423/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7200 - loss: 1.7859\n",
      "Epoch 424/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6000 - loss: 1.7854\n",
      "Epoch 425/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7600 - loss: 1.7843\n",
      "Epoch 426/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.6400 - loss: 1.7818\n",
      "Epoch 427/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7600 - loss: 1.7797\n",
      "Epoch 428/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7200 - loss: 1.7803\n",
      "Epoch 429/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7200 - loss: 1.7766\n",
      "Epoch 430/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7600 - loss: 1.7765\n",
      "Epoch 431/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6400 - loss: 1.7768\n",
      "Epoch 432/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.6800 - loss: 1.7744\n",
      "Epoch 433/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7200 - loss: 1.7731\n",
      "Epoch 434/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.6800 - loss: 1.7731\n",
      "Epoch 435/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7200 - loss: 1.7713\n",
      "Epoch 436/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7600 - loss: 1.7702\n",
      "Epoch 437/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6400 - loss: 1.7713\n",
      "Epoch 438/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7600 - loss: 1.7684\n",
      "Epoch 439/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7200 - loss: 1.7668\n",
      "Epoch 440/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7600 - loss: 1.7686\n",
      "Epoch 441/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.8000 - loss: 1.7646\n",
      "Epoch 442/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.7600 - loss: 1.7641\n",
      "Epoch 443/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.6000 - loss: 1.7639\n",
      "Epoch 444/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7200 - loss: 1.7605\n",
      "Epoch 445/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.7600 - loss: 1.7585\n",
      "Epoch 446/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.7600 - loss: 1.7605\n",
      "Epoch 447/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7600 - loss: 1.7583\n",
      "Epoch 448/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.8000 - loss: 1.7582\n",
      "Epoch 449/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.7200 - loss: 1.7571\n",
      "Epoch 450/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7200 - loss: 1.7583\n",
      "Epoch 451/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7600 - loss: 1.7539\n",
      "Epoch 452/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.8000 - loss: 1.7523\n",
      "Epoch 453/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.7600 - loss: 1.7506\n",
      "Epoch 454/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7200 - loss: 1.7498\n",
      "Epoch 455/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6800 - loss: 1.7491\n",
      "Epoch 456/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.7200 - loss: 1.7475\n",
      "Epoch 457/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6800 - loss: 1.7482\n",
      "Epoch 458/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.8000 - loss: 1.7488\n",
      "Epoch 459/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.6800 - loss: 1.7460\n",
      "Epoch 460/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.7600 - loss: 1.7429\n",
      "Epoch 461/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7200 - loss: 1.7413\n",
      "Epoch 462/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.7600 - loss: 1.7423\n",
      "Epoch 463/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.8000 - loss: 1.7411\n",
      "Epoch 464/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7600 - loss: 1.7412\n",
      "Epoch 465/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7600 - loss: 1.7384\n",
      "Epoch 466/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.7600 - loss: 1.7401\n",
      "Epoch 467/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.8000 - loss: 1.7364\n",
      "Epoch 468/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.8000 - loss: 1.7363\n",
      "Epoch 469/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.7600 - loss: 1.7358\n",
      "Epoch 470/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7200 - loss: 1.7332\n",
      "Epoch 471/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7600 - loss: 1.7332\n",
      "Epoch 472/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7600 - loss: 1.7325\n",
      "Epoch 473/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7200 - loss: 1.7298\n",
      "Epoch 474/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.8000 - loss: 1.7281\n",
      "Epoch 475/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.8000 - loss: 1.7291\n",
      "Epoch 476/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7200 - loss: 1.7276\n",
      "Epoch 477/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7200 - loss: 1.7270\n",
      "Epoch 478/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7600 - loss: 1.7265\n",
      "Epoch 479/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.8000 - loss: 1.7272\n",
      "Epoch 480/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.7600 - loss: 1.7254\n",
      "Epoch 481/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.8000 - loss: 1.7252\n",
      "Epoch 482/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7600 - loss: 1.7232\n",
      "Epoch 483/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.8000 - loss: 1.7222\n",
      "Epoch 484/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.8000 - loss: 1.7201\n",
      "Epoch 485/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7200 - loss: 1.7200\n",
      "Epoch 486/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.8000 - loss: 1.7215\n",
      "Epoch 487/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7200 - loss: 1.7184\n",
      "Epoch 488/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.8000 - loss: 1.7159\n",
      "Epoch 489/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.8000 - loss: 1.7140\n",
      "Epoch 490/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7600 - loss: 1.7127\n",
      "Epoch 491/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.8000 - loss: 1.7131\n",
      "Epoch 492/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.8000 - loss: 1.7144\n",
      "Epoch 493/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.8000 - loss: 1.7083\n",
      "Epoch 494/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.8000 - loss: 1.7096\n",
      "Epoch 495/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.8000 - loss: 1.7101\n",
      "Epoch 496/500\n",
      "25/25 - 0s - 6ms/step - accuracy: 0.8000 - loss: 1.7102\n",
      "Epoch 497/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.8400 - loss: 1.7076\n",
      "Epoch 498/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7600 - loss: 1.7055\n",
      "Epoch 499/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.8000 - loss: 1.7060\n",
      "Epoch 500/500\n",
      "25/25 - 0s - 5ms/step - accuracy: 0.7600 - loss: 1.7032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f3744b41850>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X, y, epochs=500, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP7. 評估模型準確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 80.00%\n"
     ]
    }
   ],
   "source": [
    "# 評估模型的性能\n",
    "scores = model.evaluate(X, y, verbose=0)\n",
    "print(\"Model Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP8. 預測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A'] -> B\n",
      "['B'] -> B\n",
      "['C'] -> D\n",
      "['D'] -> E\n",
      "['E'] -> F\n",
      "['F'] -> G\n",
      "['G'] -> H\n",
      "['H'] -> I\n",
      "['I'] -> J\n",
      "['J'] -> K\n",
      "['K'] -> L\n",
      "['L'] -> M\n",
      "['M'] -> N\n",
      "['N'] -> O\n",
      "['O'] -> P\n",
      "['P'] -> Q\n",
      "['Q'] -> R\n",
      "['R'] -> S\n",
      "['S'] -> T\n",
      "['T'] -> U\n",
      "['U'] -> W\n",
      "['V'] -> X\n",
      "['W'] -> Z\n",
      "['X'] -> Z\n",
      "['Y'] -> Z\n"
     ]
    }
   ],
   "source": [
    "# 展示模型預測能力\n",
    "for pattern in dataX:\n",
    "    # 把26個字母一個個拿進模型來預測會出現的字母\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(len(alphabet))\n",
    "\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)  # 機率最大的idx\n",
    "    result = int_to_char[index]  # 看看預測出來的是那一個字母\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    print(seq_in, \"->\", result)  # 打印結果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型 2. LSTM 學習三個字符特徵窗口(Three-Char Feature Window)到一個字符映射\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP1. 準備訓練用資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABC -> D\n",
      "BCD -> E\n",
      "CDE -> F\n",
      "DEF -> G\n",
      "EFG -> H\n",
      "FGH -> I\n",
      "GHI -> J\n",
      "HIJ -> K\n",
      "IJK -> L\n",
      "JKL -> M\n",
      "KLM -> N\n",
      "LMN -> O\n",
      "MNO -> P\n",
      "NOP -> Q\n",
      "OPQ -> R\n",
      "PQR -> S\n",
      "QRS -> T\n",
      "RST -> U\n",
      "STU -> V\n",
      "TUV -> W\n",
      "UVW -> X\n",
      "VWX -> Y\n",
      "WXY -> Z\n"
     ]
    }
   ],
   "source": [
    "# 準備輸入數據集\n",
    "seq_length = 3  # 這次我們要準備3個時間步長的資料\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, len(alphabet) - seq_length, 1):\n",
    "    seq_in = alphabet[i : i + seq_length]  # 3個字符\n",
    "    seq_out = alphabet[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "    print(seq_in, \"->\", seq_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP2. 資料預處理\n",
    "\n",
    "\n",
    "> ABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
    "\n",
    "> 例如: \n",
    "\n",
    "> 給 HIJ -> 預測 K\n",
    "\n",
    "> 給 EFG -> 預測 H\n",
    "\n",
    "目標訓練張量結構: (samples, time_steps, features) -> (n , **1**, **3** )\n",
    "\n",
    "請特別注意, 這裡的三個字符會變成一個有3個element的\"feature\" vector。因此在準備訓練資料集的時候, 1筆訓練資料只有\"1\"個時間步, 裡頭存放著\"3\"個字符的資料\"features\"向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (23, 1, 3)\n",
      "y shape:  (23, 26)\n"
     ]
    }
   ],
   "source": [
    "# 重塑 X 資料的維度成為 (samples, time_steps, features)\n",
    "X = numpy.reshape(dataX, (len(dataX), 1, seq_length))  # <-- 特別注意這裡\n",
    "\n",
    "# 歸一化\n",
    "X = X / float(len(alphabet))\n",
    "\n",
    "# 使用one hot encode 對Y值進行編碼\n",
    "y = np_utils.to_categorical(dataY)\n",
    "\n",
    "print(\"X shape: \", X.shape)\n",
    "print(\"y shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP3. 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,608</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">858</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,608\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │           \u001b[38;5;34m858\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,466</span> (21.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,466\u001b[0m (21.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,466</span> (21.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,466\u001b[0m (21.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 創建模型\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(X.shape[1], X.shape[2])))  # <-- 特別注意這裡\n",
    "model.add(Dense(y.shape[1], activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP4. 定義訓練並進行訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "23/23 - 1s - 37ms/step - accuracy: 0.0000e+00 - loss: 3.2677\n",
      "Epoch 2/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.2542\n",
      "Epoch 3/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.2469\n",
      "Epoch 4/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.2400\n",
      "Epoch 5/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.2332\n",
      "Epoch 6/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.2263\n",
      "Epoch 7/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.2194\n",
      "Epoch 8/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.2127\n",
      "Epoch 9/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.2049\n",
      "Epoch 10/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.1974\n",
      "Epoch 11/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.1897\n",
      "Epoch 12/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.1818\n",
      "Epoch 13/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0435 - loss: 3.1738\n",
      "Epoch 14/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.1649\n",
      "Epoch 15/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0435 - loss: 3.1569\n",
      "Epoch 16/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.1485\n",
      "Epoch 17/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.1391\n",
      "Epoch 18/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.1306\n",
      "Epoch 19/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0000e+00 - loss: 3.1221\n",
      "Epoch 20/500\n",
      "23/23 - -1s - -21971us/step - accuracy: 0.0435 - loss: 3.1130\n",
      "Epoch 21/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 3.1048\n",
      "Epoch 22/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0435 - loss: 3.0952\n",
      "Epoch 23/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.0881\n",
      "Epoch 24/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0435 - loss: 3.0791\n",
      "Epoch 25/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.0720\n",
      "Epoch 26/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.0647\n",
      "Epoch 27/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.0575\n",
      "Epoch 28/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0435 - loss: 3.0492\n",
      "Epoch 29/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.0421\n",
      "Epoch 30/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0435 - loss: 3.0355\n",
      "Epoch 31/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.0265\n",
      "Epoch 32/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.0190\n",
      "Epoch 33/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.0124\n",
      "Epoch 34/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 3.0050\n",
      "Epoch 35/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.9984\n",
      "Epoch 36/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.9901\n",
      "Epoch 37/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.9827\n",
      "Epoch 38/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.9748\n",
      "Epoch 39/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.0870 - loss: 2.9677\n",
      "Epoch 40/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.9591\n",
      "Epoch 41/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.9509\n",
      "Epoch 42/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.9426\n",
      "Epoch 43/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.9327\n",
      "Epoch 44/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.9245\n",
      "Epoch 45/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.9156\n",
      "Epoch 46/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.9066\n",
      "Epoch 47/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.8963\n",
      "Epoch 48/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.8871\n",
      "Epoch 49/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.8768\n",
      "Epoch 50/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.8660\n",
      "Epoch 51/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.8561\n",
      "Epoch 52/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.8475\n",
      "Epoch 53/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.8351\n",
      "Epoch 54/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.0870 - loss: 2.8241\n",
      "Epoch 55/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.8139\n",
      "Epoch 56/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.8030\n",
      "Epoch 57/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.7915\n",
      "Epoch 58/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.7816\n",
      "Epoch 59/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.7707\n",
      "Epoch 60/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.7601\n",
      "Epoch 61/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.7483\n",
      "Epoch 62/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1739 - loss: 2.7391\n",
      "Epoch 63/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.7296\n",
      "Epoch 64/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.7182\n",
      "Epoch 65/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.7074\n",
      "Epoch 66/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.6975\n",
      "Epoch 67/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.6858\n",
      "Epoch 68/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.6772\n",
      "Epoch 69/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.6671\n",
      "Epoch 70/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.6581\n",
      "Epoch 71/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.6488\n",
      "Epoch 72/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.6396\n",
      "Epoch 73/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.6302\n",
      "Epoch 74/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.6220\n",
      "Epoch 75/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.6134\n",
      "Epoch 76/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.6057\n",
      "Epoch 77/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.5972\n",
      "Epoch 78/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.5891\n",
      "Epoch 79/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.5816\n",
      "Epoch 80/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.5742\n",
      "Epoch 81/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.5669\n",
      "Epoch 82/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.5598\n",
      "Epoch 83/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.5522\n",
      "Epoch 84/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.5441\n",
      "Epoch 85/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.5381\n",
      "Epoch 86/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.5312\n",
      "Epoch 87/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.5251\n",
      "Epoch 88/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.5175\n",
      "Epoch 89/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.5108\n",
      "Epoch 90/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.5064\n",
      "Epoch 91/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.4987\n",
      "Epoch 92/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.4914\n",
      "Epoch 93/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.4847\n",
      "Epoch 94/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.4793\n",
      "Epoch 95/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.4738\n",
      "Epoch 96/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.4678\n",
      "Epoch 97/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.4611\n",
      "Epoch 98/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.4549\n",
      "Epoch 99/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.1304 - loss: 2.4513\n",
      "Epoch 100/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.4440\n",
      "Epoch 101/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.4397\n",
      "Epoch 102/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.4323\n",
      "Epoch 103/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.4284\n",
      "Epoch 104/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.4214\n",
      "Epoch 105/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.4160\n",
      "Epoch 106/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1739 - loss: 2.4099\n",
      "Epoch 107/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.1304 - loss: 2.4055\n",
      "Epoch 108/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.4001\n",
      "Epoch 109/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.0870 - loss: 2.3950\n",
      "Epoch 110/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.3892\n",
      "Epoch 111/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.3834\n",
      "Epoch 112/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.3777\n",
      "Epoch 113/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.3732\n",
      "Epoch 114/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.3693\n",
      "Epoch 115/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.3637\n",
      "Epoch 116/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.3601\n",
      "Epoch 117/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.3534\n",
      "Epoch 118/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1739 - loss: 2.3486\n",
      "Epoch 119/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.3425\n",
      "Epoch 120/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.3400\n",
      "Epoch 121/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.3341\n",
      "Epoch 122/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.1304 - loss: 2.3310\n",
      "Epoch 123/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.3260\n",
      "Epoch 124/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.3188\n",
      "Epoch 125/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.3147\n",
      "Epoch 126/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1739 - loss: 2.3100\n",
      "Epoch 127/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.1304 - loss: 2.3067\n",
      "Epoch 128/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.1739 - loss: 2.2999\n",
      "Epoch 129/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.2980\n",
      "Epoch 130/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1739 - loss: 2.2916\n",
      "Epoch 131/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.2886\n",
      "Epoch 132/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.2174 - loss: 2.2839\n",
      "Epoch 133/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1739 - loss: 2.2779\n",
      "Epoch 134/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.1304 - loss: 2.2732\n",
      "Epoch 135/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.1739 - loss: 2.2698\n",
      "Epoch 136/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1739 - loss: 2.2660\n",
      "Epoch 137/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1739 - loss: 2.2631\n",
      "Epoch 138/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1739 - loss: 2.2578\n",
      "Epoch 139/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1739 - loss: 2.2530\n",
      "Epoch 140/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1739 - loss: 2.2491\n",
      "Epoch 141/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.1739 - loss: 2.2454\n",
      "Epoch 142/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.1739 - loss: 2.2405\n",
      "Epoch 143/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.2174 - loss: 2.2358\n",
      "Epoch 144/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.2174 - loss: 2.2318\n",
      "Epoch 145/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.2174 - loss: 2.2279\n",
      "Epoch 146/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1739 - loss: 2.2245\n",
      "Epoch 147/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.2174 - loss: 2.2219\n",
      "Epoch 148/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.1739 - loss: 2.2158\n",
      "Epoch 149/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.1739 - loss: 2.2129\n",
      "Epoch 150/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.2609 - loss: 2.2096\n",
      "Epoch 151/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.2609 - loss: 2.2041\n",
      "Epoch 152/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.2609 - loss: 2.2018\n",
      "Epoch 153/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.2609 - loss: 2.1976\n",
      "Epoch 154/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.2609 - loss: 2.1925\n",
      "Epoch 155/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.2174 - loss: 2.1890\n",
      "Epoch 156/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.2174 - loss: 2.1880\n",
      "Epoch 157/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3478 - loss: 2.1818\n",
      "Epoch 158/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.2609 - loss: 2.1779\n",
      "Epoch 159/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.2609 - loss: 2.1743\n",
      "Epoch 160/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.3043 - loss: 2.1709\n",
      "Epoch 161/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.3043 - loss: 2.1684\n",
      "Epoch 162/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.2174 - loss: 2.1654\n",
      "Epoch 163/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.2609 - loss: 2.1619\n",
      "Epoch 164/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.2609 - loss: 2.1582\n",
      "Epoch 165/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.2174 - loss: 2.1549\n",
      "Epoch 166/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.2609 - loss: 2.1508\n",
      "Epoch 167/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.3478 - loss: 2.1472\n",
      "Epoch 168/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3043 - loss: 2.1450\n",
      "Epoch 169/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3043 - loss: 2.1408\n",
      "Epoch 170/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3478 - loss: 2.1361\n",
      "Epoch 171/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.2609 - loss: 2.1352\n",
      "Epoch 172/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.2609 - loss: 2.1297\n",
      "Epoch 173/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.2609 - loss: 2.1274\n",
      "Epoch 174/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3478 - loss: 2.1239\n",
      "Epoch 175/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3478 - loss: 2.1191\n",
      "Epoch 176/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.2609 - loss: 2.1161\n",
      "Epoch 177/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3043 - loss: 2.1142\n",
      "Epoch 178/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.2609 - loss: 2.1092\n",
      "Epoch 179/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.2609 - loss: 2.1064\n",
      "Epoch 180/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.3478 - loss: 2.1025\n",
      "Epoch 181/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3478 - loss: 2.0997\n",
      "Epoch 182/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3043 - loss: 2.0987\n",
      "Epoch 183/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.2609 - loss: 2.0943\n",
      "Epoch 184/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3043 - loss: 2.0926\n",
      "Epoch 185/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.2609 - loss: 2.0889\n",
      "Epoch 186/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.3043 - loss: 2.0846\n",
      "Epoch 187/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3043 - loss: 2.0828\n",
      "Epoch 188/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.2609 - loss: 2.0802\n",
      "Epoch 189/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.3043 - loss: 2.0785\n",
      "Epoch 190/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.3478 - loss: 2.0752\n",
      "Epoch 191/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.2609 - loss: 2.0709\n",
      "Epoch 192/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.2609 - loss: 2.0691\n",
      "Epoch 193/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3043 - loss: 2.0653\n",
      "Epoch 194/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3043 - loss: 2.0647\n",
      "Epoch 195/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.3478 - loss: 2.0577\n",
      "Epoch 196/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.3043 - loss: 2.0550\n",
      "Epoch 197/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3043 - loss: 2.0528\n",
      "Epoch 198/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.3478 - loss: 2.0516\n",
      "Epoch 199/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.2609 - loss: 2.0505\n",
      "Epoch 200/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3478 - loss: 2.0461\n",
      "Epoch 201/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3478 - loss: 2.0416\n",
      "Epoch 202/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.3043 - loss: 2.0395\n",
      "Epoch 203/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3043 - loss: 2.0376\n",
      "Epoch 204/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.3478 - loss: 2.0341\n",
      "Epoch 205/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.2609 - loss: 2.0341\n",
      "Epoch 206/500\n",
      "23/23 - 0s - 8ms/step - accuracy: 0.3478 - loss: 2.0284\n",
      "Epoch 207/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.3478 - loss: 2.0261\n",
      "Epoch 208/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.3478 - loss: 2.0251\n",
      "Epoch 209/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.3913 - loss: 2.0221\n",
      "Epoch 210/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.4348 - loss: 2.0178\n",
      "Epoch 211/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3913 - loss: 2.0158\n",
      "Epoch 212/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.3478 - loss: 2.0142\n",
      "Epoch 213/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.3043 - loss: 2.0107\n",
      "Epoch 214/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.3478 - loss: 2.0072\n",
      "Epoch 215/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.3478 - loss: 2.0058\n",
      "Epoch 216/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3478 - loss: 2.0031\n",
      "Epoch 217/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.3478 - loss: 2.0011\n",
      "Epoch 218/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3478 - loss: 1.9983\n",
      "Epoch 219/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3478 - loss: 1.9972\n",
      "Epoch 220/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.5652 - loss: 1.9934\n",
      "Epoch 221/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.4348 - loss: 1.9924\n",
      "Epoch 222/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.3913 - loss: 1.9881\n",
      "Epoch 223/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3043 - loss: 1.9877\n",
      "Epoch 224/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.3043 - loss: 1.9844\n",
      "Epoch 225/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3913 - loss: 1.9816\n",
      "Epoch 226/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.4783 - loss: 1.9793\n",
      "Epoch 227/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.4348 - loss: 1.9777\n",
      "Epoch 228/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3478 - loss: 1.9748\n",
      "Epoch 229/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.3043 - loss: 1.9728\n",
      "Epoch 230/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3913 - loss: 1.9705\n",
      "Epoch 231/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.3478 - loss: 1.9688\n",
      "Epoch 232/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3913 - loss: 1.9655\n",
      "Epoch 233/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.3913 - loss: 1.9646\n",
      "Epoch 234/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.4348 - loss: 1.9622\n",
      "Epoch 235/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.4348 - loss: 1.9578\n",
      "Epoch 236/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.4783 - loss: 1.9566\n",
      "Epoch 237/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.4348 - loss: 1.9558\n",
      "Epoch 238/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.4783 - loss: 1.9521\n",
      "Epoch 239/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.4783 - loss: 1.9495\n",
      "Epoch 240/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.5217 - loss: 1.9472\n",
      "Epoch 241/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.4783 - loss: 1.9455\n",
      "Epoch 242/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.4783 - loss: 1.9438\n",
      "Epoch 243/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.4348 - loss: 1.9401\n",
      "Epoch 244/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.4348 - loss: 1.9383\n",
      "Epoch 245/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.4783 - loss: 1.9366\n",
      "Epoch 246/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.5652 - loss: 1.9345\n",
      "Epoch 247/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.4348 - loss: 1.9335\n",
      "Epoch 248/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.4783 - loss: 1.9301\n",
      "Epoch 249/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.5217 - loss: 1.9286\n",
      "Epoch 250/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.5217 - loss: 1.9270\n",
      "Epoch 251/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.4783 - loss: 1.9237\n",
      "Epoch 252/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.5652 - loss: 1.9217\n",
      "Epoch 253/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6087 - loss: 1.9201\n",
      "Epoch 254/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.4348 - loss: 1.9188\n",
      "Epoch 255/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6087 - loss: 1.9177\n",
      "Epoch 256/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.5217 - loss: 1.9155\n",
      "Epoch 257/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.3913 - loss: 1.9126\n",
      "Epoch 258/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.4348 - loss: 1.9095\n",
      "Epoch 259/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.5217 - loss: 1.9112\n",
      "Epoch 260/500\n",
      "23/23 - -1s - -23271us/step - accuracy: 0.5652 - loss: 1.9060\n",
      "Epoch 261/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.4783 - loss: 1.9048\n",
      "Epoch 262/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.4783 - loss: 1.9021\n",
      "Epoch 263/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.4783 - loss: 1.8991\n",
      "Epoch 264/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6087 - loss: 1.8989\n",
      "Epoch 265/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.5217 - loss: 1.8970\n",
      "Epoch 266/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.5652 - loss: 1.8941\n",
      "Epoch 267/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.5652 - loss: 1.8914\n",
      "Epoch 268/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6087 - loss: 1.8895\n",
      "Epoch 269/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.5217 - loss: 1.8878\n",
      "Epoch 270/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6087 - loss: 1.8870\n",
      "Epoch 271/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6087 - loss: 1.8836\n",
      "Epoch 272/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.5652 - loss: 1.8845\n",
      "Epoch 273/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.5652 - loss: 1.8816\n",
      "Epoch 274/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6087 - loss: 1.8777\n",
      "Epoch 275/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6087 - loss: 1.8763\n",
      "Epoch 276/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.5652 - loss: 1.8743\n",
      "Epoch 277/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6087 - loss: 1.8731\n",
      "Epoch 278/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6087 - loss: 1.8724\n",
      "Epoch 279/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6522 - loss: 1.8685\n",
      "Epoch 280/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6522 - loss: 1.8680\n",
      "Epoch 281/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6522 - loss: 1.8662\n",
      "Epoch 282/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6522 - loss: 1.8619\n",
      "Epoch 283/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6087 - loss: 1.8606\n",
      "Epoch 284/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6087 - loss: 1.8610\n",
      "Epoch 285/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6087 - loss: 1.8596\n",
      "Epoch 286/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.5652 - loss: 1.8577\n",
      "Epoch 287/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6087 - loss: 1.8557\n",
      "Epoch 288/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6522 - loss: 1.8511\n",
      "Epoch 289/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.6087 - loss: 1.8532\n",
      "Epoch 290/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6087 - loss: 1.8507\n",
      "Epoch 291/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.5652 - loss: 1.8482\n",
      "Epoch 292/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.5652 - loss: 1.8467\n",
      "Epoch 293/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.5652 - loss: 1.8450\n",
      "Epoch 294/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6522 - loss: 1.8455\n",
      "Epoch 295/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6087 - loss: 1.8430\n",
      "Epoch 296/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.5217 - loss: 1.8405\n",
      "Epoch 297/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6522 - loss: 1.8377\n",
      "Epoch 298/500\n",
      "23/23 - 0s - 4ms/step - accuracy: 0.5217 - loss: 1.8346\n",
      "Epoch 299/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6087 - loss: 1.8357\n",
      "Epoch 300/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6087 - loss: 1.8322\n",
      "Epoch 301/500\n",
      "23/23 - 0s - 4ms/step - accuracy: 0.5652 - loss: 1.8314\n",
      "Epoch 302/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6522 - loss: 1.8300\n",
      "Epoch 303/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6522 - loss: 1.8268\n",
      "Epoch 304/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6087 - loss: 1.8271\n",
      "Epoch 305/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6522 - loss: 1.8248\n",
      "Epoch 306/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6087 - loss: 1.8246\n",
      "Epoch 307/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.6522 - loss: 1.8220\n",
      "Epoch 308/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6087 - loss: 1.8195\n",
      "Epoch 309/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6522 - loss: 1.8205\n",
      "Epoch 310/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7391 - loss: 1.8166\n",
      "Epoch 311/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6522 - loss: 1.8145\n",
      "Epoch 312/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6522 - loss: 1.8128\n",
      "Epoch 313/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6957 - loss: 1.8123\n",
      "Epoch 314/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6522 - loss: 1.8111\n",
      "Epoch 315/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6522 - loss: 1.8098\n",
      "Epoch 316/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.5652 - loss: 1.8061\n",
      "Epoch 317/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6522 - loss: 1.8054\n",
      "Epoch 318/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6522 - loss: 1.8020\n",
      "Epoch 319/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6522 - loss: 1.8004\n",
      "Epoch 320/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.5652 - loss: 1.8013\n",
      "Epoch 321/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6522 - loss: 1.7991\n",
      "Epoch 322/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6522 - loss: 1.7968\n",
      "Epoch 323/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6087 - loss: 1.7952\n",
      "Epoch 324/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6087 - loss: 1.7953\n",
      "Epoch 325/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6087 - loss: 1.7937\n",
      "Epoch 326/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.7903\n",
      "Epoch 327/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6957 - loss: 1.7880\n",
      "Epoch 328/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6522 - loss: 1.7895\n",
      "Epoch 329/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6522 - loss: 1.7844\n",
      "Epoch 330/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6087 - loss: 1.7866\n",
      "Epoch 331/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6522 - loss: 1.7824\n",
      "Epoch 332/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.7391 - loss: 1.7812\n",
      "Epoch 333/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6957 - loss: 1.7831\n",
      "Epoch 334/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6957 - loss: 1.7814\n",
      "Epoch 335/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6087 - loss: 1.7794\n",
      "Epoch 336/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6957 - loss: 1.7763\n",
      "Epoch 337/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6957 - loss: 1.7734\n",
      "Epoch 338/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6522 - loss: 1.7727\n",
      "Epoch 339/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6522 - loss: 1.7727\n",
      "Epoch 340/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.7706\n",
      "Epoch 341/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6087 - loss: 1.7686\n",
      "Epoch 342/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6522 - loss: 1.7650\n",
      "Epoch 343/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.7677\n",
      "Epoch 344/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6957 - loss: 1.7651\n",
      "Epoch 345/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.7627\n",
      "Epoch 346/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.7598\n",
      "Epoch 347/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6522 - loss: 1.7598\n",
      "Epoch 348/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6522 - loss: 1.7565\n",
      "Epoch 349/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6087 - loss: 1.7593\n",
      "Epoch 350/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 1.7564\n",
      "Epoch 351/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.7549\n",
      "Epoch 352/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6957 - loss: 1.7527\n",
      "Epoch 353/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7391 - loss: 1.7538\n",
      "Epoch 354/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6957 - loss: 1.7512\n",
      "Epoch 355/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6957 - loss: 1.7485\n",
      "Epoch 356/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6522 - loss: 1.7494\n",
      "Epoch 357/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6522 - loss: 1.7452\n",
      "Epoch 358/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6957 - loss: 1.7420\n",
      "Epoch 359/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6087 - loss: 1.7428\n",
      "Epoch 360/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6522 - loss: 1.7435\n",
      "Epoch 361/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6957 - loss: 1.7407\n",
      "Epoch 362/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6087 - loss: 1.7401\n",
      "Epoch 363/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6522 - loss: 1.7375\n",
      "Epoch 364/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.7366\n",
      "Epoch 365/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6957 - loss: 1.7377\n",
      "Epoch 366/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.7338\n",
      "Epoch 367/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7391 - loss: 1.7325\n",
      "Epoch 368/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6522 - loss: 1.7313\n",
      "Epoch 369/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.7303\n",
      "Epoch 370/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6522 - loss: 1.7296\n",
      "Epoch 371/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6957 - loss: 1.7256\n",
      "Epoch 372/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6957 - loss: 1.7265\n",
      "Epoch 373/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7391 - loss: 1.7249\n",
      "Epoch 374/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.7208\n",
      "Epoch 375/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.7203\n",
      "Epoch 376/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.7199\n",
      "Epoch 377/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.7183\n",
      "Epoch 378/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.7183\n",
      "Epoch 379/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6957 - loss: 1.7159\n",
      "Epoch 380/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6957 - loss: 1.7149\n",
      "Epoch 381/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6957 - loss: 1.7141\n",
      "Epoch 382/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.7115\n",
      "Epoch 383/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6957 - loss: 1.7115\n",
      "Epoch 384/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.7084\n",
      "Epoch 385/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.7093\n",
      "Epoch 386/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6957 - loss: 1.7085\n",
      "Epoch 387/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.7047\n",
      "Epoch 388/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6957 - loss: 1.7033\n",
      "Epoch 389/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.7022\n",
      "Epoch 390/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.7020\n",
      "Epoch 391/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.7003\n",
      "Epoch 392/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.6991\n",
      "Epoch 393/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.6987\n",
      "Epoch 394/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.6975\n",
      "Epoch 395/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7391 - loss: 1.6954\n",
      "Epoch 396/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.6938\n",
      "Epoch 397/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.6932\n",
      "Epoch 398/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.6931\n",
      "Epoch 399/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.6916\n",
      "Epoch 400/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.7826 - loss: 1.6895\n",
      "Epoch 401/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.6907\n",
      "Epoch 402/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.6893\n",
      "Epoch 403/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.6858\n",
      "Epoch 404/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.6845\n",
      "Epoch 405/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7391 - loss: 1.6829\n",
      "Epoch 406/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7391 - loss: 1.6819\n",
      "Epoch 407/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6522 - loss: 1.6820\n",
      "Epoch 408/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.6795\n",
      "Epoch 409/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.6782\n",
      "Epoch 410/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.6767\n",
      "Epoch 411/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8696 - loss: 1.6752\n",
      "Epoch 412/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.6763\n",
      "Epoch 413/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7826 - loss: 1.6755\n",
      "Epoch 414/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.6734\n",
      "Epoch 415/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6957 - loss: 1.6729\n",
      "Epoch 416/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.6691\n",
      "Epoch 417/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.6714\n",
      "Epoch 418/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.6692\n",
      "Epoch 419/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 1.6667\n",
      "Epoch 420/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.6653\n",
      "Epoch 421/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.6659\n",
      "Epoch 422/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6957 - loss: 1.6640\n",
      "Epoch 423/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.6620\n",
      "Epoch 424/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.6631\n",
      "Epoch 425/500\n",
      "23/23 - 0s - 8ms/step - accuracy: 0.7826 - loss: 1.6585\n",
      "Epoch 426/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.6608\n",
      "Epoch 427/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.6583\n",
      "Epoch 428/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.6566\n",
      "Epoch 429/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.6568\n",
      "Epoch 430/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.6548\n",
      "Epoch 431/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.6551\n",
      "Epoch 432/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7826 - loss: 1.6550\n",
      "Epoch 433/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 1.6524\n",
      "Epoch 434/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.6517\n",
      "Epoch 435/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.6472\n",
      "Epoch 436/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.6492\n",
      "Epoch 437/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.6475\n",
      "Epoch 438/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.6466\n",
      "Epoch 439/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7826 - loss: 1.6473\n",
      "Epoch 440/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 1.6458\n",
      "Epoch 441/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.6431\n",
      "Epoch 442/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 1.6433\n",
      "Epoch 443/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 1.6414\n",
      "Epoch 444/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.6393\n",
      "Epoch 445/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.6380\n",
      "Epoch 446/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.6378\n",
      "Epoch 447/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.6351\n",
      "Epoch 448/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.6376\n",
      "Epoch 449/500\n",
      "23/23 - 0s - 4ms/step - accuracy: 0.7391 - loss: 1.6341\n",
      "Epoch 450/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.6358\n",
      "Epoch 451/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.6337\n",
      "Epoch 452/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.8696 - loss: 1.6295\n",
      "Epoch 453/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.6294\n",
      "Epoch 454/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.6299\n",
      "Epoch 455/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 1.6288\n",
      "Epoch 456/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7826 - loss: 1.6258\n",
      "Epoch 457/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7391 - loss: 1.6285\n",
      "Epoch 458/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 1.6270\n",
      "Epoch 459/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.6248\n",
      "Epoch 460/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.6266\n",
      "Epoch 461/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7826 - loss: 1.6193\n",
      "Epoch 462/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.6191\n",
      "Epoch 463/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 1.6189\n",
      "Epoch 464/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.6189\n",
      "Epoch 465/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.6173\n",
      "Epoch 466/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.6170\n",
      "Epoch 467/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.6168\n",
      "Epoch 468/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.6149\n",
      "Epoch 469/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.6159\n",
      "Epoch 470/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.6138\n",
      "Epoch 471/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.6116\n",
      "Epoch 472/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.6147\n",
      "Epoch 473/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.6090\n",
      "Epoch 474/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 1.6101\n",
      "Epoch 475/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8696 - loss: 1.6082\n",
      "Epoch 476/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7826 - loss: 1.6098\n",
      "Epoch 477/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7826 - loss: 1.6054\n",
      "Epoch 478/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 1.6037\n",
      "Epoch 479/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8696 - loss: 1.6048\n",
      "Epoch 480/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.6059\n",
      "Epoch 481/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.6017\n",
      "Epoch 482/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8696 - loss: 1.6037\n",
      "Epoch 483/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.6017\n",
      "Epoch 484/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.6001\n",
      "Epoch 485/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8696 - loss: 1.5993\n",
      "Epoch 486/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7826 - loss: 1.5947\n",
      "Epoch 487/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7391 - loss: 1.5973\n",
      "Epoch 488/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 1.5963\n",
      "Epoch 489/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7826 - loss: 1.5948\n",
      "Epoch 490/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.5930\n",
      "Epoch 491/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7826 - loss: 1.5934\n",
      "Epoch 492/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.5910\n",
      "Epoch 493/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.5893\n",
      "Epoch 494/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8696 - loss: 1.5924\n",
      "Epoch 495/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.8261 - loss: 1.5889\n",
      "Epoch 496/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 1.5898\n",
      "Epoch 497/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.5874\n",
      "Epoch 498/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7826 - loss: 1.5872\n",
      "Epoch 499/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8696 - loss: 1.5848\n",
      "Epoch 500/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 1.5829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f373a9c3d50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X, y, epochs=500, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP5. 評估模型準確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 86.96%\n"
     ]
    }
   ],
   "source": [
    "# 評估模型的性能\n",
    "scores = model.evaluate(X, y, verbose=0)\n",
    "print(\"Model Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP6. 預測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C'] -> D\n",
      "['B', 'C', 'D'] -> E\n",
      "['C', 'D', 'E'] -> F\n",
      "['D', 'E', 'F'] -> G\n",
      "['E', 'F', 'G'] -> H\n",
      "['F', 'G', 'H'] -> I\n",
      "['G', 'H', 'I'] -> J\n",
      "['H', 'I', 'J'] -> K\n",
      "['I', 'J', 'K'] -> L\n",
      "['J', 'K', 'L'] -> M\n",
      "['K', 'L', 'M'] -> N\n",
      "['L', 'M', 'N'] -> O\n",
      "['M', 'N', 'O'] -> P\n",
      "['N', 'O', 'P'] -> Q\n",
      "['O', 'P', 'Q'] -> R\n",
      "['P', 'Q', 'R'] -> S\n",
      "['Q', 'R', 'S'] -> T\n",
      "['R', 'S', 'T'] -> U\n",
      "['S', 'T', 'U'] -> V\n",
      "['T', 'U', 'V'] -> Y\n",
      "['U', 'V', 'W'] -> Z\n",
      "['V', 'W', 'X'] -> Z\n",
      "['W', 'X', 'Y'] -> Z\n"
     ]
    }
   ],
   "source": [
    "# 展示一些模型預測\n",
    "for pattern in dataX:\n",
    "    x = numpy.reshape(pattern, (1, 1, len(pattern)))\n",
    "    x = x / float(len(alphabet))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    print(seq_in, \"->\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型 3. LSTM 學習三個字符的時間步驟窗口(Three-Char Time Step Window)到一個字符的映射"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP1. 準備訓練用資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABC -> D\n",
      "BCD -> E\n",
      "CDE -> F\n",
      "DEF -> G\n",
      "EFG -> H\n",
      "FGH -> I\n",
      "GHI -> J\n",
      "HIJ -> K\n",
      "IJK -> L\n",
      "JKL -> M\n",
      "KLM -> N\n",
      "LMN -> O\n",
      "MNO -> P\n",
      "NOP -> Q\n",
      "OPQ -> R\n",
      "PQR -> S\n",
      "QRS -> T\n",
      "RST -> U\n",
      "STU -> V\n",
      "TUV -> W\n",
      "UVW -> X\n",
      "VWX -> Y\n",
      "WXY -> Z\n"
     ]
    }
   ],
   "source": [
    "seq_length = 3\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, len(alphabet) - seq_length, 1):\n",
    "    seq_in = alphabet[i : i + seq_length]\n",
    "    seq_out = alphabet[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "    print(seq_in, \"->\", seq_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP2. 資料預處理\n",
    "\n",
    "\n",
    "> ABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
    "\n",
    "> 例如: \n",
    "\n",
    "> 給 HIJ -> 預測 K\n",
    "\n",
    "> 給 EFG -> 預測 H\n",
    "\n",
    "目標訓練張量結構: (samples, time_steps, features) -> (n , **3**, **1** )\n",
    "\n",
    "準備訓練資料集的時候要把資料的張量結構轉換成, 1筆訓練資料有\"3\"個時間步, 裡頭存放著\"1\"個字符的資料\"features\"向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 重塑 X 資料的維度成為 (samples, time_steps, features)\n",
    "X = numpy.reshape(dataX, (len(dataX), seq_length, 1))  # <-- 特別注意這裡\n",
    "\n",
    "# 歸一化\n",
    "X = X / float(len(alphabet))\n",
    "\n",
    "# 使用one hot encode 對Y值進行編碼\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP3. 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">858</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │           \u001b[38;5;34m858\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,210</span> (20.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,210\u001b[0m (20.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,210</span> (20.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,210\u001b[0m (20.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 創建模型\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(X.shape[1], X.shape[2])))  # <-- 特別注意這裡\n",
    "model.add(Dense(y.shape[1], activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP4. 定義訓練並進行訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "23/23 - 1s - 45ms/step - accuracy: 0.0435 - loss: 3.2642\n",
      "Epoch 2/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0000e+00 - loss: 3.2476\n",
      "Epoch 3/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0435 - loss: 3.2399\n",
      "Epoch 4/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.2321\n",
      "Epoch 5/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0435 - loss: 3.2233\n",
      "Epoch 6/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.2141\n",
      "Epoch 7/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.2058\n",
      "Epoch 8/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.1942\n",
      "Epoch 9/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.1821\n",
      "Epoch 10/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.1705\n",
      "Epoch 11/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.1572\n",
      "Epoch 12/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.1432\n",
      "Epoch 13/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0435 - loss: 3.1278\n",
      "Epoch 14/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.1132\n",
      "Epoch 15/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.0971\n",
      "Epoch 16/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0435 - loss: 3.0843\n",
      "Epoch 17/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0435 - loss: 3.0680\n",
      "Epoch 18/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0435 - loss: 3.0519\n",
      "Epoch 19/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.0410\n",
      "Epoch 20/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.0202\n",
      "Epoch 21/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 3.0068\n",
      "Epoch 22/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0435 - loss: 2.9838\n",
      "Epoch 23/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.9661\n",
      "Epoch 24/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.9426\n",
      "Epoch 25/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.9221\n",
      "Epoch 26/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.8970\n",
      "Epoch 27/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.8695\n",
      "Epoch 28/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.8454\n",
      "Epoch 29/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.8095\n",
      "Epoch 30/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.7786\n",
      "Epoch 31/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.7405\n",
      "Epoch 32/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.7086\n",
      "Epoch 33/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.6742\n",
      "Epoch 34/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.6402\n",
      "Epoch 35/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.6092\n",
      "Epoch 36/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.5795\n",
      "Epoch 37/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.5596\n",
      "Epoch 38/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.5328\n",
      "Epoch 39/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.5072\n",
      "Epoch 40/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.4869\n",
      "Epoch 41/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.4641\n",
      "Epoch 42/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.4399\n",
      "Epoch 43/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.4156\n",
      "Epoch 44/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.3955\n",
      "Epoch 45/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.3736\n",
      "Epoch 46/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.3490\n",
      "Epoch 47/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.3282\n",
      "Epoch 48/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.3066\n",
      "Epoch 49/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.2892\n",
      "Epoch 50/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.0870 - loss: 2.2593\n",
      "Epoch 51/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.0870 - loss: 2.2384\n",
      "Epoch 52/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1739 - loss: 2.2167\n",
      "Epoch 53/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.2001\n",
      "Epoch 54/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1304 - loss: 2.1770\n",
      "Epoch 55/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.1739 - loss: 2.1520\n",
      "Epoch 56/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.2174 - loss: 2.1360\n",
      "Epoch 57/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.2174 - loss: 2.1175\n",
      "Epoch 58/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.2609 - loss: 2.0931\n",
      "Epoch 59/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.2174 - loss: 2.0787\n",
      "Epoch 60/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.2609 - loss: 2.0510\n",
      "Epoch 61/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3478 - loss: 2.0343\n",
      "Epoch 62/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.2609 - loss: 2.0139\n",
      "Epoch 63/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.2609 - loss: 1.9961\n",
      "Epoch 64/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.2609 - loss: 1.9824\n",
      "Epoch 65/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.3043 - loss: 1.9562\n",
      "Epoch 66/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.3913 - loss: 1.9308\n",
      "Epoch 67/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.3478 - loss: 1.9120\n",
      "Epoch 68/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3478 - loss: 1.9004\n",
      "Epoch 69/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3913 - loss: 1.8745\n",
      "Epoch 70/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.3478 - loss: 1.8679\n",
      "Epoch 71/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.3913 - loss: 1.8507\n",
      "Epoch 72/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3478 - loss: 1.8350\n",
      "Epoch 73/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.4348 - loss: 1.8148\n",
      "Epoch 74/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.3478 - loss: 1.8042\n",
      "Epoch 75/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.4348 - loss: 1.7847\n",
      "Epoch 76/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3478 - loss: 1.7844\n",
      "Epoch 77/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3913 - loss: 1.7596\n",
      "Epoch 78/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3478 - loss: 1.7468\n",
      "Epoch 79/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.4348 - loss: 1.7407\n",
      "Epoch 80/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.3913 - loss: 1.7297\n",
      "Epoch 81/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.5217 - loss: 1.7118\n",
      "Epoch 82/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.4348 - loss: 1.7021\n",
      "Epoch 83/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.4783 - loss: 1.6978\n",
      "Epoch 84/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.5652 - loss: 1.6785\n",
      "Epoch 85/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.4348 - loss: 1.6733\n",
      "Epoch 86/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.5652 - loss: 1.6590\n",
      "Epoch 87/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.4783 - loss: 1.6448\n",
      "Epoch 88/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.5652 - loss: 1.6387\n",
      "Epoch 89/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6087 - loss: 1.6249\n",
      "Epoch 90/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.5652 - loss: 1.6228\n",
      "Epoch 91/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.4783 - loss: 1.6170\n",
      "Epoch 92/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.4348 - loss: 1.5991\n",
      "Epoch 93/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.5652 - loss: 1.6007\n",
      "Epoch 94/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.4783 - loss: 1.5943\n",
      "Epoch 95/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6522 - loss: 1.5744\n",
      "Epoch 96/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6522 - loss: 1.5727\n",
      "Epoch 97/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6522 - loss: 1.5598\n",
      "Epoch 98/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.6957 - loss: 1.5540\n",
      "Epoch 99/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6087 - loss: 1.5401\n",
      "Epoch 100/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6087 - loss: 1.5400\n",
      "Epoch 101/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6522 - loss: 1.5310\n",
      "Epoch 102/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6957 - loss: 1.5156\n",
      "Epoch 103/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.6957 - loss: 1.5117\n",
      "Epoch 104/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6957 - loss: 1.5106\n",
      "Epoch 105/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7391 - loss: 1.5071\n",
      "Epoch 106/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6957 - loss: 1.4885\n",
      "Epoch 107/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.6957 - loss: 1.4779\n",
      "Epoch 108/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6957 - loss: 1.4753\n",
      "Epoch 109/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.5652 - loss: 1.4682\n",
      "Epoch 110/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7391 - loss: 1.4607\n",
      "Epoch 111/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7391 - loss: 1.4570\n",
      "Epoch 112/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6957 - loss: 1.4471\n",
      "Epoch 113/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6957 - loss: 1.4364\n",
      "Epoch 114/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.7391 - loss: 1.4319\n",
      "Epoch 115/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7391 - loss: 1.4264\n",
      "Epoch 116/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7391 - loss: 1.4255\n",
      "Epoch 117/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7391 - loss: 1.4158\n",
      "Epoch 118/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7826 - loss: 1.4132\n",
      "Epoch 119/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6957 - loss: 1.4039\n",
      "Epoch 120/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.3860\n",
      "Epoch 121/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 1.3812\n",
      "Epoch 122/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6957 - loss: 1.3785\n",
      "Epoch 123/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6957 - loss: 1.3759\n",
      "Epoch 124/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.8261 - loss: 1.3703\n",
      "Epoch 125/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8696 - loss: 1.3562\n",
      "Epoch 126/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 1.3506\n",
      "Epoch 127/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7826 - loss: 1.3471\n",
      "Epoch 128/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7826 - loss: 1.3428\n",
      "Epoch 129/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.6522 - loss: 1.3492\n",
      "Epoch 130/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7826 - loss: 1.3241\n",
      "Epoch 131/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.3156\n",
      "Epoch 132/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8696 - loss: 1.3091\n",
      "Epoch 133/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 1.3070\n",
      "Epoch 134/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 1.3029\n",
      "Epoch 135/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 1.2888\n",
      "Epoch 136/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7391 - loss: 1.2864\n",
      "Epoch 137/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.2848\n",
      "Epoch 138/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.2842\n",
      "Epoch 139/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 1.2729\n",
      "Epoch 140/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 1.2627\n",
      "Epoch 141/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 1.2611\n",
      "Epoch 142/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.2557\n",
      "Epoch 143/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.2454\n",
      "Epoch 144/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 1.2420\n",
      "Epoch 145/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.2338\n",
      "Epoch 146/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9130 - loss: 1.2306\n",
      "Epoch 147/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 1.2342\n",
      "Epoch 148/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7391 - loss: 1.2269\n",
      "Epoch 149/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 1.2116\n",
      "Epoch 150/500\n",
      "23/23 - 0s - 12ms/step - accuracy: 0.8261 - loss: 1.2059\n",
      "Epoch 151/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 1.2014\n",
      "Epoch 152/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 1.1999\n",
      "Epoch 153/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.8696 - loss: 1.1928\n",
      "Epoch 154/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.8696 - loss: 1.1885\n",
      "Epoch 155/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 1.1808\n",
      "Epoch 156/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 1.1778\n",
      "Epoch 157/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 1.1701\n",
      "Epoch 158/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 1.1666\n",
      "Epoch 159/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.1616\n",
      "Epoch 160/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 1.1581\n",
      "Epoch 161/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 1.1477\n",
      "Epoch 162/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.1425\n",
      "Epoch 163/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 1.1406\n",
      "Epoch 164/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 1.1316\n",
      "Epoch 165/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 1.1308\n",
      "Epoch 166/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 1.1247\n",
      "Epoch 167/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 1.1244\n",
      "Epoch 168/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8696 - loss: 1.1126\n",
      "Epoch 169/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 1.1059\n",
      "Epoch 170/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 1.1082\n",
      "Epoch 171/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 1.1035\n",
      "Epoch 172/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 1.0953\n",
      "Epoch 173/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 1.0897\n",
      "Epoch 174/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.8696 - loss: 1.0952\n",
      "Epoch 175/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 1.0847\n",
      "Epoch 176/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9130 - loss: 1.0780\n",
      "Epoch 177/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 1.0742\n",
      "Epoch 178/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.9130 - loss: 1.0725\n",
      "Epoch 179/500\n",
      "23/23 - 0s - 12ms/step - accuracy: 0.8261 - loss: 1.0660\n",
      "Epoch 180/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.9130 - loss: 1.0597\n",
      "Epoch 181/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 1.0631\n",
      "Epoch 182/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 1.0482\n",
      "Epoch 183/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 1.0554\n",
      "Epoch 184/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 1.0474\n",
      "Epoch 185/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.8696 - loss: 1.0409\n",
      "Epoch 186/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 1.0401\n",
      "Epoch 187/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 1.0250\n",
      "Epoch 188/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8696 - loss: 1.0174\n",
      "Epoch 189/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8696 - loss: 1.0229\n",
      "Epoch 190/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 1.0144\n",
      "Epoch 191/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 1.0145\n",
      "Epoch 192/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 1.0152\n",
      "Epoch 193/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 1.0220\n",
      "Epoch 194/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 1.0096\n",
      "Epoch 195/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 1.0025\n",
      "Epoch 196/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.7826 - loss: 0.9983\n",
      "Epoch 197/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 0.9964\n",
      "Epoch 198/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 0.9828\n",
      "Epoch 199/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9130 - loss: 0.9869\n",
      "Epoch 200/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.9763\n",
      "Epoch 201/500\n",
      "23/23 - -1s - -22685us/step - accuracy: 0.9565 - loss: 0.9783\n",
      "Epoch 202/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 0.9693\n",
      "Epoch 203/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.9663\n",
      "Epoch 204/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8696 - loss: 0.9563\n",
      "Epoch 205/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8696 - loss: 0.9604\n",
      "Epoch 206/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.9535\n",
      "Epoch 207/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.9449\n",
      "Epoch 208/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.9499\n",
      "Epoch 209/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.9390\n",
      "Epoch 210/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.9351\n",
      "Epoch 211/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8696 - loss: 0.9355\n",
      "Epoch 212/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9130 - loss: 0.9288\n",
      "Epoch 213/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8696 - loss: 0.9272\n",
      "Epoch 214/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.9236\n",
      "Epoch 215/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.9565 - loss: 0.9149\n",
      "Epoch 216/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.9130 - loss: 0.9142\n",
      "Epoch 217/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.9197\n",
      "Epoch 218/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.9045\n",
      "Epoch 219/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.9095\n",
      "Epoch 220/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.8999\n",
      "Epoch 221/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.8987\n",
      "Epoch 222/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 0.8873\n",
      "Epoch 223/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.8789\n",
      "Epoch 224/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.8815\n",
      "Epoch 225/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8696 - loss: 0.8758\n",
      "Epoch 226/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.8700\n",
      "Epoch 227/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.8690\n",
      "Epoch 228/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.8670\n",
      "Epoch 229/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.8603\n",
      "Epoch 230/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.9565 - loss: 0.8613\n",
      "Epoch 231/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.9130 - loss: 0.8626\n",
      "Epoch 232/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.8540\n",
      "Epoch 233/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.8510\n",
      "Epoch 234/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9130 - loss: 0.8432\n",
      "Epoch 235/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.8395\n",
      "Epoch 236/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.8417\n",
      "Epoch 237/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.8362\n",
      "Epoch 238/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.8345\n",
      "Epoch 239/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.8338\n",
      "Epoch 240/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.8318\n",
      "Epoch 241/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.8198\n",
      "Epoch 242/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.8212\n",
      "Epoch 243/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.8175\n",
      "Epoch 244/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.9130 - loss: 0.8091\n",
      "Epoch 245/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.9130 - loss: 0.8109\n",
      "Epoch 246/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.9565 - loss: 0.8039\n",
      "Epoch 247/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.8008\n",
      "Epoch 248/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.9130 - loss: 0.8074\n",
      "Epoch 249/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 0.7947\n",
      "Epoch 250/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.7934\n",
      "Epoch 251/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.7911\n",
      "Epoch 252/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.7957\n",
      "Epoch 253/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.7942\n",
      "Epoch 254/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.7766\n",
      "Epoch 255/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9130 - loss: 0.7742\n",
      "Epoch 256/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.9565 - loss: 0.7756\n",
      "Epoch 257/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.7683\n",
      "Epoch 258/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.7645\n",
      "Epoch 259/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.7553\n",
      "Epoch 260/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.7552\n",
      "Epoch 261/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.7504\n",
      "Epoch 262/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.7520\n",
      "Epoch 263/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.7499\n",
      "Epoch 264/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.7429\n",
      "Epoch 265/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 0.7427\n",
      "Epoch 266/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.7393\n",
      "Epoch 267/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.7343\n",
      "Epoch 268/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.7312\n",
      "Epoch 269/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.7387\n",
      "Epoch 270/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9130 - loss: 0.7224\n",
      "Epoch 271/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8696 - loss: 0.7261\n",
      "Epoch 272/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.7163\n",
      "Epoch 273/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.7148\n",
      "Epoch 274/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9130 - loss: 0.7093\n",
      "Epoch 275/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.7058\n",
      "Epoch 276/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9130 - loss: 0.7106\n",
      "Epoch 277/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.7087\n",
      "Epoch 278/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.7079\n",
      "Epoch 279/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.6993\n",
      "Epoch 280/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.6879\n",
      "Epoch 281/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.6938\n",
      "Epoch 282/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.6894\n",
      "Epoch 283/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.6828\n",
      "Epoch 284/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.6739\n",
      "Epoch 285/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9130 - loss: 0.6790\n",
      "Epoch 286/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.6759\n",
      "Epoch 287/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.6700\n",
      "Epoch 288/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.6630\n",
      "Epoch 289/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.6649\n",
      "Epoch 290/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.6675\n",
      "Epoch 291/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.6653\n",
      "Epoch 292/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.6594\n",
      "Epoch 293/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.6566\n",
      "Epoch 294/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.6574\n",
      "Epoch 295/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.6458\n",
      "Epoch 296/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.6454\n",
      "Epoch 297/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.6397\n",
      "Epoch 298/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.6406\n",
      "Epoch 299/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.6402\n",
      "Epoch 300/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.6354\n",
      "Epoch 301/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.6302\n",
      "Epoch 302/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.6332\n",
      "Epoch 303/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.6369\n",
      "Epoch 304/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.6222\n",
      "Epoch 305/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.9565 - loss: 0.6250\n",
      "Epoch 306/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.6200\n",
      "Epoch 307/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.6147\n",
      "Epoch 308/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.6191\n",
      "Epoch 309/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.6103\n",
      "Epoch 310/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.6116\n",
      "Epoch 311/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.6082\n",
      "Epoch 312/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.5995\n",
      "Epoch 313/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.6042\n",
      "Epoch 314/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.9565 - loss: 0.5928\n",
      "Epoch 315/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.5942\n",
      "Epoch 316/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.5944\n",
      "Epoch 317/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.9565 - loss: 0.5925\n",
      "Epoch 318/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.5919\n",
      "Epoch 319/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.5924\n",
      "Epoch 320/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.5854\n",
      "Epoch 321/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.5842\n",
      "Epoch 322/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.5812\n",
      "Epoch 323/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.5764\n",
      "Epoch 324/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.5810\n",
      "Epoch 325/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.5783\n",
      "Epoch 326/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.5721\n",
      "Epoch 327/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.5621\n",
      "Epoch 328/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.5647\n",
      "Epoch 329/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.5563\n",
      "Epoch 330/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.5569\n",
      "Epoch 331/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.5542\n",
      "Epoch 332/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.5495\n",
      "Epoch 333/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.5514\n",
      "Epoch 334/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.5508\n",
      "Epoch 335/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.5490\n",
      "Epoch 336/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.5468\n",
      "Epoch 337/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.9565 - loss: 0.5394\n",
      "Epoch 338/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.9565 - loss: 0.5363\n",
      "Epoch 339/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.5404\n",
      "Epoch 340/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.9565 - loss: 0.5430\n",
      "Epoch 341/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.5351\n",
      "Epoch 342/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.5286\n",
      "Epoch 343/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.5252\n",
      "Epoch 344/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.5268\n",
      "Epoch 345/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9130 - loss: 0.5192\n",
      "Epoch 346/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.5233\n",
      "Epoch 347/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.5160\n",
      "Epoch 348/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.5129\n",
      "Epoch 349/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.5109\n",
      "Epoch 350/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.9565 - loss: 0.5169\n",
      "Epoch 351/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.5109\n",
      "Epoch 352/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.5046\n",
      "Epoch 353/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.5078\n",
      "Epoch 354/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.5048\n",
      "Epoch 355/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.5012\n",
      "Epoch 356/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.4969\n",
      "Epoch 357/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.4952\n",
      "Epoch 358/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.4918\n",
      "Epoch 359/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.4947\n",
      "Epoch 360/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.4870\n",
      "Epoch 361/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.4887\n",
      "Epoch 362/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.4867\n",
      "Epoch 363/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.4854\n",
      "Epoch 364/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.4875\n",
      "Epoch 365/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9130 - loss: 0.4913\n",
      "Epoch 366/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.4832\n",
      "Epoch 367/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.4797\n",
      "Epoch 368/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.4780\n",
      "Epoch 369/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.4728\n",
      "Epoch 370/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.4677\n",
      "Epoch 371/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.4712\n",
      "Epoch 372/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.4656\n",
      "Epoch 373/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.4673\n",
      "Epoch 374/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.4584\n",
      "Epoch 375/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.4615\n",
      "Epoch 376/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.4551\n",
      "Epoch 377/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.4538\n",
      "Epoch 378/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.4509\n",
      "Epoch 379/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.4544\n",
      "Epoch 380/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.4595\n",
      "Epoch 381/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.4604\n",
      "Epoch 382/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.4566\n",
      "Epoch 383/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.8261 - loss: 0.5607\n",
      "Epoch 384/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8261 - loss: 0.5373\n",
      "Epoch 385/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.7826 - loss: 0.6197\n",
      "Epoch 386/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8696 - loss: 0.4874\n",
      "Epoch 387/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.8696 - loss: 0.4562\n",
      "Epoch 388/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.4445\n",
      "Epoch 389/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.4398\n",
      "Epoch 390/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.4386\n",
      "Epoch 391/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.4325\n",
      "Epoch 392/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.4244\n",
      "Epoch 393/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.4247\n",
      "Epoch 394/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.4267\n",
      "Epoch 395/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.4200\n",
      "Epoch 396/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.4177\n",
      "Epoch 397/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 1.0000 - loss: 0.4171\n",
      "Epoch 398/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.4141\n",
      "Epoch 399/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.4163\n",
      "Epoch 400/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.4122\n",
      "Epoch 401/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.4116\n",
      "Epoch 402/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.4133\n",
      "Epoch 403/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.4084\n",
      "Epoch 404/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.4095\n",
      "Epoch 405/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.4086\n",
      "Epoch 406/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.4032\n",
      "Epoch 407/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.3966\n",
      "Epoch 408/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.4009\n",
      "Epoch 409/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.3979\n",
      "Epoch 410/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.3944\n",
      "Epoch 411/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.3956\n",
      "Epoch 412/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.3955\n",
      "Epoch 413/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.3910\n",
      "Epoch 414/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.3923\n",
      "Epoch 415/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.3866\n",
      "Epoch 416/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.3850\n",
      "Epoch 417/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.3892\n",
      "Epoch 418/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.3844\n",
      "Epoch 419/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.3842\n",
      "Epoch 420/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.3824\n",
      "Epoch 421/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.3802\n",
      "Epoch 422/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.3759\n",
      "Epoch 423/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.3763\n",
      "Epoch 424/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.3759\n",
      "Epoch 425/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.3719\n",
      "Epoch 426/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.3754\n",
      "Epoch 427/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.3787\n",
      "Epoch 428/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.3704\n",
      "Epoch 429/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.3650\n",
      "Epoch 430/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.3649\n",
      "Epoch 431/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.3661\n",
      "Epoch 432/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.3602\n",
      "Epoch 433/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.3640\n",
      "Epoch 434/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.3607\n",
      "Epoch 435/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.3582\n",
      "Epoch 436/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.3545\n",
      "Epoch 437/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.3515\n",
      "Epoch 438/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.3550\n",
      "Epoch 439/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.3485\n",
      "Epoch 440/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.3509\n",
      "Epoch 441/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.3531\n",
      "Epoch 442/500\n",
      "23/23 - -1s - -24873us/step - accuracy: 1.0000 - loss: 0.3502\n",
      "Epoch 443/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.3453\n",
      "Epoch 444/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.3475\n",
      "Epoch 445/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.9565 - loss: 0.3461\n",
      "Epoch 446/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.3466\n",
      "Epoch 447/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.3433\n",
      "Epoch 448/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.3378\n",
      "Epoch 449/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.3387\n",
      "Epoch 450/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.3424\n",
      "Epoch 451/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.3370\n",
      "Epoch 452/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.3364\n",
      "Epoch 453/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.3321\n",
      "Epoch 454/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.3325\n",
      "Epoch 455/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.3301\n",
      "Epoch 456/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.3277\n",
      "Epoch 457/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.3279\n",
      "Epoch 458/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.3304\n",
      "Epoch 459/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.3253\n",
      "Epoch 460/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.3258\n",
      "Epoch 461/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.3255\n",
      "Epoch 462/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.3191\n",
      "Epoch 463/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.3185\n",
      "Epoch 464/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.3210\n",
      "Epoch 465/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.3209\n",
      "Epoch 466/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.3163\n",
      "Epoch 467/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.3163\n",
      "Epoch 468/500\n",
      "23/23 - 0s - 13ms/step - accuracy: 1.0000 - loss: 0.3150\n",
      "Epoch 469/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 0.9565 - loss: 0.3118\n",
      "Epoch 470/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.3113\n",
      "Epoch 471/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.3110\n",
      "Epoch 472/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.3153\n",
      "Epoch 473/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.3102\n",
      "Epoch 474/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.3038\n",
      "Epoch 475/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.3036\n",
      "Epoch 476/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.3058\n",
      "Epoch 477/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.3055\n",
      "Epoch 478/500\n",
      "23/23 - 0s - 7ms/step - accuracy: 1.0000 - loss: 0.3006\n",
      "Epoch 479/500\n",
      "23/23 - 0s - 12ms/step - accuracy: 0.9565 - loss: 0.3021\n",
      "Epoch 480/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.2998\n",
      "Epoch 481/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.3039\n",
      "Epoch 482/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.2987\n",
      "Epoch 483/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.3018\n",
      "Epoch 484/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.2981\n",
      "Epoch 485/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.2942\n",
      "Epoch 486/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.2935\n",
      "Epoch 487/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.2958\n",
      "Epoch 488/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.2889\n",
      "Epoch 489/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.2930\n",
      "Epoch 490/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.2895\n",
      "Epoch 491/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.2896\n",
      "Epoch 492/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.2882\n",
      "Epoch 493/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.2983\n",
      "Epoch 494/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.2924\n",
      "Epoch 495/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.2898\n",
      "Epoch 496/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 0.9565 - loss: 0.2842\n",
      "Epoch 497/500\n",
      "23/23 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.2816\n",
      "Epoch 498/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 0.9565 - loss: 0.2789\n",
      "Epoch 499/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.2827\n",
      "Epoch 500/500\n",
      "23/23 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.2827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f3709383c90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X, y, epochs=500, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP5. 評估模型準確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# 評估模型的性能\n",
    "scores = model.evaluate(X, y, verbose=0)\n",
    "print(\"Model Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP6. 預測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C'] -> D\n",
      "['B', 'C', 'D'] -> E\n",
      "['C', 'D', 'E'] -> F\n",
      "['D', 'E', 'F'] -> G\n",
      "['E', 'F', 'G'] -> H\n",
      "['F', 'G', 'H'] -> I\n",
      "['G', 'H', 'I'] -> J\n",
      "['H', 'I', 'J'] -> K\n",
      "['I', 'J', 'K'] -> L\n",
      "['J', 'K', 'L'] -> M\n",
      "['K', 'L', 'M'] -> N\n",
      "['L', 'M', 'N'] -> O\n",
      "['M', 'N', 'O'] -> P\n",
      "['N', 'O', 'P'] -> Q\n",
      "['O', 'P', 'Q'] -> R\n",
      "['P', 'Q', 'R'] -> S\n",
      "['Q', 'R', 'S'] -> T\n",
      "['R', 'S', 'T'] -> U\n",
      "['S', 'T', 'U'] -> V\n",
      "['T', 'U', 'V'] -> W\n",
      "['U', 'V', 'W'] -> X\n",
      "['V', 'W', 'X'] -> Y\n",
      "['W', 'X', 'Y'] -> Z\n"
     ]
    }
   ],
   "source": [
    "# 讓我們擷取3個字符轉成張量結構 shape:(1,3,1)來進行infer\n",
    "for pattern in dataX:\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(len(alphabet))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    print(seq_in, \"->\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型 4. LSTM學習可變長度字符輸入到單字符輸出\n",
    "\n",
    "讓我們建立一個模型，來接受\"變動字母序列(variable-length)\"的輸入來預測下一個字母。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP1. 準備訓練用資料\n",
    "\n",
    "為了簡化，我們將定義一個最大輸入序列長度(比如說\"5\", 代表輸入的序列可以是 1 ~ 5)，以加速訓練。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PQRST -> U\n",
      "W -> X\n",
      "O -> P\n",
      "OPQ -> R\n",
      "IJKLM -> N\n",
      "QRSTU -> V\n",
      "ABCD -> E\n",
      "X -> Y\n",
      "GHIJ -> K\n",
      "M -> N\n",
      "XY -> Z\n",
      "QRST -> U\n",
      "ABC -> D\n",
      "JKLMN -> O\n",
      "OP -> Q\n",
      "XY -> Z\n",
      "D -> E\n",
      "T -> U\n",
      "B -> C\n",
      "QRSTU -> V\n",
      "HIJ -> K\n",
      "JKLM -> N\n",
      "ABCDE -> F\n",
      "X -> Y\n",
      "V -> W\n",
      "DE -> F\n",
      "DEFG -> H\n",
      "BCDE -> F\n",
      "EFGH -> I\n",
      "BCDE -> F\n",
      "FG -> H\n",
      "RST -> U\n",
      "TUV -> W\n",
      "STUV -> W\n",
      "LMN -> O\n",
      "P -> Q\n",
      "MNOP -> Q\n",
      "JK -> L\n",
      "MNOP -> Q\n",
      "OPQRS -> T\n",
      "UVWXY -> Z\n",
      "PQRS -> T\n",
      "D -> E\n",
      "EFGH -> I\n",
      "IJK -> L\n",
      "WX -> Y\n",
      "STUV -> W\n",
      "MNOPQ -> R\n",
      "P -> Q\n",
      "WXY -> Z\n",
      "VWX -> Y\n",
      "V -> W\n",
      "HI -> J\n",
      "KLMNO -> P\n",
      "UV -> W\n",
      "JKL -> M\n",
      "ABCDE -> F\n",
      "WXY -> Z\n",
      "M -> N\n",
      "CDEF -> G\n",
      "KLMNO -> P\n",
      "RST -> U\n",
      "RS -> T\n",
      "W -> X\n",
      "J -> K\n",
      "WX -> Y\n",
      "JKLMN -> O\n",
      "MN -> O\n",
      "L -> M\n",
      "BCDE -> F\n",
      "TU -> V\n",
      "MNOPQ -> R\n",
      "NOPQR -> S\n",
      "HIJ -> K\n",
      "JKLM -> N\n",
      "STUVW -> X\n",
      "QRST -> U\n",
      "N -> O\n",
      "VWXY -> Z\n",
      "B -> C\n",
      "UVWX -> Y\n",
      "OP -> Q\n",
      "K -> L\n",
      "C -> D\n",
      "X -> Y\n",
      "ST -> U\n",
      "JKLM -> N\n",
      "B -> C\n",
      "QR -> S\n",
      "RS -> T\n",
      "VWXY -> Z\n",
      "S -> T\n",
      "NOP -> Q\n",
      "KLMNO -> P\n",
      "IJ -> K\n",
      "EF -> G\n",
      "MNOP -> Q\n",
      "WXY -> Z\n",
      "HI -> J\n",
      "P -> Q\n",
      "STUVW -> X\n",
      "Q -> R\n",
      "MN -> O\n",
      "O -> P\n",
      "C -> D\n",
      "L -> M\n",
      "JKLM -> N\n",
      "K -> L\n",
      "IJKLM -> N\n",
      "FGHIJ -> K\n",
      "LM -> N\n",
      "OPQ -> R\n",
      "U -> V\n",
      "HIJKL -> M\n",
      "PQR -> S\n",
      "S -> T\n",
      "OPQR -> S\n",
      "J -> K\n",
      "DE -> F\n",
      "K -> L\n",
      "BCDE -> F\n",
      "EFGH -> I\n",
      "RSTUV -> W\n",
      "LMNOP -> Q\n",
      "QR -> S\n",
      "ABCDE -> F\n",
      "LM -> N\n",
      "IJKLM -> N\n",
      "B -> C\n",
      "VWX -> Y\n",
      "MNOPQ -> R\n",
      "MNOPQ -> R\n",
      "LM -> N\n",
      "S -> T\n",
      "VWX -> Y\n",
      "WXY -> Z\n",
      "F -> G\n",
      "KLMNO -> P\n",
      "OPQ -> R\n",
      "M -> N\n",
      "X -> Y\n",
      "OPQRS -> T\n",
      "F -> G\n",
      "JKLMN -> O\n",
      "XY -> Z\n",
      "OPQ -> R\n",
      "FG -> H\n",
      "OP -> Q\n",
      "DEFGH -> I\n",
      "ABCD -> E\n",
      "VWX -> Y\n",
      "U -> V\n",
      "UV -> W\n",
      "VWX -> Y\n",
      "LMNO -> P\n",
      "E -> F\n",
      "NOPQ -> R\n",
      "HIJK -> L\n",
      "HIJ -> K\n",
      "DE -> F\n",
      "B -> C\n",
      "UVW -> X\n",
      "STUV -> W\n",
      "RST -> U\n",
      "H -> I\n",
      "I -> J\n",
      "MN -> O\n",
      "CDEF -> G\n",
      "ABC -> D\n",
      "RSTU -> V\n",
      "B -> C\n",
      "JKLM -> N\n",
      "TUVW -> X\n",
      "STUVW -> X\n",
      "C -> D\n",
      "UV -> W\n",
      "QRS -> T\n",
      "ABC -> D\n",
      "NOP -> Q\n",
      "W -> X\n",
      "DE -> F\n",
      "VWXY -> Z\n",
      "UV -> W\n",
      "JK -> L\n",
      "E -> F\n",
      "MNO -> P\n",
      "EFGH -> I\n",
      "PQRS -> T\n",
      "FGH -> I\n",
      "WXY -> Z\n",
      "OPQRS -> T\n",
      "TUV -> W\n",
      "MN -> O\n",
      "O -> P\n",
      "LMN -> O\n",
      "VWX -> Y\n",
      "QR -> S\n",
      "TUV -> W\n",
      "STU -> V\n",
      "EFGH -> I\n",
      "E -> F\n",
      "HIJ -> K\n",
      "QRS -> T\n",
      "H -> I\n",
      "K -> L\n",
      "E -> F\n",
      "UV -> W\n",
      "X -> Y\n",
      "QR -> S\n",
      "QRS -> T\n",
      "WXY -> Z\n",
      "S -> T\n",
      "CDEFG -> H\n",
      "PQRST -> U\n",
      "RST -> U\n",
      "A -> B\n",
      "CDEF -> G\n",
      "X -> Y\n",
      "JKLM -> N\n",
      "VWX -> Y\n",
      "N -> O\n",
      "W -> X\n",
      "TUVW -> X\n",
      "LMNOP -> Q\n",
      "EFG -> H\n",
      "HI -> J\n",
      "WXY -> Z\n",
      "IJK -> L\n",
      "R -> S\n",
      "H -> I\n",
      "V -> W\n",
      "OPQR -> S\n",
      "QRSTU -> V\n",
      "MNOPQ -> R\n",
      "Q -> R\n",
      "VWXY -> Z\n",
      "ABCDE -> F\n",
      "HIJK -> L\n",
      "FGHIJ -> K\n",
      "BC -> D\n",
      "UV -> W\n",
      "WXY -> Z\n",
      "VWX -> Y\n",
      "L -> M\n",
      "FG -> H\n",
      "E -> F\n",
      "WXY -> Z\n",
      "KLMN -> O\n",
      "B -> C\n",
      "QRSTU -> V\n",
      "X -> Y\n",
      "ST -> U\n",
      "GH -> I\n",
      "CDE -> F\n",
      "IJKLM -> N\n",
      "JKL -> M\n",
      "HIJ -> K\n",
      "UVWXY -> Z\n",
      "PQ -> R\n",
      "AB -> C\n",
      "HIJ -> K\n",
      "EFG -> H\n",
      "PQRS -> T\n",
      "BCDEF -> G\n",
      "IJKL -> M\n",
      "DEFGH -> I\n",
      "VW -> X\n",
      "XY -> Z\n",
      "OPQ -> R\n",
      "MN -> O\n",
      "OP -> Q\n",
      "WXY -> Z\n",
      "STU -> V\n",
      "LM -> N\n",
      "UV -> W\n",
      "EF -> G\n",
      "LMN -> O\n",
      "D -> E\n",
      "H -> I\n",
      "KLMNO -> P\n",
      "PQRST -> U\n",
      "V -> W\n",
      "M -> N\n",
      "UVW -> X\n",
      "ABCD -> E\n",
      "LM -> N\n",
      "A -> B\n",
      "DEFGH -> I\n",
      "IJK -> L\n",
      "OP -> Q\n",
      "WXY -> Z\n",
      "CDEFG -> H\n",
      "UVW -> X\n",
      "RS -> T\n",
      "FGHIJ -> K\n",
      "RST -> U\n",
      "NO -> P\n",
      "X -> Y\n",
      "RST -> U\n",
      "I -> J\n",
      "TUV -> W\n",
      "B -> C\n",
      "UVWX -> Y\n",
      "HIJKL -> M\n",
      "MNOPQ -> R\n",
      "ABC -> D\n",
      "PQ -> R\n",
      "WX -> Y\n",
      "XY -> Z\n",
      "UVW -> X\n",
      "IJKL -> M\n",
      "XY -> Z\n",
      "DEFG -> H\n",
      "H -> I\n",
      "Q -> R\n",
      "CDEFG -> H\n",
      "C -> D\n",
      "ABCD -> E\n",
      "LMN -> O\n",
      "PQRST -> U\n",
      "VWX -> Y\n",
      "M -> N\n",
      "KLMN -> O\n",
      "AB -> C\n",
      "NOPQ -> R\n",
      "F -> G\n",
      "NO -> P\n",
      "KLM -> N\n",
      "TUVWX -> Y\n",
      "U -> V\n",
      "CDEFG -> H\n",
      "FGHI -> J\n",
      "STUVW -> X\n",
      "JKLM -> N\n",
      "ABC -> D\n",
      "JKLMN -> O\n",
      "TUVWX -> Y\n",
      "D -> E\n",
      "EFGH -> I\n",
      "IJ -> K\n",
      "UVW -> X\n",
      "OPQR -> S\n",
      "N -> O\n",
      "VWXY -> Z\n",
      "ABC -> D\n",
      "J -> K\n",
      "RS -> T\n",
      "LMNOP -> Q\n",
      "BC -> D\n",
      "OPQ -> R\n",
      "JKLM -> N\n",
      "WX -> Y\n",
      "BCD -> E\n",
      "RSTU -> V\n",
      "GHI -> J\n",
      "O -> P\n",
      "R -> S\n",
      "QR -> S\n",
      "HIJKL -> M\n",
      "UVWXY -> Z\n",
      "CDEFG -> H\n",
      "OP -> Q\n",
      "HIJK -> L\n",
      "A -> B\n",
      "RST -> U\n",
      "QR -> S\n",
      "ABCD -> E\n",
      "LMN -> O\n",
      "TUV -> W\n",
      "MNO -> P\n",
      "AB -> C\n",
      "M -> N\n",
      "OPQR -> S\n",
      "STU -> V\n",
      "TUV -> W\n",
      "PQRST -> U\n",
      "LM -> N\n",
      "A -> B\n",
      "A -> B\n",
      "OPQ -> R\n",
      "HIJK -> L\n",
      "TU -> V\n",
      "QRS -> T\n",
      "WX -> Y\n",
      "BCD -> E\n",
      "ST -> U\n",
      "X -> Y\n",
      "EFGHI -> J\n",
      "E -> F\n",
      "FGHIJ -> K\n",
      "HI -> J\n",
      "ABC -> D\n",
      "NOPQ -> R\n",
      "HIJK -> L\n",
      "B -> C\n",
      "U -> V\n",
      "GH -> I\n",
      "TUVWX -> Y\n",
      "S -> T\n",
      "BCDEF -> G\n",
      "KLM -> N\n",
      "Q -> R\n",
      "CD -> E\n",
      "PQ -> R\n",
      "GH -> I\n",
      "U -> V\n",
      "RST -> U\n",
      "JKLM -> N\n",
      "FGH -> I\n",
      "IJ -> K\n",
      "O -> P\n",
      "X -> Y\n",
      "H -> I\n",
      "DEF -> G\n",
      "QRSTU -> V\n",
      "ABCD -> E\n",
      "IJK -> L\n",
      "GHI -> J\n",
      "QR -> S\n",
      "NOPQR -> S\n",
      "EF -> G\n",
      "PQRST -> U\n",
      "RST -> U\n",
      "X -> Y\n",
      "QR -> S\n",
      "HIJ -> K\n",
      "D -> E\n",
      "AB -> C\n",
      "N -> O\n",
      "QR -> S\n",
      "BCDEF -> G\n",
      "QRS -> T\n",
      "DEF -> G\n",
      "TUV -> W\n",
      "A -> B\n",
      "GHIJ -> K\n",
      "W -> X\n",
      "VWXY -> Z\n",
      "LM -> N\n",
      "OPQ -> R\n",
      "XY -> Z\n",
      "KLM -> N\n",
      "RST -> U\n",
      "OP -> Q\n",
      "VWX -> Y\n",
      "OPQ -> R\n",
      "N -> O\n",
      "M -> N\n",
      "JKL -> M\n",
      "OP -> Q\n",
      "DEF -> G\n",
      "BCD -> E\n",
      "K -> L\n",
      "MN -> O\n",
      "IJKL -> M\n",
      "QR -> S\n",
      "IJKLM -> N\n",
      "U -> V\n",
      "FGH -> I\n",
      "MNOPQ -> R\n",
      "TUVW -> X\n",
      "MN -> O\n",
      "RSTUV -> W\n",
      "VWX -> Y\n",
      "Q -> R\n",
      "DEFGH -> I\n",
      "NO -> P\n",
      "T -> U\n",
      "V -> W\n",
      "ST -> U\n",
      "DEFG -> H\n",
      "RS -> T\n",
      "NOPQ -> R\n",
      "GHIJK -> L\n",
      "QRSTU -> V\n",
      "LMNO -> P\n",
      "IJK -> L\n",
      "PQRST -> U\n",
      "IJK -> L\n",
      "DE -> F\n",
      "CD -> E\n",
      "JKLM -> N\n",
      "WX -> Y\n",
      "UV -> W\n",
      "W -> X\n",
      "KLM -> N\n",
      "PQ -> R\n",
      "W -> X\n",
      "WXY -> Z\n",
      "EFGHI -> J\n",
      "E -> F\n",
      "NOP -> Q\n",
      "VW -> X\n",
      "EFGHI -> J\n",
      "NO -> P\n",
      "HIJKL -> M\n",
      "UVWXY -> Z\n",
      "OPQ -> R\n",
      "P -> Q\n",
      "H -> I\n",
      "O -> P\n",
      "GHIJK -> L\n",
      "S -> T\n",
      "E -> F\n",
      "KLMN -> O\n",
      "TUVW -> X\n",
      "E -> F\n",
      "CDE -> F\n",
      "I -> J\n",
      "CDEF -> G\n",
      "F -> G\n",
      "ABCD -> E\n",
      "H -> I\n",
      "LMNOP -> Q\n",
      "V -> W\n",
      "W -> X\n",
      "BCD -> E\n",
      "TU -> V\n",
      "VWXY -> Z\n",
      "UVWX -> Y\n",
      "JKL -> M\n",
      "VW -> X\n",
      "CDEF -> G\n",
      "DEF -> G\n",
      "ABCDE -> F\n",
      "MNO -> P\n",
      "EFGH -> I\n",
      "JKLM -> N\n",
      "QR -> S\n",
      "ABCDE -> F\n",
      "OPQR -> S\n",
      "DEF -> G\n",
      "Q -> R\n",
      "TU -> V\n",
      "CDEFG -> H\n",
      "KLMN -> O\n",
      "VW -> X\n",
      "HIJKL -> M\n",
      "DE -> F\n",
      "OP -> Q\n",
      "I -> J\n",
      "GHIJK -> L\n",
      "HIJKL -> M\n",
      "I -> J\n",
      "AB -> C\n",
      "DE -> F\n",
      "I -> J\n",
      "O -> P\n",
      "HIJK -> L\n",
      "QR -> S\n",
      "MN -> O\n",
      "I -> J\n",
      "LM -> N\n",
      "VWXY -> Z\n",
      "JKLMN -> O\n",
      "BC -> D\n",
      "MN -> O\n",
      "GHIJ -> K\n",
      "KL -> M\n",
      "TU -> V\n",
      "QRST -> U\n",
      "ABCDE -> F\n",
      "GH -> I\n",
      "Q -> R\n",
      "NO -> P\n",
      "RST -> U\n",
      "BCDE -> F\n",
      "T -> U\n",
      "TUV -> W\n",
      "FGHIJ -> K\n",
      "T -> U\n",
      "BCD -> E\n",
      "NO -> P\n",
      "JK -> L\n",
      "BCD -> E\n",
      "G -> H\n",
      "A -> B\n",
      "GHIJK -> L\n",
      "QRSTU -> V\n",
      "AB -> C\n",
      "VW -> X\n",
      "HIJKL -> M\n",
      "FGHIJ -> K\n",
      "PQ -> R\n",
      "UV -> W\n",
      "F -> G\n",
      "A -> B\n",
      "Q -> R\n",
      "MNOP -> Q\n",
      "UVWXY -> Z\n",
      "GHIJK -> L\n",
      "GHIJK -> L\n",
      "BCDE -> F\n",
      "QRS -> T\n",
      "PQRS -> T\n",
      "PQ -> R\n",
      "HI -> J\n",
      "PQRST -> U\n",
      "OPQR -> S\n",
      "QRST -> U\n",
      "IJKLM -> N\n",
      "Q -> R\n",
      "F -> G\n",
      "QRST -> U\n",
      "ST -> U\n",
      "MN -> O\n",
      "CD -> E\n",
      "EFG -> H\n",
      "FGH -> I\n",
      "R -> S\n",
      "C -> D\n",
      "RSTUV -> W\n",
      "KL -> M\n",
      "HIJK -> L\n",
      "CD -> E\n",
      "FGHI -> J\n",
      "VW -> X\n",
      "P -> Q\n",
      "C -> D\n",
      "DE -> F\n",
      "DE -> F\n",
      "I -> J\n",
      "LMNOP -> Q\n",
      "KLMNO -> P\n",
      "QRS -> T\n",
      "F -> G\n",
      "UVWXY -> Z\n",
      "QRS -> T\n",
      "BCD -> E\n",
      "FG -> H\n",
      "ABCDE -> F\n",
      "U -> V\n",
      "M -> N\n",
      "KLMN -> O\n",
      "RST -> U\n",
      "UVWX -> Y\n",
      "X -> Y\n",
      "XY -> Z\n",
      "I -> J\n",
      "KLMN -> O\n",
      "X -> Y\n",
      "W -> X\n",
      "RSTUV -> W\n",
      "VW -> X\n",
      "XY -> Z\n",
      "T -> U\n",
      "CDE -> F\n",
      "FGHI -> J\n",
      "PQ -> R\n",
      "OPQRS -> T\n",
      "D -> E\n",
      "E -> F\n",
      "EFGH -> I\n",
      "GHIJK -> L\n",
      "L -> M\n",
      "KLMN -> O\n",
      "STU -> V\n",
      "EF -> G\n",
      "UV -> W\n",
      "K -> L\n",
      "QRS -> T\n",
      "QRSTU -> V\n",
      "DEF -> G\n",
      "UV -> W\n",
      "D -> E\n",
      "BC -> D\n",
      "OPQRS -> T\n",
      "EFGH -> I\n",
      "QRST -> U\n",
      "EF -> G\n",
      "RST -> U\n",
      "JKL -> M\n",
      "STU -> V\n",
      "UVWX -> Y\n",
      "EFGHI -> J\n",
      "JKLMN -> O\n",
      "P -> Q\n",
      "BCD -> E\n",
      "TU -> V\n",
      "O -> P\n",
      "RST -> U\n",
      "D -> E\n",
      "VWXY -> Z\n",
      "R -> S\n",
      "P -> Q\n",
      "CDE -> F\n",
      "X -> Y\n",
      "UVWXY -> Z\n",
      "DEFGH -> I\n",
      "NOP -> Q\n",
      "ABCD -> E\n",
      "B -> C\n",
      "BC -> D\n",
      "VW -> X\n",
      "E -> F\n",
      "TUVW -> X\n",
      "JKL -> M\n",
      "XY -> Z\n",
      "LM -> N\n",
      "PQRS -> T\n",
      "O -> P\n",
      "KLMN -> O\n",
      "STUV -> W\n",
      "K -> L\n",
      "UVWX -> Y\n",
      "U -> V\n",
      "HIJ -> K\n",
      "W -> X\n",
      "VWXY -> Z\n",
      "WX -> Y\n",
      "HIJ -> K\n",
      "O -> P\n",
      "QR -> S\n",
      "VWXY -> Z\n",
      "CD -> E\n",
      "KL -> M\n",
      "DEFGH -> I\n",
      "LMN -> O\n",
      "QRS -> T\n",
      "JKLMN -> O\n",
      "QR -> S\n",
      "CD -> E\n",
      "QRST -> U\n",
      "BCDEF -> G\n",
      "CDE -> F\n",
      "LMN -> O\n",
      "DEF -> G\n",
      "BCD -> E\n",
      "UV -> W\n",
      "STUVW -> X\n",
      "RS -> T\n",
      "ABCD -> E\n",
      "BCDEF -> G\n",
      "Q -> R\n",
      "UVWXY -> Z\n",
      "VW -> X\n",
      "VW -> X\n",
      "WXY -> Z\n",
      "NOPQR -> S\n",
      "V -> W\n",
      "LM -> N\n",
      "B -> C\n",
      "JKL -> M\n",
      "DE -> F\n",
      "K -> L\n",
      "ABC -> D\n",
      "E -> F\n",
      "STU -> V\n",
      "TU -> V\n",
      "G -> H\n",
      "AB -> C\n",
      "J -> K\n",
      "FGH -> I\n",
      "MNOP -> Q\n",
      "VW -> X\n",
      "CD -> E\n",
      "TUVWX -> Y\n",
      "F -> G\n",
      "VWX -> Y\n",
      "LMNO -> P\n",
      "GHIJ -> K\n",
      "TUVWX -> Y\n",
      "JKL -> M\n",
      "LM -> N\n",
      "EFGHI -> J\n",
      "MNO -> P\n",
      "H -> I\n",
      "M -> N\n",
      "S -> T\n",
      "STU -> V\n",
      "QRST -> U\n",
      "PQR -> S\n",
      "RSTUV -> W\n",
      "ST -> U\n",
      "RSTUV -> W\n",
      "JKLM -> N\n",
      "T -> U\n",
      "CDE -> F\n",
      "HIJ -> K\n",
      "NOPQ -> R\n",
      "OPQ -> R\n",
      "EF -> G\n",
      "AB -> C\n",
      "CD -> E\n",
      "RST -> U\n",
      "STU -> V\n",
      "L -> M\n",
      "WXY -> Z\n",
      "STUVW -> X\n",
      "QRST -> U\n",
      "W -> X\n",
      "S -> T\n",
      "M -> N\n",
      "GH -> I\n",
      "QRST -> U\n",
      "FGH -> I\n",
      "PQRS -> T\n",
      "GH -> I\n",
      "DE -> F\n",
      "DE -> F\n",
      "GHIJK -> L\n",
      "Q -> R\n",
      "WX -> Y\n",
      "WX -> Y\n",
      "KLM -> N\n",
      "DE -> F\n",
      "EF -> G\n",
      "UVW -> X\n",
      "IJK -> L\n",
      "NO -> P\n",
      "QR -> S\n",
      "TU -> V\n",
      "RST -> U\n",
      "VW -> X\n",
      "A -> B\n",
      "DE -> F\n",
      "WXY -> Z\n",
      "CD -> E\n",
      "IJK -> L\n",
      "STUV -> W\n",
      "LMNOP -> Q\n",
      "X -> Y\n",
      "FGH -> I\n",
      "F -> G\n",
      "IJK -> L\n",
      "EFG -> H\n",
      "DEFG -> H\n",
      "NOP -> Q\n",
      "FG -> H\n",
      "RSTU -> V\n",
      "E -> F\n",
      "WXY -> Z\n",
      "GH -> I\n",
      "CD -> E\n",
      "IJ -> K\n",
      "TUVWX -> Y\n",
      "EFGH -> I\n",
      "DEFGH -> I\n",
      "BCDE -> F\n",
      "STUV -> W\n",
      "HI -> J\n",
      "GH -> I\n",
      "STUVW -> X\n",
      "ABC -> D\n",
      "S -> T\n",
      "LMNOP -> Q\n",
      "UVWX -> Y\n",
      "PQ -> R\n",
      "CDEF -> G\n",
      "E -> F\n",
      "TU -> V\n",
      "TUVWX -> Y\n",
      "GHIJ -> K\n",
      "JK -> L\n",
      "IJK -> L\n",
      "G -> H\n",
      "EFG -> H\n",
      "TU -> V\n",
      "FGHI -> J\n",
      "W -> X\n",
      "T -> U\n",
      "CDE -> F\n",
      "XY -> Z\n",
      "XY -> Z\n",
      "CDE -> F\n",
      "N -> O\n",
      "QRST -> U\n",
      "FGHIJ -> K\n",
      "PQ -> R\n",
      "I -> J\n",
      "GH -> I\n",
      "F -> G\n",
      "VWX -> Y\n",
      "ABC -> D\n",
      "GH -> I\n",
      "KLMN -> O\n",
      "X -> Y\n",
      "Q -> R\n",
      "NOPQR -> S\n",
      "HIJ -> K\n",
      "IJ -> K\n",
      "C -> D\n",
      "FG -> H\n",
      "JKLMN -> O\n",
      "TU -> V\n",
      "NOPQR -> S\n",
      "O -> P\n",
      "TU -> V\n",
      "MNOPQ -> R\n",
      "PQ -> R\n",
      "S -> T\n",
      "VWXY -> Z\n",
      "VWXY -> Z\n",
      "CD -> E\n",
      "BCDEF -> G\n",
      "OPQ -> R\n",
      "LMNO -> P\n",
      "HIJKL -> M\n",
      "STU -> V\n",
      "GHI -> J\n",
      "UVWX -> Y\n",
      "NOPQ -> R\n",
      "HIJK -> L\n",
      "NOP -> Q\n",
      "Q -> R\n",
      "HIJ -> K\n",
      "W -> X\n",
      "QR -> S\n",
      "UVWX -> Y\n",
      "H -> I\n",
      "ABC -> D\n",
      "RSTUV -> W\n",
      "VW -> X\n",
      "OP -> Q\n",
      "RSTUV -> W\n",
      "ABC -> D\n",
      "ABC -> D\n",
      "GHIJ -> K\n",
      "WXY -> Z\n",
      "BCDE -> F\n",
      "N -> O\n",
      "JK -> L\n",
      "X -> Y\n",
      "TUV -> W\n",
      "L -> M\n",
      "F -> G\n",
      "MN -> O\n",
      "JKLMN -> O\n",
      "G -> H\n",
      "BCDEF -> G\n",
      "LMN -> O\n",
      "N -> O\n",
      "V -> W\n",
      "BCDEF -> G\n",
      "KLM -> N\n",
      "ST -> U\n",
      "TUV -> W\n",
      "MN -> O\n",
      "JKLM -> N\n",
      "LM -> N\n",
      "U -> V\n",
      "FGH -> I\n",
      "TUV -> W\n",
      "C -> D\n",
      "HIJK -> L\n",
      "UVWX -> Y\n",
      "W -> X\n",
      "QR -> S\n",
      "PQR -> S\n",
      "STUVW -> X\n",
      "RSTU -> V\n",
      "TU -> V\n",
      "RSTU -> V\n",
      "JKL -> M\n",
      "JKL -> M\n",
      "RSTUV -> W\n",
      "GHI -> J\n",
      "V -> W\n",
      "CD -> E\n",
      "QRSTU -> V\n",
      "M -> N\n",
      "BCDE -> F\n",
      "WX -> Y\n",
      "K -> L\n",
      "VW -> X\n",
      "GHI -> J\n",
      "CD -> E\n",
      "XY -> Z\n",
      "HI -> J\n",
      "C -> D\n",
      "IJK -> L\n",
      "DEFG -> H\n",
      "UV -> W\n",
      "LM -> N\n",
      "X -> Y\n",
      "UV -> W\n",
      "I -> J\n",
      "NO -> P\n",
      "ABCD -> E\n",
      "K -> L\n",
      "IJK -> L\n",
      "JKL -> M\n",
      "EFGHI -> J\n",
      "JK -> L\n",
      "TU -> V\n",
      "IJ -> K\n",
      "MNOPQ -> R\n",
      "C -> D\n",
      "IJKLM -> N\n",
      "VW -> X\n",
      "CDE -> F\n",
      "E -> F\n",
      "NOP -> Q\n",
      "OPQRS -> T\n",
      "FGHI -> J\n",
      "STUV -> W\n",
      "IJKLM -> N\n",
      "STUV -> W\n",
      "TUVWX -> Y\n",
      "RSTU -> V\n"
     ]
    }
   ],
   "source": [
    "# 準備訓練資料\n",
    "num_inputs = 1000\n",
    "max_len = 5  # 最大序列長度\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(num_inputs):\n",
    "    start = numpy.random.randint(len(alphabet) - 2)\n",
    "    end = numpy.random.randint(start, min(start + max_len, len(alphabet) - 1))\n",
    "    sequence_in = alphabet[start : end + 1]\n",
    "    sequence_out = alphabet[end + 1]\n",
    "    dataX.append([char_to_int[char] for char in sequence_in])\n",
    "    dataY.append(char_to_int[sequence_out])\n",
    "    print(sequence_in, \"->\", sequence_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP2. 資料預處理\n",
    "因為輸入序列的長度會在1到max_len之間變動，因此需要以\"0\"來填充(padding)。在這裡，我們使用Keras內附的pad_sequences（）函數並設定使用左側（前綴）填充。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 將訓練資料轉換為陣列和並進行序列填充（如果需要）\n",
    "X = pad_sequences(dataX, maxlen=max_len, dtype=\"float32\")  # <-- 注意這裡\n",
    "\n",
    "# 重塑 X 資料的維度成為 (samples, time_steps, features)\n",
    "X = numpy.reshape(X, (X.shape[0], max_len, 1))  # <-- 特別注意這裡\n",
    "\n",
    "# 歸一化\n",
    "X = X / float(len(alphabet))\n",
    "\n",
    "# 使用one hot encode 對Y值進行編碼\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP3. 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">858</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │           \u001b[38;5;34m858\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,210</span> (20.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,210\u001b[0m (20.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,210</span> (20.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,210\u001b[0m (20.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 創建模型\n",
    "batch_size = 1\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(X.shape[1], 1)))  # <-- 注意這裡\n",
    "model.add(Dense(y.shape[1], activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP4. 定義訓練並進行訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1000/1000 - 6s - 6ms/step - accuracy: 0.0640 - loss: 3.0943\n",
      "Epoch 2/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.1150 - loss: 2.8112\n",
      "Epoch 3/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.1730 - loss: 2.5039\n",
      "Epoch 4/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.2340 - loss: 2.2602\n",
      "Epoch 5/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.2850 - loss: 2.0889\n",
      "Epoch 6/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.2910 - loss: 1.9507\n",
      "Epoch 7/500\n",
      "1000/1000 - 6s - 6ms/step - accuracy: 0.3450 - loss: 1.8458\n",
      "Epoch 8/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.3880 - loss: 1.7488\n",
      "Epoch 9/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.4150 - loss: 1.6606\n",
      "Epoch 10/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.4210 - loss: 1.5932\n",
      "Epoch 11/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.4580 - loss: 1.5340\n",
      "Epoch 12/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.4840 - loss: 1.4783\n",
      "Epoch 13/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.5190 - loss: 1.4202\n",
      "Epoch 14/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.5410 - loss: 1.3689\n",
      "Epoch 15/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.5400 - loss: 1.3286\n",
      "Epoch 16/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.5570 - loss: 1.2965\n",
      "Epoch 17/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.5870 - loss: 1.2466\n",
      "Epoch 18/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.6000 - loss: 1.2097\n",
      "Epoch 19/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.6130 - loss: 1.1672\n",
      "Epoch 20/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.6200 - loss: 1.1436\n",
      "Epoch 21/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.6530 - loss: 1.0957\n",
      "Epoch 22/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.6430 - loss: 1.0803\n",
      "Epoch 23/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.6600 - loss: 1.0456\n",
      "Epoch 24/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.6680 - loss: 1.0188\n",
      "Epoch 25/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.6870 - loss: 0.9860\n",
      "Epoch 26/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.6760 - loss: 0.9878\n",
      "Epoch 27/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.7020 - loss: 0.9423\n",
      "Epoch 28/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.6960 - loss: 0.9273\n",
      "Epoch 29/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.7190 - loss: 0.8979\n",
      "Epoch 30/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.7290 - loss: 0.8868\n",
      "Epoch 31/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.7340 - loss: 0.8681\n",
      "Epoch 32/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.7430 - loss: 0.8343\n",
      "Epoch 33/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.7250 - loss: 0.8330\n",
      "Epoch 34/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.7370 - loss: 0.8032\n",
      "Epoch 35/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.7430 - loss: 0.8069\n",
      "Epoch 36/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.7650 - loss: 0.7770\n",
      "Epoch 37/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.7720 - loss: 0.7457\n",
      "Epoch 38/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.7600 - loss: 0.7653\n",
      "Epoch 39/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.7700 - loss: 0.7312\n",
      "Epoch 40/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.7670 - loss: 0.7170\n",
      "Epoch 41/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.7740 - loss: 0.7105\n",
      "Epoch 42/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.7560 - loss: 0.7330\n",
      "Epoch 43/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.7920 - loss: 0.6759\n",
      "Epoch 44/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.7870 - loss: 0.6738\n",
      "Epoch 45/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.7680 - loss: 0.6962\n",
      "Epoch 46/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8010 - loss: 0.6503\n",
      "Epoch 47/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.7850 - loss: 0.6574\n",
      "Epoch 48/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.7740 - loss: 0.6918\n",
      "Epoch 49/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.7970 - loss: 0.6371\n",
      "Epoch 50/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8070 - loss: 0.6104\n",
      "Epoch 51/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.7900 - loss: 0.6347\n",
      "Epoch 52/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8110 - loss: 0.5960\n",
      "Epoch 53/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.7880 - loss: 0.6292\n",
      "Epoch 54/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8230 - loss: 0.5891\n",
      "Epoch 55/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8080 - loss: 0.5878\n",
      "Epoch 56/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8160 - loss: 0.5880\n",
      "Epoch 57/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8130 - loss: 0.5822\n",
      "Epoch 58/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.7920 - loss: 0.6288\n",
      "Epoch 59/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8210 - loss: 0.5512\n",
      "Epoch 60/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8270 - loss: 0.5607\n",
      "Epoch 61/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8110 - loss: 0.5754\n",
      "Epoch 62/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8330 - loss: 0.5319\n",
      "Epoch 63/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8220 - loss: 0.5478\n",
      "Epoch 64/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8000 - loss: 0.6109\n",
      "Epoch 65/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8460 - loss: 0.5100\n",
      "Epoch 66/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8210 - loss: 0.5257\n",
      "Epoch 67/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8220 - loss: 0.5408\n",
      "Epoch 68/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8050 - loss: 0.5558\n",
      "Epoch 69/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8360 - loss: 0.5180\n",
      "Epoch 70/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8370 - loss: 0.5043\n",
      "Epoch 71/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8380 - loss: 0.5083\n",
      "Epoch 72/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8260 - loss: 0.5164\n",
      "Epoch 73/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8430 - loss: 0.4825\n",
      "Epoch 74/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8440 - loss: 0.4890\n",
      "Epoch 75/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8160 - loss: 0.5309\n",
      "Epoch 76/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8600 - loss: 0.4809\n",
      "Epoch 77/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8270 - loss: 0.5151\n",
      "Epoch 78/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8530 - loss: 0.4661\n",
      "Epoch 79/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8220 - loss: 0.5120\n",
      "Epoch 80/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8450 - loss: 0.4560\n",
      "Epoch 81/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8310 - loss: 0.4743\n",
      "Epoch 82/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8550 - loss: 0.4576\n",
      "Epoch 83/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8490 - loss: 0.4696\n",
      "Epoch 84/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8520 - loss: 0.4511\n",
      "Epoch 85/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8510 - loss: 0.4460\n",
      "Epoch 86/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8150 - loss: 0.5585\n",
      "Epoch 87/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8670 - loss: 0.4301\n",
      "Epoch 88/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8600 - loss: 0.4395\n",
      "Epoch 89/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8360 - loss: 0.5168\n",
      "Epoch 90/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8630 - loss: 0.4218\n",
      "Epoch 91/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8570 - loss: 0.4292\n",
      "Epoch 92/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8540 - loss: 0.4303\n",
      "Epoch 93/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8270 - loss: 0.4795\n",
      "Epoch 94/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8630 - loss: 0.4182\n",
      "Epoch 95/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8380 - loss: 0.4597\n",
      "Epoch 96/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8700 - loss: 0.4035\n",
      "Epoch 97/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8440 - loss: 0.4776\n",
      "Epoch 98/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8620 - loss: 0.4102\n",
      "Epoch 99/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8420 - loss: 0.4633\n",
      "Epoch 100/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8780 - loss: 0.4001\n",
      "Epoch 101/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8620 - loss: 0.4068\n",
      "Epoch 102/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8570 - loss: 0.4232\n",
      "Epoch 103/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8660 - loss: 0.3978\n",
      "Epoch 104/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8320 - loss: 0.5042\n",
      "Epoch 105/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8720 - loss: 0.3879\n",
      "Epoch 106/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8590 - loss: 0.4147\n",
      "Epoch 107/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8620 - loss: 0.4120\n",
      "Epoch 108/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8730 - loss: 0.3872\n",
      "Epoch 109/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8530 - loss: 0.4088\n",
      "Epoch 110/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8480 - loss: 0.4914\n",
      "Epoch 111/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8620 - loss: 0.3786\n",
      "Epoch 112/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8370 - loss: 0.4719\n",
      "Epoch 113/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8830 - loss: 0.3713\n",
      "Epoch 114/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8630 - loss: 0.4190\n",
      "Epoch 115/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8730 - loss: 0.3787\n",
      "Epoch 116/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8690 - loss: 0.3851\n",
      "Epoch 117/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8610 - loss: 0.3974\n",
      "Epoch 118/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8680 - loss: 0.3715\n",
      "Epoch 119/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8500 - loss: 0.4249\n",
      "Epoch 120/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8640 - loss: 0.3923\n",
      "Epoch 121/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8880 - loss: 0.3670\n",
      "Epoch 122/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8520 - loss: 0.4247\n",
      "Epoch 123/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8790 - loss: 0.3602\n",
      "Epoch 124/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8750 - loss: 0.3629\n",
      "Epoch 125/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8600 - loss: 0.3772\n",
      "Epoch 126/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8730 - loss: 0.3695\n",
      "Epoch 127/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8430 - loss: 0.4258\n",
      "Epoch 128/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8820 - loss: 0.3554\n",
      "Epoch 129/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8810 - loss: 0.3543\n",
      "Epoch 130/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8540 - loss: 0.4433\n",
      "Epoch 131/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8640 - loss: 0.3870\n",
      "Epoch 132/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8760 - loss: 0.3458\n",
      "Epoch 133/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8740 - loss: 0.3590\n",
      "Epoch 134/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8800 - loss: 0.3552\n",
      "Epoch 135/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8800 - loss: 0.3488\n",
      "Epoch 136/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8430 - loss: 0.4237\n",
      "Epoch 137/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8910 - loss: 0.3329\n",
      "Epoch 138/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8800 - loss: 0.3374\n",
      "Epoch 139/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8810 - loss: 0.3439\n",
      "Epoch 140/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8770 - loss: 0.3631\n",
      "Epoch 141/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8600 - loss: 0.4122\n",
      "Epoch 142/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8830 - loss: 0.3288\n",
      "Epoch 143/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8740 - loss: 0.3416\n",
      "Epoch 144/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8700 - loss: 0.4009\n",
      "Epoch 145/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8890 - loss: 0.3250\n",
      "Epoch 146/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8790 - loss: 0.3317\n",
      "Epoch 147/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8780 - loss: 0.3402\n",
      "Epoch 148/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8740 - loss: 0.3563\n",
      "Epoch 149/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8910 - loss: 0.3163\n",
      "Epoch 150/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8520 - loss: 0.4333\n",
      "Epoch 151/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8860 - loss: 0.3178\n",
      "Epoch 152/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8880 - loss: 0.3216\n",
      "Epoch 153/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8930 - loss: 0.3254\n",
      "Epoch 154/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8590 - loss: 0.4050\n",
      "Epoch 155/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8780 - loss: 0.3104\n",
      "Epoch 156/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8950 - loss: 0.3146\n",
      "Epoch 157/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8870 - loss: 0.3169\n",
      "Epoch 158/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8940 - loss: 0.3215\n",
      "Epoch 159/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8830 - loss: 0.3172\n",
      "Epoch 160/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8650 - loss: 0.4134\n",
      "Epoch 161/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8960 - loss: 0.3048\n",
      "Epoch 162/500\n",
      "1000/1000 - 6s - 6ms/step - accuracy: 0.8900 - loss: 0.3090\n",
      "Epoch 163/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8970 - loss: 0.3086\n",
      "Epoch 164/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8620 - loss: 0.4266\n",
      "Epoch 165/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.9000 - loss: 0.3028\n",
      "Epoch 166/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.9040 - loss: 0.2998\n",
      "Epoch 167/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8910 - loss: 0.3022\n",
      "Epoch 168/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8910 - loss: 0.3337\n",
      "Epoch 169/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8910 - loss: 0.3035\n",
      "Epoch 170/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8900 - loss: 0.3217\n",
      "Epoch 171/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8540 - loss: 0.4274\n",
      "Epoch 172/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9000 - loss: 0.2971\n",
      "Epoch 173/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8940 - loss: 0.2983\n",
      "Epoch 174/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8970 - loss: 0.3056\n",
      "Epoch 175/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8900 - loss: 0.3096\n",
      "Epoch 176/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8690 - loss: 0.4097\n",
      "Epoch 177/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9040 - loss: 0.2897\n",
      "Epoch 178/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8990 - loss: 0.2928\n",
      "Epoch 179/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8990 - loss: 0.2963\n",
      "Epoch 180/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.9040 - loss: 0.2947\n",
      "Epoch 181/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9020 - loss: 0.2914\n",
      "Epoch 182/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8860 - loss: 0.3326\n",
      "Epoch 183/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8810 - loss: 0.3628\n",
      "Epoch 184/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9090 - loss: 0.2853\n",
      "Epoch 185/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9040 - loss: 0.2877\n",
      "Epoch 186/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8990 - loss: 0.2895\n",
      "Epoch 187/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9030 - loss: 0.2967\n",
      "Epoch 188/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8980 - loss: 0.3021\n",
      "Epoch 189/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8660 - loss: 0.4321\n",
      "Epoch 190/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.9070 - loss: 0.2791\n",
      "Epoch 191/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.9070 - loss: 0.2773\n",
      "Epoch 192/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9060 - loss: 0.2881\n",
      "Epoch 193/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9010 - loss: 0.2924\n",
      "Epoch 194/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.9120 - loss: 0.2846\n",
      "Epoch 195/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9010 - loss: 0.2831\n",
      "Epoch 196/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9090 - loss: 0.2829\n",
      "Epoch 197/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8890 - loss: 0.3282\n",
      "Epoch 198/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9090 - loss: 0.2854\n",
      "Epoch 199/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9060 - loss: 0.2713\n",
      "Epoch 200/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9160 - loss: 0.2723\n",
      "Epoch 201/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9000 - loss: 0.2727\n",
      "Epoch 202/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9020 - loss: 0.2828\n",
      "Epoch 203/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8890 - loss: 0.3261\n",
      "Epoch 204/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9090 - loss: 0.2672\n",
      "Epoch 205/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9090 - loss: 0.2659\n",
      "Epoch 206/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.9100 - loss: 0.2683\n",
      "Epoch 207/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8910 - loss: 0.3404\n",
      "Epoch 208/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9210 - loss: 0.2617\n",
      "Epoch 209/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.9080 - loss: 0.2619\n",
      "Epoch 210/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9020 - loss: 0.2754\n",
      "Epoch 211/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.9150 - loss: 0.2625\n",
      "Epoch 212/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8790 - loss: 0.3901\n",
      "Epoch 213/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9150 - loss: 0.2604\n",
      "Epoch 214/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9170 - loss: 0.2569\n",
      "Epoch 215/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9160 - loss: 0.2606\n",
      "Epoch 216/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9080 - loss: 0.2681\n",
      "Epoch 217/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9230 - loss: 0.2589\n",
      "Epoch 218/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9130 - loss: 0.2607\n",
      "Epoch 219/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9000 - loss: 0.2840\n",
      "Epoch 220/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9090 - loss: 0.2539\n",
      "Epoch 221/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8890 - loss: 0.3416\n",
      "Epoch 222/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9170 - loss: 0.2529\n",
      "Epoch 223/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9210 - loss: 0.2506\n",
      "Epoch 224/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9120 - loss: 0.2563\n",
      "Epoch 225/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9080 - loss: 0.2568\n",
      "Epoch 226/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9110 - loss: 0.2581\n",
      "Epoch 227/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.9180 - loss: 0.2553\n",
      "Epoch 228/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.9090 - loss: 0.2748\n",
      "Epoch 229/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9000 - loss: 0.3330\n",
      "Epoch 230/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9280 - loss: 0.2437\n",
      "Epoch 231/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9220 - loss: 0.2460\n",
      "Epoch 232/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.9210 - loss: 0.2438\n",
      "Epoch 233/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.9200 - loss: 0.2454\n",
      "Epoch 234/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.8860 - loss: 0.3622\n",
      "Epoch 235/500\n",
      "1000/1000 - 5s - 5ms/step - accuracy: 0.9250 - loss: 0.2411\n",
      "Epoch 236/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9280 - loss: 0.2403\n",
      "Epoch 237/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9220 - loss: 0.2429\n",
      "Epoch 238/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8960 - loss: 0.3328\n",
      "Epoch 239/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.8960 - loss: 0.3660\n",
      "Epoch 240/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9330 - loss: 0.2375\n",
      "Epoch 241/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9320 - loss: 0.2362\n",
      "Epoch 242/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9280 - loss: 0.2383\n",
      "Epoch 243/500\n",
      "1000/1000 - 4s - 4ms/step - accuracy: 0.9200 - loss: 0.2418\n",
      "Epoch 244/500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/github/Classwork/Classwork-PythonDLApplicationDevelopment/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/github/Classwork/Classwork-PythonDLApplicationDevelopment/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/github/Classwork/Classwork-PythonDLApplicationDevelopment/.venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/github/Classwork/Classwork-PythonDLApplicationDevelopment/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/github/Classwork/Classwork-PythonDLApplicationDevelopment/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/github/Classwork/Classwork-PythonDLApplicationDevelopment/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[1;32m    131\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m--> 132\u001b[0m function \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/github/Classwork/Classwork-PythonDLApplicationDevelopment/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/github/Classwork/Classwork-PythonDLApplicationDevelopment/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:220\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39minput_signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m   args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    216\u001b[0m       \u001b[38;5;241m*\u001b[39mtracing_options\u001b[38;5;241m.\u001b[39minput_signature,\n\u001b[1;32m    217\u001b[0m       \u001b[38;5;241m*\u001b[39margs[\u001b[38;5;28mlen\u001b[39m(tracing_options\u001b[38;5;241m.\u001b[39minput_signature) :],\n\u001b[1;32m    218\u001b[0m   )\n\u001b[0;32m--> 220\u001b[0m current_func_context \u001b[38;5;241m=\u001b[39m \u001b[43mfunction_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_function_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscope_type\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m capture_types \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    225\u001b[0m     tracing_options\u001b[38;5;241m.\u001b[39mfunction_captures\u001b[38;5;241m.\u001b[39mcapture_types\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_captures\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    228\u001b[0m )\n\u001b[1;32m    229\u001b[0m lookup_func_type, lookup_func_context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    230\u001b[0m     function_type_utils\u001b[38;5;241m.\u001b[39mmake_canonicalized_monomorphic_type(\n\u001b[1;32m    231\u001b[0m         args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     )\n\u001b[1;32m    236\u001b[0m )\n",
      "File \u001b[0;32m~/github/Classwork/Classwork-PythonDLApplicationDevelopment/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/function_context.py:101\u001b[0m, in \u001b[0;36mmake_function_context\u001b[0;34m(scope_type)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m   variable_policy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function_cache\u001b[38;5;241m.\u001b[39mFunctionContext(\n\u001b[0;32m--> 101\u001b[0m     \u001b[43mEagerContext\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparent_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolocation_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43min_cross_replica_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvariable_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxla_context_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    109\u001b[0m     scope_type,\n\u001b[1;32m    110\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X, y, epochs=500, batch_size=batch_size, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP5. 評估模型準確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 92.20%\n"
     ]
    }
   ],
   "source": [
    "# 評估模型的性能\n",
    "scores = model.evaluate(X, y, verbose=0)\n",
    "print(\"Model Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP6. 預測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J'] -> L\n",
      "['H', 'I', 'J'] -> K\n",
      "['E', 'F'] -> G\n",
      "['K', 'L', 'M'] -> N\n",
      "['B'] -> C\n",
      "['C'] -> D\n",
      "['R', 'S'] -> T\n",
      "['A', 'B', 'C'] -> D\n",
      "['C', 'D', 'E'] -> F\n",
      "['N', 'O', 'P'] -> Q\n",
      "['C', 'D'] -> E\n",
      "['L', 'M'] -> N\n",
      "['F', 'G', 'H', 'I', 'J'] -> K\n",
      "['N', 'O', 'P', 'Q'] -> R\n",
      "['C', 'D', 'E', 'F', 'G'] -> H\n",
      "['A', 'B', 'C'] -> D\n",
      "['R', 'S', 'T', 'U', 'V'] -> W\n",
      "['B', 'C', 'D'] -> E\n",
      "['F', 'G'] -> H\n",
      "['K'] -> L\n"
     ]
    }
   ],
   "source": [
    "# 讓我們擷取1~5個字符轉成張量結構 shape:(1,5,1)來進行infer\n",
    "for i in range(20):\n",
    "    pattern_index = numpy.random.randint(len(dataX))\n",
    "    pattern = dataX[pattern_index]\n",
    "    x = pad_sequences([pattern], maxlen=max_len, dtype=\"float32\")\n",
    "    x = numpy.reshape(x, (1, max_len, 1))\n",
    "    x = x / float(len(alphabet))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    print(seq_in, \"->\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = numpy.array([[['L', 'M']]])#要改成數字\n",
    "# print(model.predict(a, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "我們可以看到，雖然這個網絡模型沒有從生成的序列資料中完全學習到英文字母表的順序，但它表現相當的好。如果需要, 我們可以對這個模型進行進一歩的優化與調整，比如更多的訓練循環(more epochs)或更大的網絡(larger network)，或兩者。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 參考:\n",
    "* Jason Brownlee - \"[Understanding Stateful LSTM Recurrent Neural Networks in Python with Keras](https://machinelearningmastery.com/understanding-stateful-lstm-recurrent-neural-networks-python-keras/)\"\n",
    "\n",
    "* Keras官網 - [Recurrent Layer](https://keras.io/layers/recurrent/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
