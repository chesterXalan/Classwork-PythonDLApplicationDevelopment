{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 循環神經網絡 LSTM (長短期記憶)來學習字母表順序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型 1. 用LSTM學習一個字符到一個字符映射"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP1. 匯入 Keras 及相關模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-19 16:23:59.630307: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-19 16:23:59.643189: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1729326239.659005   26753 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1729326239.662700   26753 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-19 16:23:59.679491: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import tensorflow.keras.utils as np_utils\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 給定隨機的種子, 以便讓大家跑起來的結果是相同的\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義序列數據集\n",
    "alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "\n",
    "# 創建字符映射到整數（0 - 25)和反相的查詢字典物件\n",
    "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(alphabet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "字母對應到數字編號: \n",
      " {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25}\n",
      "\n",
      "\n",
      "數字編號對應到字母: \n",
      " {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J', 10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z'}\n"
     ]
    }
   ],
   "source": [
    "print(\"字母對應到數字編號: \\n\", char_to_int)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"數字編號對應到字母: \\n\", int_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A -> B\n",
      "B -> C\n",
      "C -> D\n",
      "D -> E\n",
      "E -> F\n",
      "F -> G\n",
      "G -> H\n",
      "H -> I\n",
      "I -> J\n",
      "J -> K\n",
      "K -> L\n",
      "L -> M\n",
      "M -> N\n",
      "N -> O\n",
      "O -> P\n",
      "P -> Q\n",
      "Q -> R\n",
      "R -> S\n",
      "S -> T\n",
      "T -> U\n",
      "U -> V\n",
      "V -> W\n",
      "W -> X\n",
      "X -> Y\n",
      "Y -> Z\n"
     ]
    }
   ],
   "source": [
    "# 準備輸入數據集\n",
    "seq_length = 1\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, len(alphabet) - seq_length, 1):\n",
    "    seq_in = alphabet[i : i + seq_length]\n",
    "    seq_out = alphabet[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])  # 輸入:A~Y(25個字)\n",
    "    dataY.append(char_to_int[seq_out])  # 輸出:B~Z\n",
    "    print(seq_in, \"->\", seq_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料預處理\n",
    "我們需要將NumPy數組重塑為LSTM網絡所期望的格式，也就是: (samples, time_steps, features)。\n",
    "同時我們將進行資料的歸一化(normalize)來讓資料的值落於0到1之間。並對標籤值進行one-hot的編碼。\n",
    "\n",
    "\n",
    "> ABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
    "\n",
    "> 例如: \n",
    "\n",
    "> 給 J -> 預測 K\n",
    "\n",
    "> 給 X -> 預測 Y\n",
    "\n",
    "\n",
    "目標訓練張量結構: (samples, time_steps, features) -> (n , **1**, **1** )\n",
    "\n",
    "請特別注意, 這裡的1個字符會變成1個時間步裡頭的1個element的\"feature\"向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (25, 1, 1)\n",
      "y shape:  (25, 26)\n"
     ]
    }
   ],
   "source": [
    "# 重塑 X 資料的維度成為 (samples, time_steps, features)\n",
    "X = numpy.reshape(dataX, (len(dataX), seq_length, 1))  # 25組,1個字,1個特徵\n",
    "\n",
    "# 歸一化\n",
    "X = X / float(len(alphabet))\n",
    "\n",
    "# one-hot 編碼輸出變量\n",
    "y = np_utils.to_categorical(dataY)\n",
    "\n",
    "print(\"X shape: \", X.shape)  # (25筆samples, \"1\"個時間步長, 1個feature)\n",
    "print(\"y shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP5. 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ELSA\\anaconda3\\envs\\Py12\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">858</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │           \u001b[38;5;34m858\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,210</span> (20.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,210\u001b[0m (20.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,210</span> (20.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,210\u001b[0m (20.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 創建模型\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dense(y.shape[1], activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP6. 定義訓練並進行訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "25/25 - 1s - 31ms/step - accuracy: 0.0000e+00 - loss: 3.2661\n",
      "Epoch 2/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 3.2581\n",
      "Epoch 3/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 3.2556\n",
      "Epoch 4/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0400 - loss: 3.2527\n",
      "Epoch 5/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0400 - loss: 3.2501\n",
      "Epoch 6/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0400 - loss: 3.2474\n",
      "Epoch 7/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 3.2447\n",
      "Epoch 8/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0400 - loss: 3.2418\n",
      "Epoch 9/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0400 - loss: 3.2387\n",
      "Epoch 10/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 3.2354\n",
      "Epoch 11/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 3.2322\n",
      "Epoch 12/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0400 - loss: 3.2288\n",
      "Epoch 13/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 3.2249\n",
      "Epoch 14/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0400 - loss: 3.2208\n",
      "Epoch 15/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0400 - loss: 3.2166\n",
      "Epoch 16/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0400 - loss: 3.2121\n",
      "Epoch 17/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0400 - loss: 3.2065\n",
      "Epoch 18/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0400 - loss: 3.2015\n",
      "Epoch 19/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 3.1956\n",
      "Epoch 20/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 3.1901\n",
      "Epoch 21/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 3.1829\n",
      "Epoch 22/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 3.1761\n",
      "Epoch 23/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 3.1686\n",
      "Epoch 24/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 3.1609\n",
      "Epoch 25/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 3.1526\n",
      "Epoch 26/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 3.1438\n",
      "Epoch 27/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 3.1354\n",
      "Epoch 28/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 3.1258\n",
      "Epoch 29/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0400 - loss: 3.1161\n",
      "Epoch 30/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0400 - loss: 3.1061\n",
      "Epoch 31/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 3.0962\n",
      "Epoch 32/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 3.0856\n",
      "Epoch 33/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 3.0747\n",
      "Epoch 34/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0400 - loss: 3.0631\n",
      "Epoch 35/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 3.0513\n",
      "Epoch 36/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 3.0398\n",
      "Epoch 37/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 3.0264\n",
      "Epoch 38/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0400 - loss: 3.0141\n",
      "Epoch 39/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 3.0013\n",
      "Epoch 40/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.9876\n",
      "Epoch 41/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.1200 - loss: 2.9753\n",
      "Epoch 42/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.9632\n",
      "Epoch 43/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.9474\n",
      "Epoch 44/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0400 - loss: 2.9336\n",
      "Epoch 45/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.9209\n",
      "Epoch 46/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.9069\n",
      "Epoch 47/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0400 - loss: 2.8930\n",
      "Epoch 48/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0400 - loss: 2.8802\n",
      "Epoch 49/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0400 - loss: 2.8670\n",
      "Epoch 50/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.8542\n",
      "Epoch 51/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.8407\n",
      "Epoch 52/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.8281\n",
      "Epoch 53/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.8164\n",
      "Epoch 54/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.8037\n",
      "Epoch 55/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.7925\n",
      "Epoch 56/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.7804\n",
      "Epoch 57/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.7692\n",
      "Epoch 58/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.7591\n",
      "Epoch 59/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.7493\n",
      "Epoch 60/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.7387\n",
      "Epoch 61/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.7285\n",
      "Epoch 62/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.7188\n",
      "Epoch 63/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.7099\n",
      "Epoch 64/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.7011\n",
      "Epoch 65/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.6917\n",
      "Epoch 66/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.6825\n",
      "Epoch 67/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.6760\n",
      "Epoch 68/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.6672\n",
      "Epoch 69/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.6590\n",
      "Epoch 70/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.6512\n",
      "Epoch 71/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.6438\n",
      "Epoch 72/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.6381\n",
      "Epoch 73/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.6295\n",
      "Epoch 74/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.6224\n",
      "Epoch 75/500\n",
      "25/25 - 0s - 2ms/step - accuracy: 0.0800 - loss: 2.6160\n",
      "Epoch 76/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.6088\n",
      "Epoch 77/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.6019\n",
      "Epoch 78/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.5973\n",
      "Epoch 79/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.5889\n",
      "Epoch 80/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.1200 - loss: 2.5843\n",
      "Epoch 81/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.5771\n",
      "Epoch 82/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.1200 - loss: 2.5730\n",
      "Epoch 83/500\n",
      "25/25 - 0s - 2ms/step - accuracy: 0.1200 - loss: 2.5664\n",
      "Epoch 84/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.5601\n",
      "Epoch 85/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.5548\n",
      "Epoch 86/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.5492\n",
      "Epoch 87/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.5435\n",
      "Epoch 88/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.5377\n",
      "Epoch 89/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.5322\n",
      "Epoch 90/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.5275\n",
      "Epoch 91/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.5220\n",
      "Epoch 92/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.5160\n",
      "Epoch 93/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.1200 - loss: 2.5107\n",
      "Epoch 94/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.5054\n",
      "Epoch 95/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.5003\n",
      "Epoch 96/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.4951\n",
      "Epoch 97/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.4900\n",
      "Epoch 98/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.4849\n",
      "Epoch 99/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.4795\n",
      "Epoch 100/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.4756\n",
      "Epoch 101/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.1200 - loss: 2.4704\n",
      "Epoch 102/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.4653\n",
      "Epoch 103/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.4610\n",
      "Epoch 104/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.0800 - loss: 2.4565\n",
      "Epoch 105/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.1200 - loss: 2.4506\n",
      "Epoch 106/500\n",
      "25/25 - 0s - 2ms/step - accuracy: 0.0800 - loss: 2.4452\n",
      "Epoch 107/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.1200 - loss: 2.4408\n",
      "Epoch 108/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.1600 - loss: 2.4373\n",
      "Epoch 109/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.4324\n",
      "Epoch 110/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2000 - loss: 2.4270\n",
      "Epoch 111/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.1600 - loss: 2.4235\n",
      "Epoch 112/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2000 - loss: 2.4177\n",
      "Epoch 113/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2000 - loss: 2.4134\n",
      "Epoch 114/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2000 - loss: 2.4077\n",
      "Epoch 115/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2000 - loss: 2.4046\n",
      "Epoch 116/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2000 - loss: 2.4006\n",
      "Epoch 117/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2000 - loss: 2.3948\n",
      "Epoch 118/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.1600 - loss: 2.3900\n",
      "Epoch 119/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.3877\n",
      "Epoch 120/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.3825\n",
      "Epoch 121/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2000 - loss: 2.3791\n",
      "Epoch 122/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2000 - loss: 2.3723\n",
      "Epoch 123/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2000 - loss: 2.3694\n",
      "Epoch 124/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2000 - loss: 2.3647\n",
      "Epoch 125/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.3623\n",
      "Epoch 126/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2000 - loss: 2.3583\n",
      "Epoch 127/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2000 - loss: 2.3542\n",
      "Epoch 128/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.3510\n",
      "Epoch 129/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2000 - loss: 2.3456\n",
      "Epoch 130/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.3410\n",
      "Epoch 131/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2000 - loss: 2.3380\n",
      "Epoch 132/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.3338\n",
      "Epoch 133/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.3302\n",
      "Epoch 134/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2000 - loss: 2.3264\n",
      "Epoch 135/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2000 - loss: 2.3213\n",
      "Epoch 136/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.3183\n",
      "Epoch 137/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.1600 - loss: 2.3141\n",
      "Epoch 138/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.3111\n",
      "Epoch 139/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.3066\n",
      "Epoch 140/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2000 - loss: 2.3028\n",
      "Epoch 141/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.3001\n",
      "Epoch 142/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.2975\n",
      "Epoch 143/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.2913\n",
      "Epoch 144/500\n",
      "25/25 - 0s - 2ms/step - accuracy: 0.2400 - loss: 2.2885\n",
      "Epoch 145/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2800 - loss: 2.2860\n",
      "Epoch 146/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.2817\n",
      "Epoch 147/500\n",
      "25/25 - 0s - 2ms/step - accuracy: 0.2400 - loss: 2.2794\n",
      "Epoch 148/500\n",
      "25/25 - 0s - 2ms/step - accuracy: 0.2400 - loss: 2.2762\n",
      "Epoch 149/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.2719\n",
      "Epoch 150/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.2693\n",
      "Epoch 151/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.2643\n",
      "Epoch 152/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.2621\n",
      "Epoch 153/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.2581\n",
      "Epoch 154/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.2560\n",
      "Epoch 155/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.2522\n",
      "Epoch 156/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.2493\n",
      "Epoch 157/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2800 - loss: 2.2452\n",
      "Epoch 158/500\n",
      "25/25 - 0s - 2ms/step - accuracy: 0.2000 - loss: 2.2432\n",
      "Epoch 159/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.2390\n",
      "Epoch 160/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2000 - loss: 2.2356\n",
      "Epoch 161/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.2339\n",
      "Epoch 162/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2800 - loss: 2.2292\n",
      "Epoch 163/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2800 - loss: 2.2262\n",
      "Epoch 164/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2800 - loss: 2.2229\n",
      "Epoch 165/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.2202\n",
      "Epoch 166/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.2167\n",
      "Epoch 167/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2000 - loss: 2.2144\n",
      "Epoch 168/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2800 - loss: 2.2120\n",
      "Epoch 169/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2800 - loss: 2.2079\n",
      "Epoch 170/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.2056\n",
      "Epoch 171/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.3200 - loss: 2.2013\n",
      "Epoch 172/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2800 - loss: 2.1983\n",
      "Epoch 173/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.1966\n",
      "Epoch 174/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.1929\n",
      "Epoch 175/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.1901\n",
      "Epoch 176/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2800 - loss: 2.1874\n",
      "Epoch 177/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2400 - loss: 2.1852\n",
      "Epoch 178/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2800 - loss: 2.1815\n",
      "Epoch 179/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.3200 - loss: 2.1791\n",
      "Epoch 180/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2800 - loss: 2.1761\n",
      "Epoch 181/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2800 - loss: 2.1736\n",
      "Epoch 182/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.3200 - loss: 2.1714\n",
      "Epoch 183/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.3200 - loss: 2.1677\n",
      "Epoch 184/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2800 - loss: 2.1643\n",
      "Epoch 185/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.3200 - loss: 2.1627\n",
      "Epoch 186/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.3200 - loss: 2.1588\n",
      "Epoch 187/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.3600 - loss: 2.1577\n",
      "Epoch 188/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4000 - loss: 2.1547\n",
      "Epoch 189/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.3200 - loss: 2.1522\n",
      "Epoch 190/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.3200 - loss: 2.1482\n",
      "Epoch 191/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4000 - loss: 2.1462\n",
      "Epoch 192/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.3600 - loss: 2.1449\n",
      "Epoch 193/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.3200 - loss: 2.1412\n",
      "Epoch 194/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2800 - loss: 2.1394\n",
      "Epoch 195/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.2800 - loss: 2.1384\n",
      "Epoch 196/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.3200 - loss: 2.1350\n",
      "Epoch 197/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4000 - loss: 2.1310\n",
      "Epoch 198/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.3600 - loss: 2.1288\n",
      "Epoch 199/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4000 - loss: 2.1265\n",
      "Epoch 200/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4000 - loss: 2.1237\n",
      "Epoch 201/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.3200 - loss: 2.1220\n",
      "Epoch 202/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4000 - loss: 2.1190\n",
      "Epoch 203/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.3600 - loss: 2.1151\n",
      "Epoch 204/500\n",
      "25/25 - 0s - 2ms/step - accuracy: 0.2800 - loss: 2.1152\n",
      "Epoch 205/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4400 - loss: 2.1127\n",
      "Epoch 206/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4400 - loss: 2.1095\n",
      "Epoch 207/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.3600 - loss: 2.1069\n",
      "Epoch 208/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4000 - loss: 2.1036\n",
      "Epoch 209/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4000 - loss: 2.1017\n",
      "Epoch 210/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4000 - loss: 2.0998\n",
      "Epoch 211/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.3200 - loss: 2.0972\n",
      "Epoch 212/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.3600 - loss: 2.0956\n",
      "Epoch 213/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4000 - loss: 2.0938\n",
      "Epoch 214/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.3200 - loss: 2.0900\n",
      "Epoch 215/500\n",
      "25/25 - 0s - 2ms/step - accuracy: 0.4000 - loss: 2.0898\n",
      "Epoch 216/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.3200 - loss: 2.0885\n",
      "Epoch 217/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.3600 - loss: 2.0843\n",
      "Epoch 218/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.3600 - loss: 2.0808\n",
      "Epoch 219/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.3200 - loss: 2.0782\n",
      "Epoch 220/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4000 - loss: 2.0763\n",
      "Epoch 221/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4000 - loss: 2.0748\n",
      "Epoch 222/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4000 - loss: 2.0728\n",
      "Epoch 223/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4400 - loss: 2.0697\n",
      "Epoch 224/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4800 - loss: 2.0684\n",
      "Epoch 225/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4400 - loss: 2.0678\n",
      "Epoch 226/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.3600 - loss: 2.0643\n",
      "Epoch 227/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.3600 - loss: 2.0620\n",
      "Epoch 228/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4000 - loss: 2.0592\n",
      "Epoch 229/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4800 - loss: 2.0566\n",
      "Epoch 230/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4400 - loss: 2.0556\n",
      "Epoch 231/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4400 - loss: 2.0530\n",
      "Epoch 232/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4000 - loss: 2.0511\n",
      "Epoch 233/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4800 - loss: 2.0504\n",
      "Epoch 234/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4800 - loss: 2.0466\n",
      "Epoch 235/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4800 - loss: 2.0458\n",
      "Epoch 236/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4400 - loss: 2.0411\n",
      "Epoch 237/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5200 - loss: 2.0406\n",
      "Epoch 238/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4000 - loss: 2.0390\n",
      "Epoch 239/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.3600 - loss: 2.0367\n",
      "Epoch 240/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4800 - loss: 2.0348\n",
      "Epoch 241/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4800 - loss: 2.0332\n",
      "Epoch 242/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4800 - loss: 2.0302\n",
      "Epoch 243/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5200 - loss: 2.0277\n",
      "Epoch 244/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4800 - loss: 2.0253\n",
      "Epoch 245/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5600 - loss: 2.0271\n",
      "Epoch 246/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5200 - loss: 2.0215\n",
      "Epoch 247/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5200 - loss: 2.0201\n",
      "Epoch 248/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5600 - loss: 2.0199\n",
      "Epoch 249/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4400 - loss: 2.0189\n",
      "Epoch 250/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5600 - loss: 2.0143\n",
      "Epoch 251/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5200 - loss: 2.0140\n",
      "Epoch 252/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5200 - loss: 2.0118\n",
      "Epoch 253/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5200 - loss: 2.0117\n",
      "Epoch 254/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4400 - loss: 2.0076\n",
      "Epoch 255/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5200 - loss: 2.0039\n",
      "Epoch 256/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5200 - loss: 2.0030\n",
      "Epoch 257/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5600 - loss: 2.0016\n",
      "Epoch 258/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5600 - loss: 1.9991\n",
      "Epoch 259/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.9980\n",
      "Epoch 260/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5200 - loss: 1.9946\n",
      "Epoch 261/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5600 - loss: 1.9941\n",
      "Epoch 262/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5600 - loss: 1.9914\n",
      "Epoch 263/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5600 - loss: 1.9905\n",
      "Epoch 264/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4800 - loss: 1.9906\n",
      "Epoch 265/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4800 - loss: 1.9870\n",
      "Epoch 266/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.9851\n",
      "Epoch 267/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4800 - loss: 1.9839\n",
      "Epoch 268/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.9818\n",
      "Epoch 269/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5600 - loss: 1.9802\n",
      "Epoch 270/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5200 - loss: 1.9794\n",
      "Epoch 271/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5600 - loss: 1.9769\n",
      "Epoch 272/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.9746\n",
      "Epoch 273/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.9723\n",
      "Epoch 274/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5200 - loss: 1.9706\n",
      "Epoch 275/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.9696\n",
      "Epoch 276/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5200 - loss: 1.9686\n",
      "Epoch 277/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5600 - loss: 1.9666\n",
      "Epoch 278/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.9665\n",
      "Epoch 279/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5200 - loss: 1.9626\n",
      "Epoch 280/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.9615\n",
      "Epoch 281/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4800 - loss: 1.9606\n",
      "Epoch 282/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5200 - loss: 1.9573\n",
      "Epoch 283/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.9572\n",
      "Epoch 284/500\n",
      "25/25 - 0s - 2ms/step - accuracy: 0.6000 - loss: 1.9559\n",
      "Epoch 285/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.9510\n",
      "Epoch 286/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.9499\n",
      "Epoch 287/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.9486\n",
      "Epoch 288/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5600 - loss: 1.9486\n",
      "Epoch 289/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5600 - loss: 1.9448\n",
      "Epoch 290/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5600 - loss: 1.9439\n",
      "Epoch 291/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5200 - loss: 1.9422\n",
      "Epoch 292/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4800 - loss: 1.9408\n",
      "Epoch 293/500\n",
      "25/25 - 0s - 2ms/step - accuracy: 0.6400 - loss: 1.9383\n",
      "Epoch 294/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.9380\n",
      "Epoch 295/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4800 - loss: 1.9365\n",
      "Epoch 296/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.4800 - loss: 1.9340\n",
      "Epoch 297/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5600 - loss: 1.9324\n",
      "Epoch 298/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.9313\n",
      "Epoch 299/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.9294\n",
      "Epoch 300/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.9284\n",
      "Epoch 301/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.9265\n",
      "Epoch 302/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6800 - loss: 1.9236\n",
      "Epoch 303/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.9238\n",
      "Epoch 304/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5200 - loss: 1.9218\n",
      "Epoch 305/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5600 - loss: 1.9201\n",
      "Epoch 306/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5600 - loss: 1.9205\n",
      "Epoch 307/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5600 - loss: 1.9195\n",
      "Epoch 308/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.9159\n",
      "Epoch 309/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.9156\n",
      "Epoch 310/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6800 - loss: 1.9136\n",
      "Epoch 311/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5200 - loss: 1.9106\n",
      "Epoch 312/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6800 - loss: 1.9095\n",
      "Epoch 313/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.9085\n",
      "Epoch 314/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5200 - loss: 1.9063\n",
      "Epoch 315/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.9069\n",
      "Epoch 316/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6800 - loss: 1.9039\n",
      "Epoch 317/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.9036\n",
      "Epoch 318/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.9004\n",
      "Epoch 319/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.8991\n",
      "Epoch 320/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.8982\n",
      "Epoch 321/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.8973\n",
      "Epoch 322/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.8943\n",
      "Epoch 323/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.8934\n",
      "Epoch 324/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.8921\n",
      "Epoch 325/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.8923\n",
      "Epoch 326/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.8916\n",
      "Epoch 327/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5600 - loss: 1.8880\n",
      "Epoch 328/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.8863\n",
      "Epoch 329/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.8859\n",
      "Epoch 330/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6800 - loss: 1.8838\n",
      "Epoch 331/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.8834\n",
      "Epoch 332/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.8807\n",
      "Epoch 333/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5200 - loss: 1.8788\n",
      "Epoch 334/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.8792\n",
      "Epoch 335/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.8764\n",
      "Epoch 336/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.8768\n",
      "Epoch 337/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.8742\n",
      "Epoch 338/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6800 - loss: 1.8740\n",
      "Epoch 339/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.8720\n",
      "Epoch 340/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.8719\n",
      "Epoch 341/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.8697\n",
      "Epoch 342/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6800 - loss: 1.8670\n",
      "Epoch 343/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5600 - loss: 1.8669\n",
      "Epoch 344/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.8657\n",
      "Epoch 345/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.8654\n",
      "Epoch 346/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.8610\n",
      "Epoch 347/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5600 - loss: 1.8607\n",
      "Epoch 348/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.8596\n",
      "Epoch 349/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6800 - loss: 1.8570\n",
      "Epoch 350/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.8582\n",
      "Epoch 351/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.8557\n",
      "Epoch 352/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.8533\n",
      "Epoch 353/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.8535\n",
      "Epoch 354/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5200 - loss: 1.8519\n",
      "Epoch 355/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.8490\n",
      "Epoch 356/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6800 - loss: 1.8478\n",
      "Epoch 357/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.8476\n",
      "Epoch 358/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.8467\n",
      "Epoch 359/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.8464\n",
      "Epoch 360/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6800 - loss: 1.8434\n",
      "Epoch 361/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.8429\n",
      "Epoch 362/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.8405\n",
      "Epoch 363/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.8418\n",
      "Epoch 364/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6800 - loss: 1.8378\n",
      "Epoch 365/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.8370\n",
      "Epoch 366/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6800 - loss: 1.8362\n",
      "Epoch 367/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.8361\n",
      "Epoch 368/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.5600 - loss: 1.8350\n",
      "Epoch 369/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.8322\n",
      "Epoch 370/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.8323\n",
      "Epoch 371/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6000 - loss: 1.8291\n",
      "Epoch 372/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6800 - loss: 1.8287\n",
      "Epoch 373/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6800 - loss: 1.8289\n",
      "Epoch 374/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.8266\n",
      "Epoch 375/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.8268\n",
      "Epoch 376/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6800 - loss: 1.8256\n",
      "Epoch 377/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.8234\n",
      "Epoch 378/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.8212\n",
      "Epoch 379/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.8195\n",
      "Epoch 380/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.8203\n",
      "Epoch 381/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6800 - loss: 1.8195\n",
      "Epoch 382/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.8185\n",
      "Epoch 383/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.8163\n",
      "Epoch 384/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6800 - loss: 1.8130\n",
      "Epoch 385/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.8142\n",
      "Epoch 386/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.8119\n",
      "Epoch 387/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.8111\n",
      "Epoch 388/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.8098\n",
      "Epoch 389/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.8093\n",
      "Epoch 390/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.8090\n",
      "Epoch 391/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.8072\n",
      "Epoch 392/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.8050\n",
      "Epoch 393/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.8046\n",
      "Epoch 394/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.8034\n",
      "Epoch 395/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.8019\n",
      "Epoch 396/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.8010\n",
      "Epoch 397/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.8001\n",
      "Epoch 398/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.7986\n",
      "Epoch 399/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6800 - loss: 1.7988\n",
      "Epoch 400/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.7973\n",
      "Epoch 401/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.7950\n",
      "Epoch 402/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6800 - loss: 1.7941\n",
      "Epoch 403/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.7942\n",
      "Epoch 404/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.7935\n",
      "Epoch 405/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.7907\n",
      "Epoch 406/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6800 - loss: 1.7901\n",
      "Epoch 407/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.7880\n",
      "Epoch 408/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.7872\n",
      "Epoch 409/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.7863\n",
      "Epoch 410/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.7851\n",
      "Epoch 411/500\n",
      "25/25 - 0s - 2ms/step - accuracy: 0.7600 - loss: 1.7832\n",
      "Epoch 412/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.7823\n",
      "Epoch 413/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.7814\n",
      "Epoch 414/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.7818\n",
      "Epoch 415/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6800 - loss: 1.7794\n",
      "Epoch 416/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.7798\n",
      "Epoch 417/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.7793\n",
      "Epoch 418/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.7773\n",
      "Epoch 419/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6800 - loss: 1.7779\n",
      "Epoch 420/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.7731\n",
      "Epoch 421/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.7745\n",
      "Epoch 422/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8400 - loss: 1.7724\n",
      "Epoch 423/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.7729\n",
      "Epoch 424/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7716\n",
      "Epoch 425/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6800 - loss: 1.7686\n",
      "Epoch 426/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7689\n",
      "Epoch 427/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.7676\n",
      "Epoch 428/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8400 - loss: 1.7659\n",
      "Epoch 429/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.7665\n",
      "Epoch 430/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.7659\n",
      "Epoch 431/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7624\n",
      "Epoch 432/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.7628\n",
      "Epoch 433/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7617\n",
      "Epoch 434/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.7597\n",
      "Epoch 435/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.7590\n",
      "Epoch 436/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.7588\n",
      "Epoch 437/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.7550\n",
      "Epoch 438/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.7565\n",
      "Epoch 439/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.7554\n",
      "Epoch 440/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6800 - loss: 1.7531\n",
      "Epoch 441/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.7527\n",
      "Epoch 442/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6400 - loss: 1.7517\n",
      "Epoch 443/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.7512\n",
      "Epoch 444/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.7515\n",
      "Epoch 445/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.6800 - loss: 1.7499\n",
      "Epoch 446/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7488\n",
      "Epoch 447/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7446\n",
      "Epoch 448/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.7461\n",
      "Epoch 449/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.7451\n",
      "Epoch 450/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7456\n",
      "Epoch 451/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.7444\n",
      "Epoch 452/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.7441\n",
      "Epoch 453/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.7421\n",
      "Epoch 454/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7418\n",
      "Epoch 455/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7391\n",
      "Epoch 456/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.7382\n",
      "Epoch 457/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7348\n",
      "Epoch 458/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.7367\n",
      "Epoch 459/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.7362\n",
      "Epoch 460/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7332\n",
      "Epoch 461/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7333\n",
      "Epoch 462/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.7330\n",
      "Epoch 463/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.7317\n",
      "Epoch 464/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7286\n",
      "Epoch 465/500\n",
      "25/25 - 0s - 2ms/step - accuracy: 0.7200 - loss: 1.7291\n",
      "Epoch 466/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.7286\n",
      "Epoch 467/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7281\n",
      "Epoch 468/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.7279\n",
      "Epoch 469/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.7266\n",
      "Epoch 470/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7285\n",
      "Epoch 471/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7242\n",
      "Epoch 472/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7247\n",
      "Epoch 473/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.7214\n",
      "Epoch 474/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.7215\n",
      "Epoch 475/500\n",
      "25/25 - 0s - 2ms/step - accuracy: 0.8400 - loss: 1.7197\n",
      "Epoch 476/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7185\n",
      "Epoch 477/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7198\n",
      "Epoch 478/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7186\n",
      "Epoch 479/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7178\n",
      "Epoch 480/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7168\n",
      "Epoch 481/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.7139\n",
      "Epoch 482/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.7121\n",
      "Epoch 483/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.7129\n",
      "Epoch 484/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8400 - loss: 1.7122\n",
      "Epoch 485/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7122\n",
      "Epoch 486/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7090\n",
      "Epoch 487/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7088\n",
      "Epoch 488/500\n",
      "25/25 - 0s - 2ms/step - accuracy: 0.7600 - loss: 1.7068\n",
      "Epoch 489/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.7070\n",
      "Epoch 490/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8400 - loss: 1.7091\n",
      "Epoch 491/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7056\n",
      "Epoch 492/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7600 - loss: 1.7048\n",
      "Epoch 493/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7022\n",
      "Epoch 494/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7045\n",
      "Epoch 495/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.7025\n",
      "Epoch 496/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8400 - loss: 1.7021\n",
      "Epoch 497/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.7200 - loss: 1.6998\n",
      "Epoch 498/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.6988\n",
      "Epoch 499/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8400 - loss: 1.6986\n",
      "Epoch 500/500\n",
      "25/25 - 0s - 1ms/step - accuracy: 0.8000 - loss: 1.6984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1463190ad50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X, y, epochs=500, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP7. 評估模型準確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 84.00%\n"
     ]
    }
   ],
   "source": [
    "# 評估模型的性能\n",
    "scores = model.evaluate(X, y, verbose=0)\n",
    "print(\"Model Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP8. 預測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A'] -> B\n",
      "['B'] -> B\n",
      "['C'] -> D\n",
      "['D'] -> E\n",
      "['E'] -> F\n",
      "['F'] -> G\n",
      "['G'] -> H\n",
      "['H'] -> I\n",
      "['I'] -> J\n",
      "['J'] -> K\n",
      "['K'] -> L\n",
      "['L'] -> M\n",
      "['M'] -> N\n",
      "['N'] -> O\n",
      "['O'] -> P\n",
      "['P'] -> Q\n",
      "['Q'] -> R\n",
      "['R'] -> S\n",
      "['S'] -> T\n",
      "['T'] -> U\n",
      "['U'] -> W\n",
      "['V'] -> W\n",
      "['W'] -> Z\n",
      "['X'] -> Z\n",
      "['Y'] -> Z\n"
     ]
    }
   ],
   "source": [
    "# 展示模型預測能力\n",
    "for pattern in dataX:\n",
    "    # 把26個字母一個個拿進模型來預測會出現的字母\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(len(alphabet))\n",
    "\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)  # 機率最大的idx\n",
    "    result = int_to_char[index]  # 看看預測出來的是那一個字母\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    print(seq_in, \"->\", result)  # 打印結果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型 2. LSTM 學習三個字符特徵窗口(Three-Char Feature Window)到一個字符映射\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP1. 準備訓練用資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABC -> D\n",
      "BCD -> E\n",
      "CDE -> F\n",
      "DEF -> G\n",
      "EFG -> H\n",
      "FGH -> I\n",
      "GHI -> J\n",
      "HIJ -> K\n",
      "IJK -> L\n",
      "JKL -> M\n",
      "KLM -> N\n",
      "LMN -> O\n",
      "MNO -> P\n",
      "NOP -> Q\n",
      "OPQ -> R\n",
      "PQR -> S\n",
      "QRS -> T\n",
      "RST -> U\n",
      "STU -> V\n",
      "TUV -> W\n",
      "UVW -> X\n",
      "VWX -> Y\n",
      "WXY -> Z\n"
     ]
    }
   ],
   "source": [
    "# 準備輸入數據集\n",
    "seq_length = 3  # 這次我們要準備3個時間步長的資料\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, len(alphabet) - seq_length, 1):\n",
    "    seq_in = alphabet[i : i + seq_length]  # 3個字符\n",
    "    seq_out = alphabet[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "    print(seq_in, \"->\", seq_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP2. 資料預處理\n",
    "\n",
    "\n",
    "> ABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
    "\n",
    "> 例如: \n",
    "\n",
    "> 給 HIJ -> 預測 K\n",
    "\n",
    "> 給 EFG -> 預測 H\n",
    "\n",
    "目標訓練張量結構: (samples, time_steps, features) -> (n , **1**, **3** )\n",
    "\n",
    "請特別注意, 這裡的三個字符會變成一個有3個element的\"feature\" vector。因此在準備訓練資料集的時候, 1筆訓練資料只有\"1\"個時間步, 裡頭存放著\"3\"個字符的資料\"features\"向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (23, 1, 3)\n",
      "y shape:  (23, 26)\n"
     ]
    }
   ],
   "source": [
    "# 重塑 X 資料的維度成為 (samples, time_steps, features)\n",
    "X = numpy.reshape(dataX, (len(dataX), 1, seq_length))  # <-- 特別注意這裡\n",
    "\n",
    "# 歸一化\n",
    "X = X / float(len(alphabet))\n",
    "\n",
    "# 使用one hot encode 對Y值進行編碼\n",
    "y = np_utils.to_categorical(dataY)\n",
    "\n",
    "print(\"X shape: \", X.shape)\n",
    "print(\"y shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP3. 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,608</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">858</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,608\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │           \u001b[38;5;34m858\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,466</span> (21.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,466\u001b[0m (21.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,466</span> (21.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,466\u001b[0m (21.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 創建模型\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(X.shape[1], X.shape[2])))  # <-- 特別注意這裡\n",
    "model.add(Dense(y.shape[1], activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP4. 定義訓練並進行訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "23/23 - 1s - 40ms/step - accuracy: 0.0000e+00 - loss: 3.2668\n",
      "Epoch 2/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.2558\n",
      "Epoch 3/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.2508\n",
      "Epoch 4/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.2450\n",
      "Epoch 5/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.2394\n",
      "Epoch 6/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.2342\n",
      "Epoch 7/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.2276\n",
      "Epoch 8/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 3.2217\n",
      "Epoch 9/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.0435 - loss: 3.2146\n",
      "Epoch 10/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.2073\n",
      "Epoch 11/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.0435 - loss: 3.1992\n",
      "Epoch 12/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 3.1914\n",
      "Epoch 13/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.1823\n",
      "Epoch 14/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.1719\n",
      "Epoch 15/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.1629\n",
      "Epoch 16/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.1527\n",
      "Epoch 17/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 3.1432\n",
      "Epoch 18/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.1323\n",
      "Epoch 19/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.1216\n",
      "Epoch 20/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.1124\n",
      "Epoch 21/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.1039\n",
      "Epoch 22/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.0942\n",
      "Epoch 23/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.0848\n",
      "Epoch 24/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.0784\n",
      "Epoch 25/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.0688\n",
      "Epoch 26/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.0609\n",
      "Epoch 27/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.0542\n",
      "Epoch 28/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.0450\n",
      "Epoch 29/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.0378\n",
      "Epoch 30/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.0309\n",
      "Epoch 31/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.0224\n",
      "Epoch 32/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.0161\n",
      "Epoch 33/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.0078\n",
      "Epoch 34/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.0012\n",
      "Epoch 35/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 2.9930\n",
      "Epoch 36/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 2.9856\n",
      "Epoch 37/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.9780\n",
      "Epoch 38/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.9688\n",
      "Epoch 39/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.9608\n",
      "Epoch 40/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.9511\n",
      "Epoch 41/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.9437\n",
      "Epoch 42/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.9347\n",
      "Epoch 43/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.9242\n",
      "Epoch 44/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.9152\n",
      "Epoch 45/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.9060\n",
      "Epoch 46/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.8961\n",
      "Epoch 47/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.8869\n",
      "Epoch 48/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.8753\n",
      "Epoch 49/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.8650\n",
      "Epoch 50/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 2.8553\n",
      "Epoch 51/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.8431\n",
      "Epoch 52/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 2.8325\n",
      "Epoch 53/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 2.8234\n",
      "Epoch 54/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.8108\n",
      "Epoch 55/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.8012\n",
      "Epoch 56/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.7902\n",
      "Epoch 57/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 2.7788\n",
      "Epoch 58/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.7680\n",
      "Epoch 59/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.7573\n",
      "Epoch 60/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 2.7472\n",
      "Epoch 61/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.0435 - loss: 2.7359\n",
      "Epoch 62/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 2.7270\n",
      "Epoch 63/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 2.7148\n",
      "Epoch 64/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.7067\n",
      "Epoch 65/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.0435 - loss: 2.6964\n",
      "Epoch 66/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 2.6868\n",
      "Epoch 67/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.0870 - loss: 2.6764\n",
      "Epoch 68/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.0870 - loss: 2.6673\n",
      "Epoch 69/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.6594\n",
      "Epoch 70/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.6483\n",
      "Epoch 71/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.6402\n",
      "Epoch 72/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.1304 - loss: 2.6302\n",
      "Epoch 73/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.0870 - loss: 2.6230\n",
      "Epoch 74/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.6141\n",
      "Epoch 75/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.6072\n",
      "Epoch 76/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.5991\n",
      "Epoch 77/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.5909\n",
      "Epoch 78/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.5842\n",
      "Epoch 79/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.5759\n",
      "Epoch 80/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.5687\n",
      "Epoch 81/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.5616\n",
      "Epoch 82/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.5559\n",
      "Epoch 83/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.5497\n",
      "Epoch 84/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.5435\n",
      "Epoch 85/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.5352\n",
      "Epoch 86/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.5286\n",
      "Epoch 87/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.5232\n",
      "Epoch 88/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.5170\n",
      "Epoch 89/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.5116\n",
      "Epoch 90/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.5043\n",
      "Epoch 91/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.4991\n",
      "Epoch 92/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.4929\n",
      "Epoch 93/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.4888\n",
      "Epoch 94/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.4818\n",
      "Epoch 95/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.4773\n",
      "Epoch 96/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.4704\n",
      "Epoch 97/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.4656\n",
      "Epoch 98/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.4605\n",
      "Epoch 99/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.4552\n",
      "Epoch 100/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.4494\n",
      "Epoch 101/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.4432\n",
      "Epoch 102/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.4396\n",
      "Epoch 103/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.4336\n",
      "Epoch 104/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1739 - loss: 2.4298\n",
      "Epoch 105/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.4247\n",
      "Epoch 106/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.4180\n",
      "Epoch 107/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.4148\n",
      "Epoch 108/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.4091\n",
      "Epoch 109/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1739 - loss: 2.4050\n",
      "Epoch 110/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.3989\n",
      "Epoch 111/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1739 - loss: 2.3959\n",
      "Epoch 112/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.3903\n",
      "Epoch 113/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.3864\n",
      "Epoch 114/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.3814\n",
      "Epoch 115/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.3779\n",
      "Epoch 116/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1739 - loss: 2.3716\n",
      "Epoch 117/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1739 - loss: 2.3672\n",
      "Epoch 118/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1739 - loss: 2.3636\n",
      "Epoch 119/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.1739 - loss: 2.3587\n",
      "Epoch 120/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 2.3541\n",
      "Epoch 121/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 2.3516\n",
      "Epoch 122/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 2.3469\n",
      "Epoch 123/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 2.3408\n",
      "Epoch 124/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 2.3368\n",
      "Epoch 125/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.3331\n",
      "Epoch 126/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 2.3299\n",
      "Epoch 127/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 2.3240\n",
      "Epoch 128/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1739 - loss: 2.3201\n",
      "Epoch 129/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 2.3164\n",
      "Epoch 130/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1739 - loss: 2.3111\n",
      "Epoch 131/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.2174 - loss: 2.3081\n",
      "Epoch 132/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1739 - loss: 2.3042\n",
      "Epoch 133/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1739 - loss: 2.2996\n",
      "Epoch 134/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1739 - loss: 2.2963\n",
      "Epoch 135/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.2174 - loss: 2.2920\n",
      "Epoch 136/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1739 - loss: 2.2889\n",
      "Epoch 137/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1739 - loss: 2.2854\n",
      "Epoch 138/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1739 - loss: 2.2812\n",
      "Epoch 139/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1739 - loss: 2.2762\n",
      "Epoch 140/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.2174 - loss: 2.2743\n",
      "Epoch 141/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.2609 - loss: 2.2690\n",
      "Epoch 142/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1739 - loss: 2.2653\n",
      "Epoch 143/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 2.2625\n",
      "Epoch 144/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.2174 - loss: 2.2573\n",
      "Epoch 145/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.1739 - loss: 2.2534\n",
      "Epoch 146/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1739 - loss: 2.2517\n",
      "Epoch 147/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1739 - loss: 2.2480\n",
      "Epoch 148/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 2.2452\n",
      "Epoch 149/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 2.2388\n",
      "Epoch 150/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 2.2347\n",
      "Epoch 151/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 2.2332\n",
      "Epoch 152/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1739 - loss: 2.2305\n",
      "Epoch 153/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 2.2246\n",
      "Epoch 154/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 2.2231\n",
      "Epoch 155/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1739 - loss: 2.2192\n",
      "Epoch 156/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.2153\n",
      "Epoch 157/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.1739 - loss: 2.2125\n",
      "Epoch 158/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.2090\n",
      "Epoch 159/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.2054\n",
      "Epoch 160/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 2.2020\n",
      "Epoch 161/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1739 - loss: 2.2012\n",
      "Epoch 162/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 2.1964\n",
      "Epoch 163/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3043 - loss: 2.1941\n",
      "Epoch 164/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.1892\n",
      "Epoch 165/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.1880\n",
      "Epoch 166/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 2.1826\n",
      "Epoch 167/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 2.1787\n",
      "Epoch 168/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 2.1766\n",
      "Epoch 169/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.1732\n",
      "Epoch 170/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.1689\n",
      "Epoch 171/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.1647\n",
      "Epoch 172/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3043 - loss: 2.1643\n",
      "Epoch 173/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3478 - loss: 2.1582\n",
      "Epoch 174/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3478 - loss: 2.1566\n",
      "Epoch 175/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.1529\n",
      "Epoch 176/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.1513\n",
      "Epoch 177/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.1491\n",
      "Epoch 178/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.1440\n",
      "Epoch 179/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.1439\n",
      "Epoch 180/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.1380\n",
      "Epoch 181/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.1379\n",
      "Epoch 182/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.1326\n",
      "Epoch 183/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.1316\n",
      "Epoch 184/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.1265\n",
      "Epoch 185/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 2.1244\n",
      "Epoch 186/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.1227\n",
      "Epoch 187/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3043 - loss: 2.1193\n",
      "Epoch 188/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.1169\n",
      "Epoch 189/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1739 - loss: 2.1138\n",
      "Epoch 190/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3043 - loss: 2.1105\n",
      "Epoch 191/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3478 - loss: 2.1069\n",
      "Epoch 192/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 2.1071\n",
      "Epoch 193/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.1036\n",
      "Epoch 194/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3043 - loss: 2.0986\n",
      "Epoch 195/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.4348 - loss: 2.0963\n",
      "Epoch 196/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.0953\n",
      "Epoch 197/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3478 - loss: 2.0915\n",
      "Epoch 198/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3913 - loss: 2.0890\n",
      "Epoch 199/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.2609 - loss: 2.0869\n",
      "Epoch 200/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.0825\n",
      "Epoch 201/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3043 - loss: 2.0822\n",
      "Epoch 202/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.0800\n",
      "Epoch 203/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3478 - loss: 2.0758\n",
      "Epoch 204/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3913 - loss: 2.0743\n",
      "Epoch 205/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3478 - loss: 2.0707\n",
      "Epoch 206/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.0679\n",
      "Epoch 207/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.3478 - loss: 2.0645\n",
      "Epoch 208/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3043 - loss: 2.0630\n",
      "Epoch 209/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.3043 - loss: 2.0606\n",
      "Epoch 210/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.0579\n",
      "Epoch 211/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3478 - loss: 2.0553\n",
      "Epoch 212/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3043 - loss: 2.0552\n",
      "Epoch 213/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3043 - loss: 2.0488\n",
      "Epoch 214/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3913 - loss: 2.0497\n",
      "Epoch 215/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3913 - loss: 2.0456\n",
      "Epoch 216/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3478 - loss: 2.0435\n",
      "Epoch 217/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3913 - loss: 2.0415\n",
      "Epoch 218/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3478 - loss: 2.0376\n",
      "Epoch 219/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.0364\n",
      "Epoch 220/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4348 - loss: 2.0340\n",
      "Epoch 221/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.3913 - loss: 2.0325\n",
      "Epoch 222/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3913 - loss: 2.0302\n",
      "Epoch 223/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3913 - loss: 2.0279\n",
      "Epoch 224/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4783 - loss: 2.0241\n",
      "Epoch 225/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3913 - loss: 2.0206\n",
      "Epoch 226/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4348 - loss: 2.0179\n",
      "Epoch 227/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.4348 - loss: 2.0182\n",
      "Epoch 228/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.4348 - loss: 2.0156\n",
      "Epoch 229/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3913 - loss: 2.0142\n",
      "Epoch 230/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4348 - loss: 2.0097\n",
      "Epoch 231/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4783 - loss: 2.0080\n",
      "Epoch 232/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4348 - loss: 2.0053\n",
      "Epoch 233/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3913 - loss: 2.0031\n",
      "Epoch 234/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3913 - loss: 2.0023\n",
      "Epoch 235/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4783 - loss: 2.0000\n",
      "Epoch 236/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3913 - loss: 1.9966\n",
      "Epoch 237/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3913 - loss: 1.9950\n",
      "Epoch 238/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4348 - loss: 1.9936\n",
      "Epoch 239/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4783 - loss: 1.9930\n",
      "Epoch 240/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4348 - loss: 1.9879\n",
      "Epoch 241/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3478 - loss: 1.9866\n",
      "Epoch 242/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4348 - loss: 1.9851\n",
      "Epoch 243/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4348 - loss: 1.9839\n",
      "Epoch 244/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4348 - loss: 1.9800\n",
      "Epoch 245/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5217 - loss: 1.9779\n",
      "Epoch 246/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4783 - loss: 1.9774\n",
      "Epoch 247/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5652 - loss: 1.9746\n",
      "Epoch 248/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5217 - loss: 1.9718\n",
      "Epoch 249/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4783 - loss: 1.9707\n",
      "Epoch 250/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5217 - loss: 1.9671\n",
      "Epoch 251/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4348 - loss: 1.9636\n",
      "Epoch 252/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4783 - loss: 1.9639\n",
      "Epoch 253/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.5652 - loss: 1.9594\n",
      "Epoch 254/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6087 - loss: 1.9591\n",
      "Epoch 255/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4348 - loss: 1.9581\n",
      "Epoch 256/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4348 - loss: 1.9568\n",
      "Epoch 257/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3913 - loss: 1.9535\n",
      "Epoch 258/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4783 - loss: 1.9506\n",
      "Epoch 259/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5217 - loss: 1.9519\n",
      "Epoch 260/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5652 - loss: 1.9487\n",
      "Epoch 261/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5217 - loss: 1.9447\n",
      "Epoch 262/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.5217 - loss: 1.9449\n",
      "Epoch 263/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5652 - loss: 1.9411\n",
      "Epoch 264/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.6087 - loss: 1.9408\n",
      "Epoch 265/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5217 - loss: 1.9388\n",
      "Epoch 266/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.5217 - loss: 1.9366\n",
      "Epoch 267/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4348 - loss: 1.9360\n",
      "Epoch 268/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.5652 - loss: 1.9318\n",
      "Epoch 269/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4783 - loss: 1.9293\n",
      "Epoch 270/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5217 - loss: 1.9298\n",
      "Epoch 271/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4783 - loss: 1.9281\n",
      "Epoch 272/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.5652 - loss: 1.9258\n",
      "Epoch 273/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4783 - loss: 1.9226\n",
      "Epoch 274/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5217 - loss: 1.9216\n",
      "Epoch 275/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5217 - loss: 1.9182\n",
      "Epoch 276/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5217 - loss: 1.9192\n",
      "Epoch 277/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5652 - loss: 1.9144\n",
      "Epoch 278/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.5217 - loss: 1.9116\n",
      "Epoch 279/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5217 - loss: 1.9123\n",
      "Epoch 280/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5652 - loss: 1.9076\n",
      "Epoch 281/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5652 - loss: 1.9072\n",
      "Epoch 282/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5217 - loss: 1.9054\n",
      "Epoch 283/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6087 - loss: 1.9050\n",
      "Epoch 284/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.9024\n",
      "Epoch 285/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6087 - loss: 1.9035\n",
      "Epoch 286/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5217 - loss: 1.9000\n",
      "Epoch 287/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4783 - loss: 1.8986\n",
      "Epoch 288/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.5652 - loss: 1.8956\n",
      "Epoch 289/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.8929\n",
      "Epoch 290/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5217 - loss: 1.8895\n",
      "Epoch 291/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5217 - loss: 1.8913\n",
      "Epoch 292/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5217 - loss: 1.8883\n",
      "Epoch 293/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5652 - loss: 1.8866\n",
      "Epoch 294/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.8836\n",
      "Epoch 295/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4783 - loss: 1.8823\n",
      "Epoch 296/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5652 - loss: 1.8836\n",
      "Epoch 297/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.5217 - loss: 1.8790\n",
      "Epoch 298/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5217 - loss: 1.8774\n",
      "Epoch 299/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6087 - loss: 1.8756\n",
      "Epoch 300/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.8755\n",
      "Epoch 301/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6087 - loss: 1.8732\n",
      "Epoch 302/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5217 - loss: 1.8705\n",
      "Epoch 303/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6087 - loss: 1.8704\n",
      "Epoch 304/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6087 - loss: 1.8681\n",
      "Epoch 305/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5652 - loss: 1.8664\n",
      "Epoch 306/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5652 - loss: 1.8677\n",
      "Epoch 307/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6087 - loss: 1.8641\n",
      "Epoch 308/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5652 - loss: 1.8609\n",
      "Epoch 309/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.8594\n",
      "Epoch 310/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.8572\n",
      "Epoch 311/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6087 - loss: 1.8558\n",
      "Epoch 312/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.8563\n",
      "Epoch 313/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.8531\n",
      "Epoch 314/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.8530\n",
      "Epoch 315/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6087 - loss: 1.8512\n",
      "Epoch 316/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6087 - loss: 1.8495\n",
      "Epoch 317/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4783 - loss: 1.8480\n",
      "Epoch 318/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.8447\n",
      "Epoch 319/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.8438\n",
      "Epoch 320/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.8426\n",
      "Epoch 321/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.8403\n",
      "Epoch 322/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6087 - loss: 1.8398\n",
      "Epoch 323/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.8368\n",
      "Epoch 324/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.8333\n",
      "Epoch 325/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.8332\n",
      "Epoch 326/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.8337\n",
      "Epoch 327/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.8302\n",
      "Epoch 328/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6087 - loss: 1.8293\n",
      "Epoch 329/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.8276\n",
      "Epoch 330/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5652 - loss: 1.8278\n",
      "Epoch 331/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6087 - loss: 1.8250\n",
      "Epoch 332/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.8254\n",
      "Epoch 333/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6087 - loss: 1.8231\n",
      "Epoch 334/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6087 - loss: 1.8202\n",
      "Epoch 335/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.8198\n",
      "Epoch 336/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.6957 - loss: 1.8193\n",
      "Epoch 337/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.8141\n",
      "Epoch 338/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.8150\n",
      "Epoch 339/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.8128\n",
      "Epoch 340/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5652 - loss: 1.8126\n",
      "Epoch 341/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6087 - loss: 1.8100\n",
      "Epoch 342/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.8091\n",
      "Epoch 343/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.6957 - loss: 1.8090\n",
      "Epoch 344/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5652 - loss: 1.8081\n",
      "Epoch 345/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.8031\n",
      "Epoch 346/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.8026\n",
      "Epoch 347/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.6957 - loss: 1.8016\n",
      "Epoch 348/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.8011\n",
      "Epoch 349/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.8004\n",
      "Epoch 350/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.7960\n",
      "Epoch 351/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.7977\n",
      "Epoch 352/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6087 - loss: 1.7953\n",
      "Epoch 353/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.7927\n",
      "Epoch 354/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.7930\n",
      "Epoch 355/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.7932\n",
      "Epoch 356/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.7863\n",
      "Epoch 357/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.7864\n",
      "Epoch 358/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.7853\n",
      "Epoch 359/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.7835\n",
      "Epoch 360/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.7822\n",
      "Epoch 361/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.7808\n",
      "Epoch 362/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.7816\n",
      "Epoch 363/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.7795\n",
      "Epoch 364/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.6522 - loss: 1.7777\n",
      "Epoch 365/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.7760\n",
      "Epoch 366/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.7741\n",
      "Epoch 367/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.7739\n",
      "Epoch 368/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.7720\n",
      "Epoch 369/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.7391 - loss: 1.7732\n",
      "Epoch 370/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.7694\n",
      "Epoch 371/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.6957 - loss: 1.7707\n",
      "Epoch 372/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.7696\n",
      "Epoch 373/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.7684\n",
      "Epoch 374/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.7641\n",
      "Epoch 375/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.7640\n",
      "Epoch 376/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.7625\n",
      "Epoch 377/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.7622\n",
      "Epoch 378/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.7582\n",
      "Epoch 379/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.7579\n",
      "Epoch 380/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.7571\n",
      "Epoch 381/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.7553\n",
      "Epoch 382/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.7541\n",
      "Epoch 383/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.7551\n",
      "Epoch 384/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.7530\n",
      "Epoch 385/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.7512\n",
      "Epoch 386/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.7496\n",
      "Epoch 387/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.7479\n",
      "Epoch 388/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.7486\n",
      "Epoch 389/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.7451\n",
      "Epoch 390/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.7435\n",
      "Epoch 391/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.7424\n",
      "Epoch 392/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.7426\n",
      "Epoch 393/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.7410\n",
      "Epoch 394/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.7387\n",
      "Epoch 395/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.7378\n",
      "Epoch 396/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.7372\n",
      "Epoch 397/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.7391 - loss: 1.7357\n",
      "Epoch 398/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.7352\n",
      "Epoch 399/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.7333\n",
      "Epoch 400/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.7329\n",
      "Epoch 401/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.7290\n",
      "Epoch 402/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.7298\n",
      "Epoch 403/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.7296\n",
      "Epoch 404/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.7277\n",
      "Epoch 405/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.7266\n",
      "Epoch 406/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.7271\n",
      "Epoch 407/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.7232\n",
      "Epoch 408/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.7246\n",
      "Epoch 409/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.7826 - loss: 1.7195\n",
      "Epoch 410/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.7226\n",
      "Epoch 411/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.7190\n",
      "Epoch 412/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.7193\n",
      "Epoch 413/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.7163\n",
      "Epoch 414/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.7159\n",
      "Epoch 415/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.7145\n",
      "Epoch 416/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.6087 - loss: 1.7140\n",
      "Epoch 417/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.7391 - loss: 1.7127\n",
      "Epoch 418/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.7108\n",
      "Epoch 419/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.7109\n",
      "Epoch 420/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.7095\n",
      "Epoch 421/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.7065\n",
      "Epoch 422/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.7088\n",
      "Epoch 423/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.7068\n",
      "Epoch 424/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.7026\n",
      "Epoch 425/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.7391 - loss: 1.7016\n",
      "Epoch 426/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.7032\n",
      "Epoch 427/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.7826 - loss: 1.7004\n",
      "Epoch 428/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.6969\n",
      "Epoch 429/500\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.6957 - loss: 1.6978\n",
      "Epoch 430/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.7391 - loss: 1.6955\n",
      "Epoch 431/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.6947\n",
      "Epoch 432/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.6958\n",
      "Epoch 433/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.6934\n",
      "Epoch 434/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.6946\n",
      "Epoch 435/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.6929\n",
      "Epoch 436/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.6918\n",
      "Epoch 437/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.6891\n",
      "Epoch 438/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.6892\n",
      "Epoch 439/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.6870\n",
      "Epoch 440/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.6847\n",
      "Epoch 441/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.6852\n",
      "Epoch 442/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.6836\n",
      "Epoch 443/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.7826 - loss: 1.6831\n",
      "Epoch 444/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.6816\n",
      "Epoch 445/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.6792\n",
      "Epoch 446/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.6798\n",
      "Epoch 447/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.6772\n",
      "Epoch 448/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.6778\n",
      "Epoch 449/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.6771\n",
      "Epoch 450/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.6778\n",
      "Epoch 451/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.6734\n",
      "Epoch 452/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.6732\n",
      "Epoch 453/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.6703\n",
      "Epoch 454/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.6711\n",
      "Epoch 455/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.6688\n",
      "Epoch 456/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.6703\n",
      "Epoch 457/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.6673\n",
      "Epoch 458/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.6674\n",
      "Epoch 459/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.6664\n",
      "Epoch 460/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.6639\n",
      "Epoch 461/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 1.6638\n",
      "Epoch 462/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.6617\n",
      "Epoch 463/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.6634\n",
      "Epoch 464/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.6599\n",
      "Epoch 465/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.6601\n",
      "Epoch 466/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.6583\n",
      "Epoch 467/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.6588\n",
      "Epoch 468/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.6565\n",
      "Epoch 469/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.6565\n",
      "Epoch 470/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.6547\n",
      "Epoch 471/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.6523\n",
      "Epoch 472/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.6525\n",
      "Epoch 473/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.6531\n",
      "Epoch 474/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.8261 - loss: 1.6486\n",
      "Epoch 475/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.6487\n",
      "Epoch 476/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.6501\n",
      "Epoch 477/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.8261 - loss: 1.6467\n",
      "Epoch 478/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.6463\n",
      "Epoch 479/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.6439\n",
      "Epoch 480/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.6427\n",
      "Epoch 481/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.6424\n",
      "Epoch 482/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.6408\n",
      "Epoch 483/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.8696 - loss: 1.6415\n",
      "Epoch 484/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.8261 - loss: 1.6388\n",
      "Epoch 485/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.6409\n",
      "Epoch 486/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.6392\n",
      "Epoch 487/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.6343\n",
      "Epoch 488/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.6395\n",
      "Epoch 489/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.6360\n",
      "Epoch 490/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 1.6342\n",
      "Epoch 491/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.6330\n",
      "Epoch 492/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.6318\n",
      "Epoch 493/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.6315\n",
      "Epoch 494/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.6280\n",
      "Epoch 495/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.6292\n",
      "Epoch 496/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.6284\n",
      "Epoch 497/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.6278\n",
      "Epoch 498/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.6253\n",
      "Epoch 499/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.7826 - loss: 1.6267\n",
      "Epoch 500/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.6241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x296cb341a60>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X, y, epochs=500, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP5. 評估模型準確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 86.96%\n"
     ]
    }
   ],
   "source": [
    "# 評估模型的性能\n",
    "scores = model.evaluate(X, y, verbose=0)\n",
    "print(\"Model Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP6. 預測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C'] -> D\n",
      "['B', 'C', 'D'] -> E\n",
      "['C', 'D', 'E'] -> F\n",
      "['D', 'E', 'F'] -> G\n",
      "['E', 'F', 'G'] -> H\n",
      "['F', 'G', 'H'] -> I\n",
      "['G', 'H', 'I'] -> J\n",
      "['H', 'I', 'J'] -> K\n",
      "['I', 'J', 'K'] -> L\n",
      "['J', 'K', 'L'] -> M\n",
      "['K', 'L', 'M'] -> N\n",
      "['L', 'M', 'N'] -> O\n",
      "['M', 'N', 'O'] -> P\n",
      "['N', 'O', 'P'] -> Q\n",
      "['O', 'P', 'Q'] -> R\n",
      "['P', 'Q', 'R'] -> S\n",
      "['Q', 'R', 'S'] -> T\n",
      "['R', 'S', 'T'] -> U\n",
      "['S', 'T', 'U'] -> V\n",
      "['T', 'U', 'V'] -> X\n",
      "['U', 'V', 'W'] -> Z\n",
      "['V', 'W', 'X'] -> Z\n",
      "['W', 'X', 'Y'] -> Z\n"
     ]
    }
   ],
   "source": [
    "# 展示一些模型預測\n",
    "for pattern in dataX:\n",
    "    x = numpy.reshape(pattern, (1, 1, len(pattern)))\n",
    "    x = x / float(len(alphabet))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    print(seq_in, \"->\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型 3. LSTM 學習三個字符的時間步驟窗口(Three-Char Time Step Window)到一個字符的映射"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP1. 準備訓練用資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABC -> D\n",
      "BCD -> E\n",
      "CDE -> F\n",
      "DEF -> G\n",
      "EFG -> H\n",
      "FGH -> I\n",
      "GHI -> J\n",
      "HIJ -> K\n",
      "IJK -> L\n",
      "JKL -> M\n",
      "KLM -> N\n",
      "LMN -> O\n",
      "MNO -> P\n",
      "NOP -> Q\n",
      "OPQ -> R\n",
      "PQR -> S\n",
      "QRS -> T\n",
      "RST -> U\n",
      "STU -> V\n",
      "TUV -> W\n",
      "UVW -> X\n",
      "VWX -> Y\n",
      "WXY -> Z\n"
     ]
    }
   ],
   "source": [
    "seq_length = 3\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, len(alphabet) - seq_length, 1):\n",
    "    seq_in = alphabet[i : i + seq_length]\n",
    "    seq_out = alphabet[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "    print(seq_in, \"->\", seq_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP2. 資料預處理\n",
    "\n",
    "\n",
    "> ABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
    "\n",
    "> 例如: \n",
    "\n",
    "> 給 HIJ -> 預測 K\n",
    "\n",
    "> 給 EFG -> 預測 H\n",
    "\n",
    "目標訓練張量結構: (samples, time_steps, features) -> (n , **3**, **1** )\n",
    "\n",
    "準備訓練資料集的時候要把資料的張量結構轉換成, 1筆訓練資料有\"3\"個時間步, 裡頭存放著\"1\"個字符的資料\"features\"向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 重塑 X 資料的維度成為 (samples, time_steps, features)\n",
    "X = numpy.reshape(dataX, (len(dataX), seq_length, 1))  # <-- 特別注意這裡\n",
    "\n",
    "# 歸一化\n",
    "X = X / float(len(alphabet))\n",
    "\n",
    "# 使用one hot encode 對Y值進行編碼\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP3. 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">858</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │           \u001b[38;5;34m858\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,210</span> (20.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,210\u001b[0m (20.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,210</span> (20.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,210\u001b[0m (20.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 創建模型\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(X.shape[1], X.shape[2])))  # <-- 特別注意這裡\n",
    "model.add(Dense(y.shape[1], activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP4. 定義訓練並進行訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "23/23 - 1s - 37ms/step - accuracy: 0.0000e+00 - loss: 3.2682\n",
      "Epoch 2/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.2532\n",
      "Epoch 3/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.2448\n",
      "Epoch 4/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.0435 - loss: 3.2372\n",
      "Epoch 5/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.0435 - loss: 3.2286\n",
      "Epoch 6/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.0435 - loss: 3.2211\n",
      "Epoch 7/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.0435 - loss: 3.2119\n",
      "Epoch 8/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.0435 - loss: 3.2011\n",
      "Epoch 9/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.1892\n",
      "Epoch 10/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.0435 - loss: 3.1765\n",
      "Epoch 11/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.0435 - loss: 3.1620\n",
      "Epoch 12/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.1454\n",
      "Epoch 13/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.0435 - loss: 3.1285\n",
      "Epoch 14/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.1116\n",
      "Epoch 15/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.0435 - loss: 3.0939\n",
      "Epoch 16/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.0435 - loss: 3.0759\n",
      "Epoch 17/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.0573\n",
      "Epoch 18/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 3.0408\n",
      "Epoch 19/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 3.0235\n",
      "Epoch 20/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 3.0013\n",
      "Epoch 21/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.9793\n",
      "Epoch 22/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.9559\n",
      "Epoch 23/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.0870 - loss: 2.9304\n",
      "Epoch 24/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.0870 - loss: 2.9019\n",
      "Epoch 25/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.8745\n",
      "Epoch 26/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.0870 - loss: 2.8425\n",
      "Epoch 27/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.8083\n",
      "Epoch 28/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.0870 - loss: 2.7706\n",
      "Epoch 29/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.7351\n",
      "Epoch 30/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.0870 - loss: 2.6974\n",
      "Epoch 31/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.6617\n",
      "Epoch 32/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.0870 - loss: 2.6213\n",
      "Epoch 33/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.5895\n",
      "Epoch 34/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.5620\n",
      "Epoch 35/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.5285\n",
      "Epoch 36/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.5023\n",
      "Epoch 37/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.0435 - loss: 2.4783\n",
      "Epoch 38/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0435 - loss: 2.4528\n",
      "Epoch 39/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.0870 - loss: 2.4269\n",
      "Epoch 40/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.0870 - loss: 2.4058\n",
      "Epoch 41/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.3806\n",
      "Epoch 42/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.3639\n",
      "Epoch 43/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.0870 - loss: 2.3372\n",
      "Epoch 44/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1739 - loss: 2.3123\n",
      "Epoch 45/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.2174 - loss: 2.2930\n",
      "Epoch 46/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1739 - loss: 2.2762\n",
      "Epoch 47/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.2174 - loss: 2.2483\n",
      "Epoch 48/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 2.2304\n",
      "Epoch 49/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.2119\n",
      "Epoch 50/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 2.1917\n",
      "Epoch 51/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.1749\n",
      "Epoch 52/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1304 - loss: 2.1587\n",
      "Epoch 53/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 2.1358\n",
      "Epoch 54/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.1230\n",
      "Epoch 55/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1739 - loss: 2.1099\n",
      "Epoch 56/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 2.0878\n",
      "Epoch 57/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.0731\n",
      "Epoch 58/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 2.0533\n",
      "Epoch 59/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2609 - loss: 2.0405\n",
      "Epoch 60/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.2609 - loss: 2.0280\n",
      "Epoch 61/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1739 - loss: 2.0162\n",
      "Epoch 62/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 1.9987\n",
      "Epoch 63/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.2174 - loss: 1.9828\n",
      "Epoch 64/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3043 - loss: 1.9639\n",
      "Epoch 65/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3043 - loss: 1.9544\n",
      "Epoch 66/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.1739 - loss: 1.9416\n",
      "Epoch 67/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3043 - loss: 1.9223\n",
      "Epoch 68/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.3478 - loss: 1.9179\n",
      "Epoch 69/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4348 - loss: 1.8935\n",
      "Epoch 70/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3478 - loss: 1.8878\n",
      "Epoch 71/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.3478 - loss: 1.8864\n",
      "Epoch 72/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3043 - loss: 1.8654\n",
      "Epoch 73/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3913 - loss: 1.8436\n",
      "Epoch 74/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.5217 - loss: 1.8402\n",
      "Epoch 75/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4348 - loss: 1.8235\n",
      "Epoch 76/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4783 - loss: 1.8125\n",
      "Epoch 77/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.3043 - loss: 1.7946\n",
      "Epoch 78/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4783 - loss: 1.7883\n",
      "Epoch 79/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.4348 - loss: 1.7763\n",
      "Epoch 80/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4348 - loss: 1.7731\n",
      "Epoch 81/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5217 - loss: 1.7511\n",
      "Epoch 82/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5217 - loss: 1.7366\n",
      "Epoch 83/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5652 - loss: 1.7262\n",
      "Epoch 84/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5652 - loss: 1.7136\n",
      "Epoch 85/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5217 - loss: 1.6988\n",
      "Epoch 86/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5652 - loss: 1.6927\n",
      "Epoch 87/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.4783 - loss: 1.6861\n",
      "Epoch 88/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5652 - loss: 1.6729\n",
      "Epoch 89/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.6657\n",
      "Epoch 90/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.6522 - loss: 1.6503\n",
      "Epoch 91/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5652 - loss: 1.6431\n",
      "Epoch 92/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6087 - loss: 1.6336\n",
      "Epoch 93/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5217 - loss: 1.6161\n",
      "Epoch 94/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.6957 - loss: 1.6137\n",
      "Epoch 95/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.6522 - loss: 1.5975\n",
      "Epoch 96/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.5975\n",
      "Epoch 97/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.6087 - loss: 1.5834\n",
      "Epoch 98/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.5726\n",
      "Epoch 99/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5652 - loss: 1.5685\n",
      "Epoch 100/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.5635\n",
      "Epoch 101/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.6957 - loss: 1.5491\n",
      "Epoch 102/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.5379\n",
      "Epoch 103/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.5652 - loss: 1.5368\n",
      "Epoch 104/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.5261\n",
      "Epoch 105/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.5119\n",
      "Epoch 106/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.5103\n",
      "Epoch 107/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.4991\n",
      "Epoch 108/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.4912\n",
      "Epoch 109/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.4881\n",
      "Epoch 110/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.4804\n",
      "Epoch 111/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.4693\n",
      "Epoch 112/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6522 - loss: 1.4617\n",
      "Epoch 113/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.7391 - loss: 1.4508\n",
      "Epoch 114/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.7826 - loss: 1.4467\n",
      "Epoch 115/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.4335\n",
      "Epoch 116/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.4315\n",
      "Epoch 117/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.4228\n",
      "Epoch 118/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.4164\n",
      "Epoch 119/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.4113\n",
      "Epoch 120/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.4020\n",
      "Epoch 121/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.3935\n",
      "Epoch 122/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.3856\n",
      "Epoch 123/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.3937\n",
      "Epoch 124/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.3706\n",
      "Epoch 125/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.3718\n",
      "Epoch 126/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.7391 - loss: 1.3663\n",
      "Epoch 127/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.3533\n",
      "Epoch 128/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.3465\n",
      "Epoch 129/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.3515\n",
      "Epoch 130/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.3389\n",
      "Epoch 131/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.3337\n",
      "Epoch 132/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.3216\n",
      "Epoch 133/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.8261 - loss: 1.3202\n",
      "Epoch 134/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.6957 - loss: 1.3180\n",
      "Epoch 135/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.3049\n",
      "Epoch 136/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.2970\n",
      "Epoch 137/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.2934\n",
      "Epoch 138/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.7391 - loss: 1.2892\n",
      "Epoch 139/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.2838\n",
      "Epoch 140/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 1.2707\n",
      "Epoch 141/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.7826 - loss: 1.2678\n",
      "Epoch 142/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.2677\n",
      "Epoch 143/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.7826 - loss: 1.2578\n",
      "Epoch 144/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.2529\n",
      "Epoch 145/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.2441\n",
      "Epoch 146/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.2378\n",
      "Epoch 147/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.2356\n",
      "Epoch 148/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.2371\n",
      "Epoch 149/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 1.2237\n",
      "Epoch 150/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7391 - loss: 1.2172\n",
      "Epoch 151/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.2180\n",
      "Epoch 152/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.2038\n",
      "Epoch 153/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.7391 - loss: 1.2097\n",
      "Epoch 154/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.1976\n",
      "Epoch 155/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.7826 - loss: 1.1928\n",
      "Epoch 156/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.8261 - loss: 1.1973\n",
      "Epoch 157/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.1805\n",
      "Epoch 158/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.1747\n",
      "Epoch 159/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.1689\n",
      "Epoch 160/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.1644\n",
      "Epoch 161/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 1.1593\n",
      "Epoch 162/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.1616\n",
      "Epoch 163/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.8261 - loss: 1.1549\n",
      "Epoch 164/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.7391 - loss: 1.1482\n",
      "Epoch 165/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.8696 - loss: 1.1451\n",
      "Epoch 166/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.1323\n",
      "Epoch 167/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.1254\n",
      "Epoch 168/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.7826 - loss: 1.1191\n",
      "Epoch 169/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 1.1218\n",
      "Epoch 170/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.1103\n",
      "Epoch 171/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 1.1048\n",
      "Epoch 172/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 1.1075\n",
      "Epoch 173/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.7391 - loss: 1.1024\n",
      "Epoch 174/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 1.0897\n",
      "Epoch 175/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9130 - loss: 1.0870\n",
      "Epoch 176/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 1.0799\n",
      "Epoch 177/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 1.0765\n",
      "Epoch 178/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 1.0679\n",
      "Epoch 179/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 1.0634\n",
      "Epoch 180/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9130 - loss: 1.0552\n",
      "Epoch 181/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 1.0593\n",
      "Epoch 182/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.0508\n",
      "Epoch 183/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 1.0451\n",
      "Epoch 184/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 1.0429\n",
      "Epoch 185/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 1.0363\n",
      "Epoch 186/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 1.0318\n",
      "Epoch 187/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 1.0282\n",
      "Epoch 188/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 1.0203\n",
      "Epoch 189/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 1.0162\n",
      "Epoch 190/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 1.0091\n",
      "Epoch 191/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9130 - loss: 1.0033\n",
      "Epoch 192/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.9977\n",
      "Epoch 193/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 1.0000\n",
      "Epoch 194/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.9917\n",
      "Epoch 195/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.9916\n",
      "Epoch 196/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.9855\n",
      "Epoch 197/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.9812\n",
      "Epoch 198/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.9748\n",
      "Epoch 199/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9130 - loss: 0.9750\n",
      "Epoch 200/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8261 - loss: 0.9631\n",
      "Epoch 201/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9130 - loss: 0.9623\n",
      "Epoch 202/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.9564\n",
      "Epoch 203/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.9535\n",
      "Epoch 204/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.9564\n",
      "Epoch 205/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.9508\n",
      "Epoch 206/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.8696 - loss: 0.9385\n",
      "Epoch 207/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.9335\n",
      "Epoch 208/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9130 - loss: 0.9369\n",
      "Epoch 209/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9130 - loss: 0.9261\n",
      "Epoch 210/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.9259\n",
      "Epoch 211/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.9242\n",
      "Epoch 212/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9130 - loss: 0.9164\n",
      "Epoch 213/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.9125\n",
      "Epoch 214/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.8696 - loss: 0.9118\n",
      "Epoch 215/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.9077\n",
      "Epoch 216/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.9004\n",
      "Epoch 217/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.8960\n",
      "Epoch 218/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.8957\n",
      "Epoch 219/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.8895\n",
      "Epoch 220/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.8869\n",
      "Epoch 221/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.8793\n",
      "Epoch 222/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.8822\n",
      "Epoch 223/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.8687\n",
      "Epoch 224/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.8637\n",
      "Epoch 225/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.8627\n",
      "Epoch 226/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.8615\n",
      "Epoch 227/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.8646\n",
      "Epoch 228/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.8574\n",
      "Epoch 229/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.8462\n",
      "Epoch 230/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.8483\n",
      "Epoch 231/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.8441\n",
      "Epoch 232/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.8499\n",
      "Epoch 233/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.8393\n",
      "Epoch 234/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.8331\n",
      "Epoch 235/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.8282\n",
      "Epoch 236/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.8240\n",
      "Epoch 237/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.8225\n",
      "Epoch 238/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.8127\n",
      "Epoch 239/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.8136\n",
      "Epoch 240/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.8077\n",
      "Epoch 241/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.8084\n",
      "Epoch 242/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.8014\n",
      "Epoch 243/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.8050\n",
      "Epoch 244/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.7996\n",
      "Epoch 245/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9130 - loss: 0.7985\n",
      "Epoch 246/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.7827\n",
      "Epoch 247/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.7909\n",
      "Epoch 248/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.7811\n",
      "Epoch 249/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.7796\n",
      "Epoch 250/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.7747\n",
      "Epoch 251/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.7711\n",
      "Epoch 252/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.7682\n",
      "Epoch 253/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.7584\n",
      "Epoch 254/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.7656\n",
      "Epoch 255/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.7670\n",
      "Epoch 256/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.7592\n",
      "Epoch 257/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9130 - loss: 0.7563\n",
      "Epoch 258/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.7589\n",
      "Epoch 259/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.7506\n",
      "Epoch 260/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.7420\n",
      "Epoch 261/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.7433\n",
      "Epoch 262/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.7378\n",
      "Epoch 263/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.7321\n",
      "Epoch 264/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.7311\n",
      "Epoch 265/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.7215\n",
      "Epoch 266/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.7217\n",
      "Epoch 267/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.7216\n",
      "Epoch 268/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.7254\n",
      "Epoch 269/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.7351\n",
      "Epoch 270/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.7152\n",
      "Epoch 271/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.7105\n",
      "Epoch 272/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.7065\n",
      "Epoch 273/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.7061\n",
      "Epoch 274/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.6977\n",
      "Epoch 275/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.6894\n",
      "Epoch 276/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.6893\n",
      "Epoch 277/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.6975\n",
      "Epoch 278/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.6890\n",
      "Epoch 279/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.6833\n",
      "Epoch 280/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.8696 - loss: 0.6786\n",
      "Epoch 281/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.6746\n",
      "Epoch 282/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.6686\n",
      "Epoch 283/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.6706\n",
      "Epoch 284/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.6639\n",
      "Epoch 285/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.6617\n",
      "Epoch 286/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.6705\n",
      "Epoch 287/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.6592\n",
      "Epoch 288/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.6494\n",
      "Epoch 289/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.6486\n",
      "Epoch 290/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.6502\n",
      "Epoch 291/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.6490\n",
      "Epoch 292/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.6365\n",
      "Epoch 293/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.6408\n",
      "Epoch 294/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.6336\n",
      "Epoch 295/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.6329\n",
      "Epoch 296/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.6288\n",
      "Epoch 297/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.6252\n",
      "Epoch 298/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.6231\n",
      "Epoch 299/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.6223\n",
      "Epoch 300/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.6285\n",
      "Epoch 301/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.6267\n",
      "Epoch 302/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.6227\n",
      "Epoch 303/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.6161\n",
      "Epoch 304/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.6154\n",
      "Epoch 305/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.6121\n",
      "Epoch 306/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.6061\n",
      "Epoch 307/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.6011\n",
      "Epoch 308/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.5937\n",
      "Epoch 309/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.5945\n",
      "Epoch 310/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.5925\n",
      "Epoch 311/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.5868\n",
      "Epoch 312/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.5887\n",
      "Epoch 313/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.5855\n",
      "Epoch 314/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.5815\n",
      "Epoch 315/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.5803\n",
      "Epoch 316/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.5750\n",
      "Epoch 317/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.5750\n",
      "Epoch 318/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.5757\n",
      "Epoch 319/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9130 - loss: 0.5694\n",
      "Epoch 320/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.5723\n",
      "Epoch 321/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.5704\n",
      "Epoch 322/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.5611\n",
      "Epoch 323/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.5627\n",
      "Epoch 324/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.5617\n",
      "Epoch 325/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.5596\n",
      "Epoch 326/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.5532\n",
      "Epoch 327/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.5507\n",
      "Epoch 328/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.5475\n",
      "Epoch 329/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.8696 - loss: 0.5439\n",
      "Epoch 330/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.5401\n",
      "Epoch 331/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.5405\n",
      "Epoch 332/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.5388\n",
      "Epoch 333/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.5447\n",
      "Epoch 334/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.5424\n",
      "Epoch 335/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.5302\n",
      "Epoch 336/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.5270\n",
      "Epoch 337/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.5289\n",
      "Epoch 338/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.5292\n",
      "Epoch 339/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.5211\n",
      "Epoch 340/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.5217\n",
      "Epoch 341/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9130 - loss: 0.5222\n",
      "Epoch 342/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.5176\n",
      "Epoch 343/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9130 - loss: 0.5074\n",
      "Epoch 344/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.5111\n",
      "Epoch 345/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.5061\n",
      "Epoch 346/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.5065\n",
      "Epoch 347/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9130 - loss: 0.5014\n",
      "Epoch 348/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.5043\n",
      "Epoch 349/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.5027\n",
      "Epoch 350/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.4992\n",
      "Epoch 351/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.4960\n",
      "Epoch 352/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.4948\n",
      "Epoch 353/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.5003\n",
      "Epoch 354/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.8696 - loss: 0.5027\n",
      "Epoch 355/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.4959\n",
      "Epoch 356/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.4817\n",
      "Epoch 357/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.4802\n",
      "Epoch 358/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.4800\n",
      "Epoch 359/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.4807\n",
      "Epoch 360/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.4798\n",
      "Epoch 361/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.4738\n",
      "Epoch 362/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.4703\n",
      "Epoch 363/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.4737\n",
      "Epoch 364/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.4696\n",
      "Epoch 365/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.4689\n",
      "Epoch 366/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.4631\n",
      "Epoch 367/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.4588\n",
      "Epoch 368/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.4619\n",
      "Epoch 369/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.4597\n",
      "Epoch 370/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.4558\n",
      "Epoch 371/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.4574\n",
      "Epoch 372/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.4524\n",
      "Epoch 373/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.4489\n",
      "Epoch 374/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.4494\n",
      "Epoch 375/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.4506\n",
      "Epoch 376/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9130 - loss: 0.4505\n",
      "Epoch 377/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.4496\n",
      "Epoch 378/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.4413\n",
      "Epoch 379/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.4404\n",
      "Epoch 380/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.4378\n",
      "Epoch 381/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.4378\n",
      "Epoch 382/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.4361\n",
      "Epoch 383/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.4331\n",
      "Epoch 384/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.4333\n",
      "Epoch 385/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.4318\n",
      "Epoch 386/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.4341\n",
      "Epoch 387/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.4262\n",
      "Epoch 388/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.4240\n",
      "Epoch 389/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.4225\n",
      "Epoch 390/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.4186\n",
      "Epoch 391/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.4153\n",
      "Epoch 392/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.4138\n",
      "Epoch 393/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.4209\n",
      "Epoch 394/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.4105\n",
      "Epoch 395/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.4126\n",
      "Epoch 396/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.4092\n",
      "Epoch 397/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.4078\n",
      "Epoch 398/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.4051\n",
      "Epoch 399/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.4056\n",
      "Epoch 400/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.4028\n",
      "Epoch 401/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.3955\n",
      "Epoch 402/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.3933\n",
      "Epoch 403/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.3940\n",
      "Epoch 404/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.3917\n",
      "Epoch 405/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.3914\n",
      "Epoch 406/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.3947\n",
      "Epoch 407/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.3924\n",
      "Epoch 408/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.3885\n",
      "Epoch 409/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.3851\n",
      "Epoch 410/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.3822\n",
      "Epoch 411/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9130 - loss: 0.3829\n",
      "Epoch 412/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.3801\n",
      "Epoch 413/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.3791\n",
      "Epoch 414/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.3735\n",
      "Epoch 415/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.3735\n",
      "Epoch 416/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.3752\n",
      "Epoch 417/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.3706\n",
      "Epoch 418/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.3694\n",
      "Epoch 419/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.3696\n",
      "Epoch 420/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.3655\n",
      "Epoch 421/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.3661\n",
      "Epoch 422/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.3638\n",
      "Epoch 423/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.3675\n",
      "Epoch 424/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.3622\n",
      "Epoch 425/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.3584\n",
      "Epoch 426/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.3579\n",
      "Epoch 427/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.3575\n",
      "Epoch 428/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.3535\n",
      "Epoch 429/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.3558\n",
      "Epoch 430/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.3578\n",
      "Epoch 431/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.3480\n",
      "Epoch 432/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.3515\n",
      "Epoch 433/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.3482\n",
      "Epoch 434/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9130 - loss: 0.3532\n",
      "Epoch 435/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.3526\n",
      "Epoch 436/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.3454\n",
      "Epoch 437/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.3529\n",
      "Epoch 438/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.3410\n",
      "Epoch 439/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.3379\n",
      "Epoch 440/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.3386\n",
      "Epoch 441/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.3361\n",
      "Epoch 442/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.3361\n",
      "Epoch 443/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.3369\n",
      "Epoch 444/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.3398\n",
      "Epoch 445/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.3337\n",
      "Epoch 446/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.3283\n",
      "Epoch 447/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9130 - loss: 0.3335\n",
      "Epoch 448/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.3307\n",
      "Epoch 449/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.3254\n",
      "Epoch 450/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.3257\n",
      "Epoch 451/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.3293\n",
      "Epoch 452/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.3222\n",
      "Epoch 453/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.3217\n",
      "Epoch 454/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.3205\n",
      "Epoch 455/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.3191\n",
      "Epoch 456/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.3162\n",
      "Epoch 457/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.3131\n",
      "Epoch 458/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.3132\n",
      "Epoch 459/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.3112\n",
      "Epoch 460/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.3136\n",
      "Epoch 461/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.3129\n",
      "Epoch 462/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.3170\n",
      "Epoch 463/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.3292\n",
      "Epoch 464/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.3245\n",
      "Epoch 465/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.3079\n",
      "Epoch 466/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.3024\n",
      "Epoch 467/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.3049\n",
      "Epoch 468/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.3025\n",
      "Epoch 469/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.3017\n",
      "Epoch 470/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.3013\n",
      "Epoch 471/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.2984\n",
      "Epoch 472/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.2990\n",
      "Epoch 473/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.2968\n",
      "Epoch 474/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.2942\n",
      "Epoch 475/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.2952\n",
      "Epoch 476/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.2935\n",
      "Epoch 477/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.2907\n",
      "Epoch 478/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.2903\n",
      "Epoch 479/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.2877\n",
      "Epoch 480/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.2903\n",
      "Epoch 481/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.2861\n",
      "Epoch 482/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.2885\n",
      "Epoch 483/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.2861\n",
      "Epoch 484/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.2855\n",
      "Epoch 485/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.2785\n",
      "Epoch 486/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.2819\n",
      "Epoch 487/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.2856\n",
      "Epoch 488/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.2885\n",
      "Epoch 489/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.2815\n",
      "Epoch 490/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.2804\n",
      "Epoch 491/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 0.9565 - loss: 0.2733\n",
      "Epoch 492/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.2742\n",
      "Epoch 493/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.2727\n",
      "Epoch 494/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.2695\n",
      "Epoch 495/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.2725\n",
      "Epoch 496/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.2759\n",
      "Epoch 497/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.2707\n",
      "Epoch 498/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 0.9565 - loss: 0.2708\n",
      "Epoch 499/500\n",
      "23/23 - 0s - 1ms/step - accuracy: 1.0000 - loss: 0.2716\n",
      "Epoch 500/500\n",
      "23/23 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.2666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x296d036f770>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X, y, epochs=500, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP5. 評估模型準確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# 評估模型的性能\n",
    "scores = model.evaluate(X, y, verbose=0)\n",
    "print(\"Model Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP6. 預測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C'] -> D\n",
      "['B', 'C', 'D'] -> E\n",
      "['C', 'D', 'E'] -> F\n",
      "['D', 'E', 'F'] -> G\n",
      "['E', 'F', 'G'] -> H\n",
      "['F', 'G', 'H'] -> I\n",
      "['G', 'H', 'I'] -> J\n",
      "['H', 'I', 'J'] -> K\n",
      "['I', 'J', 'K'] -> L\n",
      "['J', 'K', 'L'] -> M\n",
      "['K', 'L', 'M'] -> N\n",
      "['L', 'M', 'N'] -> O\n",
      "['M', 'N', 'O'] -> P\n",
      "['N', 'O', 'P'] -> Q\n",
      "['O', 'P', 'Q'] -> R\n",
      "['P', 'Q', 'R'] -> S\n",
      "['Q', 'R', 'S'] -> T\n",
      "['R', 'S', 'T'] -> U\n",
      "['S', 'T', 'U'] -> V\n",
      "['T', 'U', 'V'] -> W\n",
      "['U', 'V', 'W'] -> X\n",
      "['V', 'W', 'X'] -> Y\n",
      "['W', 'X', 'Y'] -> Z\n"
     ]
    }
   ],
   "source": [
    "# 讓我們擷取3個字符轉成張量結構 shape:(1,3,1)來進行infer\n",
    "for pattern in dataX:\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(len(alphabet))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    print(seq_in, \"->\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型 4. LSTM學習可變長度字符輸入到單字符輸出\n",
    "\n",
    "讓我們建立一個模型，來接受\"變動字母序列(variable-length)\"的輸入來預測下一個字母。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP1. 準備訓練用資料\n",
    "\n",
    "為了簡化，我們將定義一個最大輸入序列長度(比如說\"5\", 代表輸入的序列可以是 1 ~ 5)，以加速訓練。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PQRST -> U\n",
      "W -> X\n",
      "O -> P\n",
      "OPQ -> R\n",
      "IJKLM -> N\n",
      "QRSTU -> V\n",
      "ABCD -> E\n",
      "X -> Y\n",
      "GHIJ -> K\n",
      "M -> N\n",
      "XY -> Z\n",
      "QRST -> U\n",
      "ABC -> D\n",
      "JKLMN -> O\n",
      "OP -> Q\n",
      "XY -> Z\n",
      "D -> E\n",
      "T -> U\n",
      "B -> C\n",
      "QRSTU -> V\n",
      "HIJ -> K\n",
      "JKLM -> N\n",
      "ABCDE -> F\n",
      "X -> Y\n",
      "V -> W\n",
      "DE -> F\n",
      "DEFG -> H\n",
      "BCDE -> F\n",
      "EFGH -> I\n",
      "BCDE -> F\n",
      "FG -> H\n",
      "RST -> U\n",
      "TUV -> W\n",
      "STUV -> W\n",
      "LMN -> O\n",
      "P -> Q\n",
      "MNOP -> Q\n",
      "JK -> L\n",
      "MNOP -> Q\n",
      "OPQRS -> T\n",
      "UVWXY -> Z\n",
      "PQRS -> T\n",
      "D -> E\n",
      "EFGH -> I\n",
      "IJK -> L\n",
      "WX -> Y\n",
      "STUV -> W\n",
      "MNOPQ -> R\n",
      "P -> Q\n",
      "WXY -> Z\n",
      "VWX -> Y\n",
      "V -> W\n",
      "HI -> J\n",
      "KLMNO -> P\n",
      "UV -> W\n",
      "JKL -> M\n",
      "ABCDE -> F\n",
      "WXY -> Z\n",
      "M -> N\n",
      "CDEF -> G\n",
      "KLMNO -> P\n",
      "RST -> U\n",
      "RS -> T\n",
      "W -> X\n",
      "J -> K\n",
      "WX -> Y\n",
      "JKLMN -> O\n",
      "MN -> O\n",
      "L -> M\n",
      "BCDE -> F\n",
      "TU -> V\n",
      "MNOPQ -> R\n",
      "NOPQR -> S\n",
      "HIJ -> K\n",
      "JKLM -> N\n",
      "STUVW -> X\n",
      "QRST -> U\n",
      "N -> O\n",
      "VWXY -> Z\n",
      "B -> C\n",
      "UVWX -> Y\n",
      "OP -> Q\n",
      "K -> L\n",
      "C -> D\n",
      "X -> Y\n",
      "ST -> U\n",
      "JKLM -> N\n",
      "B -> C\n",
      "QR -> S\n",
      "RS -> T\n",
      "VWXY -> Z\n",
      "S -> T\n",
      "NOP -> Q\n",
      "KLMNO -> P\n",
      "IJ -> K\n",
      "EF -> G\n",
      "MNOP -> Q\n",
      "WXY -> Z\n",
      "HI -> J\n",
      "P -> Q\n",
      "STUVW -> X\n",
      "Q -> R\n",
      "MN -> O\n",
      "O -> P\n",
      "C -> D\n",
      "L -> M\n",
      "JKLM -> N\n",
      "K -> L\n",
      "IJKLM -> N\n",
      "FGHIJ -> K\n",
      "LM -> N\n",
      "OPQ -> R\n",
      "U -> V\n",
      "HIJKL -> M\n",
      "PQR -> S\n",
      "S -> T\n",
      "OPQR -> S\n",
      "J -> K\n",
      "DE -> F\n",
      "K -> L\n",
      "BCDE -> F\n",
      "EFGH -> I\n",
      "RSTUV -> W\n",
      "LMNOP -> Q\n",
      "QR -> S\n",
      "ABCDE -> F\n",
      "LM -> N\n",
      "IJKLM -> N\n",
      "B -> C\n",
      "VWX -> Y\n",
      "MNOPQ -> R\n",
      "MNOPQ -> R\n",
      "LM -> N\n",
      "S -> T\n",
      "VWX -> Y\n",
      "WXY -> Z\n",
      "F -> G\n",
      "KLMNO -> P\n",
      "OPQ -> R\n",
      "M -> N\n",
      "X -> Y\n",
      "OPQRS -> T\n",
      "F -> G\n",
      "JKLMN -> O\n",
      "XY -> Z\n",
      "OPQ -> R\n",
      "FG -> H\n",
      "OP -> Q\n",
      "DEFGH -> I\n",
      "ABCD -> E\n",
      "VWX -> Y\n",
      "U -> V\n",
      "UV -> W\n",
      "VWX -> Y\n",
      "LMNO -> P\n",
      "E -> F\n",
      "NOPQ -> R\n",
      "HIJK -> L\n",
      "HIJ -> K\n",
      "DE -> F\n",
      "B -> C\n",
      "UVW -> X\n",
      "STUV -> W\n",
      "RST -> U\n",
      "H -> I\n",
      "I -> J\n",
      "MN -> O\n",
      "CDEF -> G\n",
      "ABC -> D\n",
      "RSTU -> V\n",
      "B -> C\n",
      "JKLM -> N\n",
      "TUVW -> X\n",
      "STUVW -> X\n",
      "C -> D\n",
      "UV -> W\n",
      "QRS -> T\n",
      "ABC -> D\n",
      "NOP -> Q\n",
      "W -> X\n",
      "DE -> F\n",
      "VWXY -> Z\n",
      "UV -> W\n",
      "JK -> L\n",
      "E -> F\n",
      "MNO -> P\n",
      "EFGH -> I\n",
      "PQRS -> T\n",
      "FGH -> I\n",
      "WXY -> Z\n",
      "OPQRS -> T\n",
      "TUV -> W\n",
      "MN -> O\n",
      "O -> P\n",
      "LMN -> O\n",
      "VWX -> Y\n",
      "QR -> S\n",
      "TUV -> W\n",
      "STU -> V\n",
      "EFGH -> I\n",
      "E -> F\n",
      "HIJ -> K\n",
      "QRS -> T\n",
      "H -> I\n",
      "K -> L\n",
      "E -> F\n",
      "UV -> W\n",
      "X -> Y\n",
      "QR -> S\n",
      "QRS -> T\n",
      "WXY -> Z\n",
      "S -> T\n",
      "CDEFG -> H\n",
      "PQRST -> U\n",
      "RST -> U\n",
      "A -> B\n",
      "CDEF -> G\n",
      "X -> Y\n",
      "JKLM -> N\n",
      "VWX -> Y\n",
      "N -> O\n",
      "W -> X\n",
      "TUVW -> X\n",
      "LMNOP -> Q\n",
      "EFG -> H\n",
      "HI -> J\n",
      "WXY -> Z\n",
      "IJK -> L\n",
      "R -> S\n",
      "H -> I\n",
      "V -> W\n",
      "OPQR -> S\n",
      "QRSTU -> V\n",
      "MNOPQ -> R\n",
      "Q -> R\n",
      "VWXY -> Z\n",
      "ABCDE -> F\n",
      "HIJK -> L\n",
      "FGHIJ -> K\n",
      "BC -> D\n",
      "UV -> W\n",
      "WXY -> Z\n",
      "VWX -> Y\n",
      "L -> M\n",
      "FG -> H\n",
      "E -> F\n",
      "WXY -> Z\n",
      "KLMN -> O\n",
      "B -> C\n",
      "QRSTU -> V\n",
      "X -> Y\n",
      "ST -> U\n",
      "GH -> I\n",
      "CDE -> F\n",
      "IJKLM -> N\n",
      "JKL -> M\n",
      "HIJ -> K\n",
      "UVWXY -> Z\n",
      "PQ -> R\n",
      "AB -> C\n",
      "HIJ -> K\n",
      "EFG -> H\n",
      "PQRS -> T\n",
      "BCDEF -> G\n",
      "IJKL -> M\n",
      "DEFGH -> I\n",
      "VW -> X\n",
      "XY -> Z\n",
      "OPQ -> R\n",
      "MN -> O\n",
      "OP -> Q\n",
      "WXY -> Z\n",
      "STU -> V\n",
      "LM -> N\n",
      "UV -> W\n",
      "EF -> G\n",
      "LMN -> O\n",
      "D -> E\n",
      "H -> I\n",
      "KLMNO -> P\n",
      "PQRST -> U\n",
      "V -> W\n",
      "M -> N\n",
      "UVW -> X\n",
      "ABCD -> E\n",
      "LM -> N\n",
      "A -> B\n",
      "DEFGH -> I\n",
      "IJK -> L\n",
      "OP -> Q\n",
      "WXY -> Z\n",
      "CDEFG -> H\n",
      "UVW -> X\n",
      "RS -> T\n",
      "FGHIJ -> K\n",
      "RST -> U\n",
      "NO -> P\n",
      "X -> Y\n",
      "RST -> U\n",
      "I -> J\n",
      "TUV -> W\n",
      "B -> C\n",
      "UVWX -> Y\n",
      "HIJKL -> M\n",
      "MNOPQ -> R\n",
      "ABC -> D\n",
      "PQ -> R\n",
      "WX -> Y\n",
      "XY -> Z\n",
      "UVW -> X\n",
      "IJKL -> M\n",
      "XY -> Z\n",
      "DEFG -> H\n",
      "H -> I\n",
      "Q -> R\n",
      "CDEFG -> H\n",
      "C -> D\n",
      "ABCD -> E\n",
      "LMN -> O\n",
      "PQRST -> U\n",
      "VWX -> Y\n",
      "M -> N\n",
      "KLMN -> O\n",
      "AB -> C\n",
      "NOPQ -> R\n",
      "F -> G\n",
      "NO -> P\n",
      "KLM -> N\n",
      "TUVWX -> Y\n",
      "U -> V\n",
      "CDEFG -> H\n",
      "FGHI -> J\n",
      "STUVW -> X\n",
      "JKLM -> N\n",
      "ABC -> D\n",
      "JKLMN -> O\n",
      "TUVWX -> Y\n",
      "D -> E\n",
      "EFGH -> I\n",
      "IJ -> K\n",
      "UVW -> X\n",
      "OPQR -> S\n",
      "N -> O\n",
      "VWXY -> Z\n",
      "ABC -> D\n",
      "J -> K\n",
      "RS -> T\n",
      "LMNOP -> Q\n",
      "BC -> D\n",
      "OPQ -> R\n",
      "JKLM -> N\n",
      "WX -> Y\n",
      "BCD -> E\n",
      "RSTU -> V\n",
      "GHI -> J\n",
      "O -> P\n",
      "R -> S\n",
      "QR -> S\n",
      "HIJKL -> M\n",
      "UVWXY -> Z\n",
      "CDEFG -> H\n",
      "OP -> Q\n",
      "HIJK -> L\n",
      "A -> B\n",
      "RST -> U\n",
      "QR -> S\n",
      "ABCD -> E\n",
      "LMN -> O\n",
      "TUV -> W\n",
      "MNO -> P\n",
      "AB -> C\n",
      "M -> N\n",
      "OPQR -> S\n",
      "STU -> V\n",
      "TUV -> W\n",
      "PQRST -> U\n",
      "LM -> N\n",
      "A -> B\n",
      "A -> B\n",
      "OPQ -> R\n",
      "HIJK -> L\n",
      "TU -> V\n",
      "QRS -> T\n",
      "WX -> Y\n",
      "BCD -> E\n",
      "ST -> U\n",
      "X -> Y\n",
      "EFGHI -> J\n",
      "E -> F\n",
      "FGHIJ -> K\n",
      "HI -> J\n",
      "ABC -> D\n",
      "NOPQ -> R\n",
      "HIJK -> L\n",
      "B -> C\n",
      "U -> V\n",
      "GH -> I\n",
      "TUVWX -> Y\n",
      "S -> T\n",
      "BCDEF -> G\n",
      "KLM -> N\n",
      "Q -> R\n",
      "CD -> E\n",
      "PQ -> R\n",
      "GH -> I\n",
      "U -> V\n",
      "RST -> U\n",
      "JKLM -> N\n",
      "FGH -> I\n",
      "IJ -> K\n",
      "O -> P\n",
      "X -> Y\n",
      "H -> I\n",
      "DEF -> G\n",
      "QRSTU -> V\n",
      "ABCD -> E\n",
      "IJK -> L\n",
      "GHI -> J\n",
      "QR -> S\n",
      "NOPQR -> S\n",
      "EF -> G\n",
      "PQRST -> U\n",
      "RST -> U\n",
      "X -> Y\n",
      "QR -> S\n",
      "HIJ -> K\n",
      "D -> E\n",
      "AB -> C\n",
      "N -> O\n",
      "QR -> S\n",
      "BCDEF -> G\n",
      "QRS -> T\n",
      "DEF -> G\n",
      "TUV -> W\n",
      "A -> B\n",
      "GHIJ -> K\n",
      "W -> X\n",
      "VWXY -> Z\n",
      "LM -> N\n",
      "OPQ -> R\n",
      "XY -> Z\n",
      "KLM -> N\n",
      "RST -> U\n",
      "OP -> Q\n",
      "VWX -> Y\n",
      "OPQ -> R\n",
      "N -> O\n",
      "M -> N\n",
      "JKL -> M\n",
      "OP -> Q\n",
      "DEF -> G\n",
      "BCD -> E\n",
      "K -> L\n",
      "MN -> O\n",
      "IJKL -> M\n",
      "QR -> S\n",
      "IJKLM -> N\n",
      "U -> V\n",
      "FGH -> I\n",
      "MNOPQ -> R\n",
      "TUVW -> X\n",
      "MN -> O\n",
      "RSTUV -> W\n",
      "VWX -> Y\n",
      "Q -> R\n",
      "DEFGH -> I\n",
      "NO -> P\n",
      "T -> U\n",
      "V -> W\n",
      "ST -> U\n",
      "DEFG -> H\n",
      "RS -> T\n",
      "NOPQ -> R\n",
      "GHIJK -> L\n",
      "QRSTU -> V\n",
      "LMNO -> P\n",
      "IJK -> L\n",
      "PQRST -> U\n",
      "IJK -> L\n",
      "DE -> F\n",
      "CD -> E\n",
      "JKLM -> N\n",
      "WX -> Y\n",
      "UV -> W\n",
      "W -> X\n",
      "KLM -> N\n",
      "PQ -> R\n",
      "W -> X\n",
      "WXY -> Z\n",
      "EFGHI -> J\n",
      "E -> F\n",
      "NOP -> Q\n",
      "VW -> X\n",
      "EFGHI -> J\n",
      "NO -> P\n",
      "HIJKL -> M\n",
      "UVWXY -> Z\n",
      "OPQ -> R\n",
      "P -> Q\n",
      "H -> I\n",
      "O -> P\n",
      "GHIJK -> L\n",
      "S -> T\n",
      "E -> F\n",
      "KLMN -> O\n",
      "TUVW -> X\n",
      "E -> F\n",
      "CDE -> F\n",
      "I -> J\n",
      "CDEF -> G\n",
      "F -> G\n",
      "ABCD -> E\n",
      "H -> I\n",
      "LMNOP -> Q\n",
      "V -> W\n",
      "W -> X\n",
      "BCD -> E\n",
      "TU -> V\n",
      "VWXY -> Z\n",
      "UVWX -> Y\n",
      "JKL -> M\n",
      "VW -> X\n",
      "CDEF -> G\n",
      "DEF -> G\n",
      "ABCDE -> F\n",
      "MNO -> P\n",
      "EFGH -> I\n",
      "JKLM -> N\n",
      "QR -> S\n",
      "ABCDE -> F\n",
      "OPQR -> S\n",
      "DEF -> G\n",
      "Q -> R\n",
      "TU -> V\n",
      "CDEFG -> H\n",
      "KLMN -> O\n",
      "VW -> X\n",
      "HIJKL -> M\n",
      "DE -> F\n",
      "OP -> Q\n",
      "I -> J\n",
      "GHIJK -> L\n",
      "HIJKL -> M\n",
      "I -> J\n",
      "AB -> C\n",
      "DE -> F\n",
      "I -> J\n",
      "O -> P\n",
      "HIJK -> L\n",
      "QR -> S\n",
      "MN -> O\n",
      "I -> J\n",
      "LM -> N\n",
      "VWXY -> Z\n",
      "JKLMN -> O\n",
      "BC -> D\n",
      "MN -> O\n",
      "GHIJ -> K\n",
      "KL -> M\n",
      "TU -> V\n",
      "QRST -> U\n",
      "ABCDE -> F\n",
      "GH -> I\n",
      "Q -> R\n",
      "NO -> P\n",
      "RST -> U\n",
      "BCDE -> F\n",
      "T -> U\n",
      "TUV -> W\n",
      "FGHIJ -> K\n",
      "T -> U\n",
      "BCD -> E\n",
      "NO -> P\n",
      "JK -> L\n",
      "BCD -> E\n",
      "G -> H\n",
      "A -> B\n",
      "GHIJK -> L\n",
      "QRSTU -> V\n",
      "AB -> C\n",
      "VW -> X\n",
      "HIJKL -> M\n",
      "FGHIJ -> K\n",
      "PQ -> R\n",
      "UV -> W\n",
      "F -> G\n",
      "A -> B\n",
      "Q -> R\n",
      "MNOP -> Q\n",
      "UVWXY -> Z\n",
      "GHIJK -> L\n",
      "GHIJK -> L\n",
      "BCDE -> F\n",
      "QRS -> T\n",
      "PQRS -> T\n",
      "PQ -> R\n",
      "HI -> J\n",
      "PQRST -> U\n",
      "OPQR -> S\n",
      "QRST -> U\n",
      "IJKLM -> N\n",
      "Q -> R\n",
      "F -> G\n",
      "QRST -> U\n",
      "ST -> U\n",
      "MN -> O\n",
      "CD -> E\n",
      "EFG -> H\n",
      "FGH -> I\n",
      "R -> S\n",
      "C -> D\n",
      "RSTUV -> W\n",
      "KL -> M\n",
      "HIJK -> L\n",
      "CD -> E\n",
      "FGHI -> J\n",
      "VW -> X\n",
      "P -> Q\n",
      "C -> D\n",
      "DE -> F\n",
      "DE -> F\n",
      "I -> J\n",
      "LMNOP -> Q\n",
      "KLMNO -> P\n",
      "QRS -> T\n",
      "F -> G\n",
      "UVWXY -> Z\n",
      "QRS -> T\n",
      "BCD -> E\n",
      "FG -> H\n",
      "ABCDE -> F\n",
      "U -> V\n",
      "M -> N\n",
      "KLMN -> O\n",
      "RST -> U\n",
      "UVWX -> Y\n",
      "X -> Y\n",
      "XY -> Z\n",
      "I -> J\n",
      "KLMN -> O\n",
      "X -> Y\n",
      "W -> X\n",
      "RSTUV -> W\n",
      "VW -> X\n",
      "XY -> Z\n",
      "T -> U\n",
      "CDE -> F\n",
      "FGHI -> J\n",
      "PQ -> R\n",
      "OPQRS -> T\n",
      "D -> E\n",
      "E -> F\n",
      "EFGH -> I\n",
      "GHIJK -> L\n",
      "L -> M\n",
      "KLMN -> O\n",
      "STU -> V\n",
      "EF -> G\n",
      "UV -> W\n",
      "K -> L\n",
      "QRS -> T\n",
      "QRSTU -> V\n",
      "DEF -> G\n",
      "UV -> W\n",
      "D -> E\n",
      "BC -> D\n",
      "OPQRS -> T\n",
      "EFGH -> I\n",
      "QRST -> U\n",
      "EF -> G\n",
      "RST -> U\n",
      "JKL -> M\n",
      "STU -> V\n",
      "UVWX -> Y\n",
      "EFGHI -> J\n",
      "JKLMN -> O\n",
      "P -> Q\n",
      "BCD -> E\n",
      "TU -> V\n",
      "O -> P\n",
      "RST -> U\n",
      "D -> E\n",
      "VWXY -> Z\n",
      "R -> S\n",
      "P -> Q\n",
      "CDE -> F\n",
      "X -> Y\n",
      "UVWXY -> Z\n",
      "DEFGH -> I\n",
      "NOP -> Q\n",
      "ABCD -> E\n",
      "B -> C\n",
      "BC -> D\n",
      "VW -> X\n",
      "E -> F\n",
      "TUVW -> X\n",
      "JKL -> M\n",
      "XY -> Z\n",
      "LM -> N\n",
      "PQRS -> T\n",
      "O -> P\n",
      "KLMN -> O\n",
      "STUV -> W\n",
      "K -> L\n",
      "UVWX -> Y\n",
      "U -> V\n",
      "HIJ -> K\n",
      "W -> X\n",
      "VWXY -> Z\n",
      "WX -> Y\n",
      "HIJ -> K\n",
      "O -> P\n",
      "QR -> S\n",
      "VWXY -> Z\n",
      "CD -> E\n",
      "KL -> M\n",
      "DEFGH -> I\n",
      "LMN -> O\n",
      "QRS -> T\n",
      "JKLMN -> O\n",
      "QR -> S\n",
      "CD -> E\n",
      "QRST -> U\n",
      "BCDEF -> G\n",
      "CDE -> F\n",
      "LMN -> O\n",
      "DEF -> G\n",
      "BCD -> E\n",
      "UV -> W\n",
      "STUVW -> X\n",
      "RS -> T\n",
      "ABCD -> E\n",
      "BCDEF -> G\n",
      "Q -> R\n",
      "UVWXY -> Z\n",
      "VW -> X\n",
      "VW -> X\n",
      "WXY -> Z\n",
      "NOPQR -> S\n",
      "V -> W\n",
      "LM -> N\n",
      "B -> C\n",
      "JKL -> M\n",
      "DE -> F\n",
      "K -> L\n",
      "ABC -> D\n",
      "E -> F\n",
      "STU -> V\n",
      "TU -> V\n",
      "G -> H\n",
      "AB -> C\n",
      "J -> K\n",
      "FGH -> I\n",
      "MNOP -> Q\n",
      "VW -> X\n",
      "CD -> E\n",
      "TUVWX -> Y\n",
      "F -> G\n",
      "VWX -> Y\n",
      "LMNO -> P\n",
      "GHIJ -> K\n",
      "TUVWX -> Y\n",
      "JKL -> M\n",
      "LM -> N\n",
      "EFGHI -> J\n",
      "MNO -> P\n",
      "H -> I\n",
      "M -> N\n",
      "S -> T\n",
      "STU -> V\n",
      "QRST -> U\n",
      "PQR -> S\n",
      "RSTUV -> W\n",
      "ST -> U\n",
      "RSTUV -> W\n",
      "JKLM -> N\n",
      "T -> U\n",
      "CDE -> F\n",
      "HIJ -> K\n",
      "NOPQ -> R\n",
      "OPQ -> R\n",
      "EF -> G\n",
      "AB -> C\n",
      "CD -> E\n",
      "RST -> U\n",
      "STU -> V\n",
      "L -> M\n",
      "WXY -> Z\n",
      "STUVW -> X\n",
      "QRST -> U\n",
      "W -> X\n",
      "S -> T\n",
      "M -> N\n",
      "GH -> I\n",
      "QRST -> U\n",
      "FGH -> I\n",
      "PQRS -> T\n",
      "GH -> I\n",
      "DE -> F\n",
      "DE -> F\n",
      "GHIJK -> L\n",
      "Q -> R\n",
      "WX -> Y\n",
      "WX -> Y\n",
      "KLM -> N\n",
      "DE -> F\n",
      "EF -> G\n",
      "UVW -> X\n",
      "IJK -> L\n",
      "NO -> P\n",
      "QR -> S\n",
      "TU -> V\n",
      "RST -> U\n",
      "VW -> X\n",
      "A -> B\n",
      "DE -> F\n",
      "WXY -> Z\n",
      "CD -> E\n",
      "IJK -> L\n",
      "STUV -> W\n",
      "LMNOP -> Q\n",
      "X -> Y\n",
      "FGH -> I\n",
      "F -> G\n",
      "IJK -> L\n",
      "EFG -> H\n",
      "DEFG -> H\n",
      "NOP -> Q\n",
      "FG -> H\n",
      "RSTU -> V\n",
      "E -> F\n",
      "WXY -> Z\n",
      "GH -> I\n",
      "CD -> E\n",
      "IJ -> K\n",
      "TUVWX -> Y\n",
      "EFGH -> I\n",
      "DEFGH -> I\n",
      "BCDE -> F\n",
      "STUV -> W\n",
      "HI -> J\n",
      "GH -> I\n",
      "STUVW -> X\n",
      "ABC -> D\n",
      "S -> T\n",
      "LMNOP -> Q\n",
      "UVWX -> Y\n",
      "PQ -> R\n",
      "CDEF -> G\n",
      "E -> F\n",
      "TU -> V\n",
      "TUVWX -> Y\n",
      "GHIJ -> K\n",
      "JK -> L\n",
      "IJK -> L\n",
      "G -> H\n",
      "EFG -> H\n",
      "TU -> V\n",
      "FGHI -> J\n",
      "W -> X\n",
      "T -> U\n",
      "CDE -> F\n",
      "XY -> Z\n",
      "XY -> Z\n",
      "CDE -> F\n",
      "N -> O\n",
      "QRST -> U\n",
      "FGHIJ -> K\n",
      "PQ -> R\n",
      "I -> J\n",
      "GH -> I\n",
      "F -> G\n",
      "VWX -> Y\n",
      "ABC -> D\n",
      "GH -> I\n",
      "KLMN -> O\n",
      "X -> Y\n",
      "Q -> R\n",
      "NOPQR -> S\n",
      "HIJ -> K\n",
      "IJ -> K\n",
      "C -> D\n",
      "FG -> H\n",
      "JKLMN -> O\n",
      "TU -> V\n",
      "NOPQR -> S\n",
      "O -> P\n",
      "TU -> V\n",
      "MNOPQ -> R\n",
      "PQ -> R\n",
      "S -> T\n",
      "VWXY -> Z\n",
      "VWXY -> Z\n",
      "CD -> E\n",
      "BCDEF -> G\n",
      "OPQ -> R\n",
      "LMNO -> P\n",
      "HIJKL -> M\n",
      "STU -> V\n",
      "GHI -> J\n",
      "UVWX -> Y\n",
      "NOPQ -> R\n",
      "HIJK -> L\n",
      "NOP -> Q\n",
      "Q -> R\n",
      "HIJ -> K\n",
      "W -> X\n",
      "QR -> S\n",
      "UVWX -> Y\n",
      "H -> I\n",
      "ABC -> D\n",
      "RSTUV -> W\n",
      "VW -> X\n",
      "OP -> Q\n",
      "RSTUV -> W\n",
      "ABC -> D\n",
      "ABC -> D\n",
      "GHIJ -> K\n",
      "WXY -> Z\n",
      "BCDE -> F\n",
      "N -> O\n",
      "JK -> L\n",
      "X -> Y\n",
      "TUV -> W\n",
      "L -> M\n",
      "F -> G\n",
      "MN -> O\n",
      "JKLMN -> O\n",
      "G -> H\n",
      "BCDEF -> G\n",
      "LMN -> O\n",
      "N -> O\n",
      "V -> W\n",
      "BCDEF -> G\n",
      "KLM -> N\n",
      "ST -> U\n",
      "TUV -> W\n",
      "MN -> O\n",
      "JKLM -> N\n",
      "LM -> N\n",
      "U -> V\n",
      "FGH -> I\n",
      "TUV -> W\n",
      "C -> D\n",
      "HIJK -> L\n",
      "UVWX -> Y\n",
      "W -> X\n",
      "QR -> S\n",
      "PQR -> S\n",
      "STUVW -> X\n",
      "RSTU -> V\n",
      "TU -> V\n",
      "RSTU -> V\n",
      "JKL -> M\n",
      "JKL -> M\n",
      "RSTUV -> W\n",
      "GHI -> J\n",
      "V -> W\n",
      "CD -> E\n",
      "QRSTU -> V\n",
      "M -> N\n",
      "BCDE -> F\n",
      "WX -> Y\n",
      "K -> L\n",
      "VW -> X\n",
      "GHI -> J\n",
      "CD -> E\n",
      "XY -> Z\n",
      "HI -> J\n",
      "C -> D\n",
      "IJK -> L\n",
      "DEFG -> H\n",
      "UV -> W\n",
      "LM -> N\n",
      "X -> Y\n",
      "UV -> W\n",
      "I -> J\n",
      "NO -> P\n",
      "ABCD -> E\n",
      "K -> L\n",
      "IJK -> L\n",
      "JKL -> M\n",
      "EFGHI -> J\n",
      "JK -> L\n",
      "TU -> V\n",
      "IJ -> K\n",
      "MNOPQ -> R\n",
      "C -> D\n",
      "IJKLM -> N\n",
      "VW -> X\n",
      "CDE -> F\n",
      "E -> F\n",
      "NOP -> Q\n",
      "OPQRS -> T\n",
      "FGHI -> J\n",
      "STUV -> W\n",
      "IJKLM -> N\n",
      "STUV -> W\n",
      "TUVWX -> Y\n",
      "RSTU -> V\n"
     ]
    }
   ],
   "source": [
    "# 準備訓練資料\n",
    "num_inputs = 1000\n",
    "max_len = 5  # 最大序列長度\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(num_inputs):\n",
    "    start = numpy.random.randint(len(alphabet) - 2)\n",
    "    end = numpy.random.randint(start, min(start + max_len, len(alphabet) - 1))\n",
    "    sequence_in = alphabet[start : end + 1]\n",
    "    sequence_out = alphabet[end + 1]\n",
    "    dataX.append([char_to_int[char] for char in sequence_in])\n",
    "    dataY.append(char_to_int[sequence_out])\n",
    "    print(sequence_in, \"->\", sequence_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP2. 資料預處理\n",
    "因為輸入序列的長度會在1到max_len之間變動，因此需要以\"0\"來填充(padding)。在這裡，我們使用Keras內附的pad_sequences（）函數並設定使用左側（前綴）填充。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 將訓練資料轉換為陣列和並進行序列填充（如果需要）\n",
    "X = pad_sequences(dataX, maxlen=max_len, dtype=\"float32\")  # <-- 注意這裡\n",
    "\n",
    "# 重塑 X 資料的維度成為 (samples, time_steps, features)\n",
    "X = numpy.reshape(X, (X.shape[0], max_len, 1))  # <-- 特別注意這裡\n",
    "\n",
    "# 歸一化\n",
    "X = X / float(len(alphabet))\n",
    "\n",
    "# 使用one hot encode 對Y值進行編碼\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP3. 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">858</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │           \u001b[38;5;34m858\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,210</span> (20.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,210\u001b[0m (20.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,210</span> (20.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,210\u001b[0m (20.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 創建模型\n",
    "batch_size = 1\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(X.shape[1], 1)))  # <-- 注意這裡\n",
    "model.add(Dense(y.shape[1], activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP4. 定義訓練並進行訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1000/1000 - 2s - 2ms/step - accuracy: 0.0700 - loss: 3.0963\n",
      "Epoch 2/500\n",
      "1000/1000 - 1s - 826us/step - accuracy: 0.1070 - loss: 2.8607\n",
      "Epoch 3/500\n",
      "1000/1000 - 1s - 774us/step - accuracy: 0.1700 - loss: 2.5559\n",
      "Epoch 4/500\n",
      "1000/1000 - 1s - 779us/step - accuracy: 0.2320 - loss: 2.2867\n",
      "Epoch 5/500\n",
      "1000/1000 - 1s - 798us/step - accuracy: 0.2800 - loss: 2.1165\n",
      "Epoch 6/500\n",
      "1000/1000 - 1s - 811us/step - accuracy: 0.3150 - loss: 1.9774\n",
      "Epoch 7/500\n",
      "1000/1000 - 1s - 781us/step - accuracy: 0.3610 - loss: 1.8770\n",
      "Epoch 8/500\n",
      "1000/1000 - 1s - 812us/step - accuracy: 0.3630 - loss: 1.7738\n",
      "Epoch 9/500\n",
      "1000/1000 - 1s - 806us/step - accuracy: 0.3900 - loss: 1.6888\n",
      "Epoch 10/500\n",
      "1000/1000 - 1s - 829us/step - accuracy: 0.4240 - loss: 1.6155\n",
      "Epoch 11/500\n",
      "1000/1000 - 1s - 805us/step - accuracy: 0.4570 - loss: 1.5427\n",
      "Epoch 12/500\n",
      "1000/1000 - 1s - 778us/step - accuracy: 0.4790 - loss: 1.4768\n",
      "Epoch 13/500\n",
      "1000/1000 - 1s - 798us/step - accuracy: 0.5100 - loss: 1.4184\n",
      "Epoch 14/500\n",
      "1000/1000 - 1s - 819us/step - accuracy: 0.5250 - loss: 1.3703\n",
      "Epoch 15/500\n",
      "1000/1000 - 1s - 784us/step - accuracy: 0.5430 - loss: 1.3227\n",
      "Epoch 16/500\n",
      "1000/1000 - 1s - 787us/step - accuracy: 0.5870 - loss: 1.2644\n",
      "Epoch 17/500\n",
      "1000/1000 - 1s - 824us/step - accuracy: 0.6110 - loss: 1.2234\n",
      "Epoch 18/500\n",
      "1000/1000 - 1s - 782us/step - accuracy: 0.6210 - loss: 1.1690\n",
      "Epoch 19/500\n",
      "1000/1000 - 1s - 788us/step - accuracy: 0.6440 - loss: 1.1349\n",
      "Epoch 20/500\n",
      "1000/1000 - 1s - 800us/step - accuracy: 0.6600 - loss: 1.0962\n",
      "Epoch 21/500\n",
      "1000/1000 - 1s - 808us/step - accuracy: 0.6850 - loss: 1.0607\n",
      "Epoch 22/500\n",
      "1000/1000 - 1s - 807us/step - accuracy: 0.6850 - loss: 1.0360\n",
      "Epoch 23/500\n",
      "1000/1000 - 1s - 770us/step - accuracy: 0.7020 - loss: 0.9866\n",
      "Epoch 24/500\n",
      "1000/1000 - 1s - 765us/step - accuracy: 0.6970 - loss: 0.9689\n",
      "Epoch 25/500\n",
      "1000/1000 - 1s - 823us/step - accuracy: 0.7140 - loss: 0.9548\n",
      "Epoch 26/500\n",
      "1000/1000 - 1s - 822us/step - accuracy: 0.7310 - loss: 0.8921\n",
      "Epoch 27/500\n",
      "1000/1000 - 1s - 783us/step - accuracy: 0.7420 - loss: 0.8866\n",
      "Epoch 28/500\n",
      "1000/1000 - 1s - 788us/step - accuracy: 0.7280 - loss: 0.8682\n",
      "Epoch 29/500\n",
      "1000/1000 - 1s - 825us/step - accuracy: 0.7530 - loss: 0.8378\n",
      "Epoch 30/500\n",
      "1000/1000 - 1s - 796us/step - accuracy: 0.7380 - loss: 0.8286\n",
      "Epoch 31/500\n",
      "1000/1000 - 1s - 763us/step - accuracy: 0.7520 - loss: 0.7932\n",
      "Epoch 32/500\n",
      "1000/1000 - 1s - 788us/step - accuracy: 0.7530 - loss: 0.7874\n",
      "Epoch 33/500\n",
      "1000/1000 - 1s - 822us/step - accuracy: 0.7630 - loss: 0.7801\n",
      "Epoch 34/500\n",
      "1000/1000 - 1s - 813us/step - accuracy: 0.7680 - loss: 0.7554\n",
      "Epoch 35/500\n",
      "1000/1000 - 1s - 784us/step - accuracy: 0.7670 - loss: 0.7482\n",
      "Epoch 36/500\n",
      "1000/1000 - 1s - 786us/step - accuracy: 0.7880 - loss: 0.7175\n",
      "Epoch 37/500\n",
      "1000/1000 - 1s - 819us/step - accuracy: 0.7690 - loss: 0.7267\n",
      "Epoch 38/500\n",
      "1000/1000 - 1s - 827us/step - accuracy: 0.7760 - loss: 0.7159\n",
      "Epoch 39/500\n",
      "1000/1000 - 1s - 794us/step - accuracy: 0.7890 - loss: 0.6798\n",
      "Epoch 40/500\n",
      "1000/1000 - 1s - 775us/step - accuracy: 0.7660 - loss: 0.7155\n",
      "Epoch 41/500\n",
      "1000/1000 - 1s - 811us/step - accuracy: 0.7930 - loss: 0.6666\n",
      "Epoch 42/500\n",
      "1000/1000 - 1s - 831us/step - accuracy: 0.7940 - loss: 0.6588\n",
      "Epoch 43/500\n",
      "1000/1000 - 1s - 816us/step - accuracy: 0.7790 - loss: 0.6755\n",
      "Epoch 44/500\n",
      "1000/1000 - 1s - 784us/step - accuracy: 0.7920 - loss: 0.6353\n",
      "Epoch 45/500\n",
      "1000/1000 - 1s - 776us/step - accuracy: 0.7820 - loss: 0.6788\n",
      "Epoch 46/500\n",
      "1000/1000 - 1s - 782us/step - accuracy: 0.8040 - loss: 0.6301\n",
      "Epoch 47/500\n",
      "1000/1000 - 1s - 771us/step - accuracy: 0.8150 - loss: 0.6086\n",
      "Epoch 48/500\n",
      "1000/1000 - 1s - 743us/step - accuracy: 0.7920 - loss: 0.6429\n",
      "Epoch 49/500\n",
      "1000/1000 - 1s - 783us/step - accuracy: 0.8100 - loss: 0.6334\n",
      "Epoch 50/500\n",
      "1000/1000 - 1s - 790us/step - accuracy: 0.7940 - loss: 0.6243\n",
      "Epoch 51/500\n",
      "1000/1000 - 1s - 745us/step - accuracy: 0.8170 - loss: 0.5738\n",
      "Epoch 52/500\n",
      "1000/1000 - 1s - 768us/step - accuracy: 0.8250 - loss: 0.5704\n",
      "Epoch 53/500\n",
      "1000/1000 - 1s - 804us/step - accuracy: 0.8040 - loss: 0.6145\n",
      "Epoch 54/500\n",
      "1000/1000 - 1s - 798us/step - accuracy: 0.8260 - loss: 0.5531\n",
      "Epoch 55/500\n",
      "1000/1000 - 1s - 802us/step - accuracy: 0.8070 - loss: 0.5910\n",
      "Epoch 56/500\n",
      "1000/1000 - 1s - 809us/step - accuracy: 0.8210 - loss: 0.5476\n",
      "Epoch 57/500\n",
      "1000/1000 - 1s - 788us/step - accuracy: 0.8220 - loss: 0.5623\n",
      "Epoch 58/500\n",
      "1000/1000 - 1s - 790us/step - accuracy: 0.8130 - loss: 0.5939\n",
      "Epoch 59/500\n",
      "1000/1000 - 1s - 802us/step - accuracy: 0.8400 - loss: 0.5267\n",
      "Epoch 60/500\n",
      "1000/1000 - 1s - 780us/step - accuracy: 0.8260 - loss: 0.5353\n",
      "Epoch 61/500\n",
      "1000/1000 - 1s - 784us/step - accuracy: 0.8240 - loss: 0.5331\n",
      "Epoch 62/500\n",
      "1000/1000 - 1s - 787us/step - accuracy: 0.8300 - loss: 0.5178\n",
      "Epoch 63/500\n",
      "1000/1000 - 1s - 788us/step - accuracy: 0.8080 - loss: 0.5614\n",
      "Epoch 64/500\n",
      "1000/1000 - 1s - 799us/step - accuracy: 0.8420 - loss: 0.4994\n",
      "Epoch 65/500\n",
      "1000/1000 - 1s - 840us/step - accuracy: 0.8130 - loss: 0.5717\n",
      "Epoch 66/500\n",
      "1000/1000 - 1s - 804us/step - accuracy: 0.8400 - loss: 0.4854\n",
      "Epoch 67/500\n",
      "1000/1000 - 1s - 783us/step - accuracy: 0.7930 - loss: 0.5851\n",
      "Epoch 68/500\n",
      "1000/1000 - 1s - 763us/step - accuracy: 0.8530 - loss: 0.4845\n",
      "Epoch 69/500\n",
      "1000/1000 - 1s - 765us/step - accuracy: 0.8500 - loss: 0.4815\n",
      "Epoch 70/500\n",
      "1000/1000 - 1s - 792us/step - accuracy: 0.8350 - loss: 0.4883\n",
      "Epoch 71/500\n",
      "1000/1000 - 1s - 786us/step - accuracy: 0.8380 - loss: 0.4801\n",
      "Epoch 72/500\n",
      "1000/1000 - 1s - 770us/step - accuracy: 0.8030 - loss: 0.5856\n",
      "Epoch 73/500\n",
      "1000/1000 - 1s - 804us/step - accuracy: 0.8620 - loss: 0.4588\n",
      "Epoch 74/500\n",
      "1000/1000 - 1s - 803us/step - accuracy: 0.8360 - loss: 0.5077\n",
      "Epoch 75/500\n",
      "1000/1000 - 1s - 807us/step - accuracy: 0.8600 - loss: 0.4524\n",
      "Epoch 76/500\n",
      "1000/1000 - 1s - 803us/step - accuracy: 0.8480 - loss: 0.4599\n",
      "Epoch 77/500\n",
      "1000/1000 - 1s - 813us/step - accuracy: 0.8410 - loss: 0.4800\n",
      "Epoch 78/500\n",
      "1000/1000 - 1s - 768us/step - accuracy: 0.8340 - loss: 0.5151\n",
      "Epoch 79/500\n",
      "1000/1000 - 1s - 759us/step - accuracy: 0.8530 - loss: 0.4710\n",
      "Epoch 80/500\n",
      "1000/1000 - 1s - 733us/step - accuracy: 0.8530 - loss: 0.4340\n",
      "Epoch 81/500\n",
      "1000/1000 - 1s - 755us/step - accuracy: 0.8540 - loss: 0.4528\n",
      "Epoch 82/500\n",
      "1000/1000 - 1s - 777us/step - accuracy: 0.8470 - loss: 0.4451\n",
      "Epoch 83/500\n",
      "1000/1000 - 1s - 789us/step - accuracy: 0.8430 - loss: 0.4912\n",
      "Epoch 84/500\n",
      "1000/1000 - 1s - 765us/step - accuracy: 0.8710 - loss: 0.4330\n",
      "Epoch 85/500\n",
      "1000/1000 - 1s - 802us/step - accuracy: 0.8620 - loss: 0.4309\n",
      "Epoch 86/500\n",
      "1000/1000 - 1s - 792us/step - accuracy: 0.8340 - loss: 0.4839\n",
      "Epoch 87/500\n",
      "1000/1000 - 1s - 759us/step - accuracy: 0.8650 - loss: 0.4314\n",
      "Epoch 88/500\n",
      "1000/1000 - 1s - 799us/step - accuracy: 0.8770 - loss: 0.4105\n",
      "Epoch 89/500\n",
      "1000/1000 - 1s - 817us/step - accuracy: 0.8620 - loss: 0.4157\n",
      "Epoch 90/500\n",
      "1000/1000 - 1s - 778us/step - accuracy: 0.8210 - loss: 0.5082\n",
      "Epoch 91/500\n",
      "1000/1000 - 1s - 753us/step - accuracy: 0.8710 - loss: 0.4024\n",
      "Epoch 92/500\n",
      "1000/1000 - 1s - 795us/step - accuracy: 0.8470 - loss: 0.4592\n",
      "Epoch 93/500\n",
      "1000/1000 - 1s - 812us/step - accuracy: 0.8710 - loss: 0.3982\n",
      "Epoch 94/500\n",
      "1000/1000 - 1s - 802us/step - accuracy: 0.8600 - loss: 0.4111\n",
      "Epoch 95/500\n",
      "1000/1000 - 1s - 766us/step - accuracy: 0.8600 - loss: 0.4119\n",
      "Epoch 96/500\n",
      "1000/1000 - 1s - 776us/step - accuracy: 0.8480 - loss: 0.5071\n",
      "Epoch 97/500\n",
      "1000/1000 - 1s - 854us/step - accuracy: 0.8770 - loss: 0.3882\n",
      "Epoch 98/500\n",
      "1000/1000 - 1s - 803us/step - accuracy: 0.8700 - loss: 0.3981\n",
      "Epoch 99/500\n",
      "1000/1000 - 1s - 764us/step - accuracy: 0.8660 - loss: 0.3964\n",
      "Epoch 100/500\n",
      "1000/1000 - 1s - 779us/step - accuracy: 0.8150 - loss: 0.5032\n",
      "Epoch 101/500\n",
      "1000/1000 - 1s - 778us/step - accuracy: 0.8780 - loss: 0.3697\n",
      "Epoch 102/500\n",
      "1000/1000 - 1s - 838us/step - accuracy: 0.8850 - loss: 0.3760\n",
      "Epoch 103/500\n",
      "1000/1000 - 1s - 818us/step - accuracy: 0.8730 - loss: 0.3846\n",
      "Epoch 104/500\n",
      "1000/1000 - 1s - 778us/step - accuracy: 0.8710 - loss: 0.3928\n",
      "Epoch 105/500\n",
      "1000/1000 - 1s - 766us/step - accuracy: 0.8390 - loss: 0.5137\n",
      "Epoch 106/500\n",
      "1000/1000 - 1s - 829us/step - accuracy: 0.8810 - loss: 0.3718\n",
      "Epoch 107/500\n",
      "1000/1000 - 1s - 792us/step - accuracy: 0.8850 - loss: 0.3749\n",
      "Epoch 108/500\n",
      "1000/1000 - 1s - 754us/step - accuracy: 0.8480 - loss: 0.4667\n",
      "Epoch 109/500\n",
      "1000/1000 - 1s - 780us/step - accuracy: 0.8940 - loss: 0.3643\n",
      "Epoch 110/500\n",
      "1000/1000 - 1s - 834us/step - accuracy: 0.8850 - loss: 0.3662\n",
      "Epoch 111/500\n",
      "1000/1000 - 1s - 810us/step - accuracy: 0.8920 - loss: 0.3705\n",
      "Epoch 112/500\n",
      "1000/1000 - 1s - 773us/step - accuracy: 0.8700 - loss: 0.3825\n",
      "Epoch 113/500\n",
      "1000/1000 - 1s - 810us/step - accuracy: 0.8840 - loss: 0.3687\n",
      "Epoch 114/500\n",
      "1000/1000 - 1s - 783us/step - accuracy: 0.8460 - loss: 0.4514\n",
      "Epoch 115/500\n",
      "1000/1000 - 1s - 766us/step - accuracy: 0.8880 - loss: 0.3556\n",
      "Epoch 116/500\n",
      "1000/1000 - 1s - 764us/step - accuracy: 0.8850 - loss: 0.3496\n",
      "Epoch 117/500\n",
      "1000/1000 - 1s - 765us/step - accuracy: 0.8900 - loss: 0.3547\n",
      "Epoch 118/500\n",
      "1000/1000 - 1s - 818us/step - accuracy: 0.8410 - loss: 0.4832\n",
      "Epoch 119/500\n",
      "1000/1000 - 1s - 798us/step - accuracy: 0.8950 - loss: 0.3424\n",
      "Epoch 120/500\n",
      "1000/1000 - 1s - 747us/step - accuracy: 0.8950 - loss: 0.3462\n",
      "Epoch 121/500\n",
      "1000/1000 - 1s - 773us/step - accuracy: 0.8730 - loss: 0.3750\n",
      "Epoch 122/500\n",
      "1000/1000 - 1s - 786us/step - accuracy: 0.8780 - loss: 0.3818\n",
      "Epoch 123/500\n",
      "1000/1000 - 1s - 784us/step - accuracy: 0.8980 - loss: 0.3377\n",
      "Epoch 124/500\n",
      "1000/1000 - 1s - 762us/step - accuracy: 0.8760 - loss: 0.3867\n",
      "Epoch 125/500\n",
      "1000/1000 - 1s - 772us/step - accuracy: 0.8930 - loss: 0.3343\n",
      "Epoch 126/500\n",
      "1000/1000 - 1s - 796us/step - accuracy: 0.8850 - loss: 0.3388\n",
      "Epoch 127/500\n",
      "1000/1000 - 1s - 797us/step - accuracy: 0.8930 - loss: 0.3352\n",
      "Epoch 128/500\n",
      "1000/1000 - 1s - 751us/step - accuracy: 0.8240 - loss: 0.4984\n",
      "Epoch 129/500\n",
      "1000/1000 - 1s - 765us/step - accuracy: 0.9080 - loss: 0.3295\n",
      "Epoch 130/500\n",
      "1000/1000 - 1s - 793us/step - accuracy: 0.9020 - loss: 0.3264\n",
      "Epoch 131/500\n",
      "1000/1000 - 1s - 781us/step - accuracy: 0.8910 - loss: 0.3299\n",
      "Epoch 132/500\n",
      "1000/1000 - 1s - 773us/step - accuracy: 0.8920 - loss: 0.3366\n",
      "Epoch 133/500\n",
      "1000/1000 - 1s - 767us/step - accuracy: 0.8720 - loss: 0.4050\n",
      "Epoch 134/500\n",
      "1000/1000 - 1s - 775us/step - accuracy: 0.9040 - loss: 0.3197\n",
      "Epoch 135/500\n",
      "1000/1000 - 1s - 791us/step - accuracy: 0.8970 - loss: 0.3267\n",
      "Epoch 136/500\n",
      "1000/1000 - 1s - 790us/step - accuracy: 0.8890 - loss: 0.3256\n",
      "Epoch 137/500\n",
      "1000/1000 - 1s - 749us/step - accuracy: 0.8700 - loss: 0.4236\n",
      "Epoch 138/500\n",
      "1000/1000 - 1s - 772us/step - accuracy: 0.9040 - loss: 0.3191\n",
      "Epoch 139/500\n",
      "1000/1000 - 1s - 802us/step - accuracy: 0.9080 - loss: 0.3155\n",
      "Epoch 140/500\n",
      "1000/1000 - 1s - 777us/step - accuracy: 0.8910 - loss: 0.3305\n",
      "Epoch 141/500\n",
      "1000/1000 - 1s - 779us/step - accuracy: 0.8920 - loss: 0.3236\n",
      "Epoch 142/500\n",
      "1000/1000 - 1s - 820us/step - accuracy: 0.8960 - loss: 0.3286\n",
      "Epoch 143/500\n",
      "1000/1000 - 1s - 777us/step - accuracy: 0.8980 - loss: 0.3153\n",
      "Epoch 144/500\n",
      "1000/1000 - 1s - 814us/step - accuracy: 0.8280 - loss: 0.5115\n",
      "Epoch 145/500\n",
      "1000/1000 - 1s - 762us/step - accuracy: 0.9080 - loss: 0.3052\n",
      "Epoch 146/500\n",
      "1000/1000 - 1s - 754us/step - accuracy: 0.9050 - loss: 0.3085\n",
      "Epoch 147/500\n",
      "1000/1000 - 1s - 766us/step - accuracy: 0.8990 - loss: 0.3102\n",
      "Epoch 148/500\n",
      "1000/1000 - 1s - 787us/step - accuracy: 0.8810 - loss: 0.3999\n",
      "Epoch 149/500\n",
      "1000/1000 - 1s - 771us/step - accuracy: 0.9100 - loss: 0.3063\n",
      "Epoch 150/500\n",
      "1000/1000 - 1s - 754us/step - accuracy: 0.9080 - loss: 0.3088\n",
      "Epoch 151/500\n",
      "1000/1000 - 1s - 781us/step - accuracy: 0.8950 - loss: 0.3449\n",
      "Epoch 152/500\n",
      "1000/1000 - 1s - 765us/step - accuracy: 0.9010 - loss: 0.3070\n",
      "Epoch 153/500\n",
      "1000/1000 - 1s - 785us/step - accuracy: 0.8860 - loss: 0.3565\n",
      "Epoch 154/500\n",
      "1000/1000 - 1s - 763us/step - accuracy: 0.9050 - loss: 0.3383\n",
      "Epoch 155/500\n",
      "1000/1000 - 1s - 761us/step - accuracy: 0.9090 - loss: 0.2936\n",
      "Epoch 156/500\n",
      "1000/1000 - 1s - 776us/step - accuracy: 0.9070 - loss: 0.3043\n",
      "Epoch 157/500\n",
      "1000/1000 - 1s - 775us/step - accuracy: 0.9030 - loss: 0.3054\n",
      "Epoch 158/500\n",
      "1000/1000 - 1s - 793us/step - accuracy: 0.8840 - loss: 0.3768\n",
      "Epoch 159/500\n",
      "1000/1000 - 1s - 778us/step - accuracy: 0.9110 - loss: 0.2908\n",
      "Epoch 160/500\n",
      "1000/1000 - 1s - 771us/step - accuracy: 0.8690 - loss: 0.4048\n",
      "Epoch 161/500\n",
      "1000/1000 - 1s - 781us/step - accuracy: 0.9110 - loss: 0.3031\n",
      "Epoch 162/500\n",
      "1000/1000 - 1s - 796us/step - accuracy: 0.9060 - loss: 0.2872\n",
      "Epoch 163/500\n",
      "1000/1000 - 1s - 744us/step - accuracy: 0.9090 - loss: 0.2927\n",
      "Epoch 164/500\n",
      "1000/1000 - 1s - 756us/step - accuracy: 0.9070 - loss: 0.2936\n",
      "Epoch 165/500\n",
      "1000/1000 - 1s - 786us/step - accuracy: 0.8830 - loss: 0.4597\n",
      "Epoch 166/500\n",
      "1000/1000 - 1s - 789us/step - accuracy: 0.9200 - loss: 0.2851\n",
      "Epoch 167/500\n",
      "1000/1000 - 1s - 751us/step - accuracy: 0.9130 - loss: 0.2864\n",
      "Epoch 168/500\n",
      "1000/1000 - 1s - 773us/step - accuracy: 0.9050 - loss: 0.2918\n",
      "Epoch 169/500\n",
      "1000/1000 - 1s - 785us/step - accuracy: 0.8990 - loss: 0.3302\n",
      "Epoch 170/500\n",
      "1000/1000 - 1s - 784us/step - accuracy: 0.9110 - loss: 0.2812\n",
      "Epoch 171/500\n",
      "1000/1000 - 1s - 757us/step - accuracy: 0.8800 - loss: 0.3664\n",
      "Epoch 172/500\n",
      "1000/1000 - 1s - 743us/step - accuracy: 0.9120 - loss: 0.2798\n",
      "Epoch 173/500\n",
      "1000/1000 - 1s - 800us/step - accuracy: 0.9100 - loss: 0.2795\n",
      "Epoch 174/500\n",
      "1000/1000 - 1s - 783us/step - accuracy: 0.9140 - loss: 0.2812\n",
      "Epoch 175/500\n",
      "1000/1000 - 1s - 768us/step - accuracy: 0.8890 - loss: 0.3475\n",
      "Epoch 176/500\n",
      "1000/1000 - 1s - 1ms/step - accuracy: 0.9190 - loss: 0.2883\n",
      "Epoch 177/500\n",
      "1000/1000 - 1s - 788us/step - accuracy: 0.9080 - loss: 0.2795\n",
      "Epoch 178/500\n",
      "1000/1000 - 1s - 799us/step - accuracy: 0.9050 - loss: 0.2787\n",
      "Epoch 179/500\n",
      "1000/1000 - 1s - 789us/step - accuracy: 0.9140 - loss: 0.2780\n",
      "Epoch 180/500\n",
      "1000/1000 - 1s - 772us/step - accuracy: 0.8760 - loss: 0.4100\n",
      "Epoch 181/500\n",
      "1000/1000 - 1s - 780us/step - accuracy: 0.9020 - loss: 0.2954\n",
      "Epoch 182/500\n",
      "1000/1000 - 1s - 779us/step - accuracy: 0.9160 - loss: 0.2702\n",
      "Epoch 183/500\n",
      "1000/1000 - 1s - 767us/step - accuracy: 0.9160 - loss: 0.2710\n",
      "Epoch 184/500\n",
      "1000/1000 - 1s - 797us/step - accuracy: 0.9090 - loss: 0.2786\n",
      "Epoch 185/500\n",
      "1000/1000 - 1s - 742us/step - accuracy: 0.9180 - loss: 0.2723\n",
      "Epoch 186/500\n",
      "1000/1000 - 1s - 757us/step - accuracy: 0.8860 - loss: 0.3734\n",
      "Epoch 187/500\n",
      "1000/1000 - 1s - 779us/step - accuracy: 0.9180 - loss: 0.2697\n",
      "Epoch 188/500\n",
      "1000/1000 - 1s - 785us/step - accuracy: 0.9200 - loss: 0.2643\n",
      "Epoch 189/500\n",
      "1000/1000 - 1s - 770us/step - accuracy: 0.9150 - loss: 0.2681\n",
      "Epoch 190/500\n",
      "1000/1000 - 1s - 750us/step - accuracy: 0.9080 - loss: 0.3116\n",
      "Epoch 191/500\n",
      "1000/1000 - 1s - 776us/step - accuracy: 0.9210 - loss: 0.2608\n",
      "Epoch 192/500\n",
      "1000/1000 - 1s - 790us/step - accuracy: 0.9150 - loss: 0.2674\n",
      "Epoch 193/500\n",
      "1000/1000 - 1s - 766us/step - accuracy: 0.8780 - loss: 0.4837\n",
      "Epoch 194/500\n",
      "1000/1000 - 1s - 767us/step - accuracy: 0.9260 - loss: 0.2573\n",
      "Epoch 195/500\n",
      "1000/1000 - 1s - 754us/step - accuracy: 0.9220 - loss: 0.2569\n",
      "Epoch 196/500\n",
      "1000/1000 - 1s - 766us/step - accuracy: 0.9140 - loss: 0.2613\n",
      "Epoch 197/500\n",
      "1000/1000 - 1s - 801us/step - accuracy: 0.9280 - loss: 0.2640\n",
      "Epoch 198/500\n",
      "1000/1000 - 1s - 762us/step - accuracy: 0.9200 - loss: 0.2676\n",
      "Epoch 199/500\n",
      "1000/1000 - 1s - 761us/step - accuracy: 0.8720 - loss: 0.4020\n",
      "Epoch 200/500\n",
      "1000/1000 - 1s - 812us/step - accuracy: 0.9250 - loss: 0.2507\n",
      "Epoch 201/500\n",
      "1000/1000 - 1s - 796us/step - accuracy: 0.9240 - loss: 0.2558\n",
      "Epoch 202/500\n",
      "1000/1000 - 1s - 757us/step - accuracy: 0.9260 - loss: 0.2555\n",
      "Epoch 203/500\n",
      "1000/1000 - 1s - 774us/step - accuracy: 0.8810 - loss: 0.4411\n",
      "Epoch 204/500\n",
      "1000/1000 - 1s - 765us/step - accuracy: 0.9200 - loss: 0.2830\n",
      "Epoch 205/500\n",
      "1000/1000 - 1s - 777us/step - accuracy: 0.9200 - loss: 0.2477\n",
      "Epoch 206/500\n",
      "1000/1000 - 1s - 762us/step - accuracy: 0.9250 - loss: 0.2531\n",
      "Epoch 207/500\n",
      "1000/1000 - 1s - 762us/step - accuracy: 0.9240 - loss: 0.2567\n",
      "Epoch 208/500\n",
      "1000/1000 - 1s - 769us/step - accuracy: 0.9000 - loss: 0.3374\n",
      "Epoch 209/500\n",
      "1000/1000 - 1s - 772us/step - accuracy: 0.9300 - loss: 0.2502\n",
      "Epoch 210/500\n",
      "1000/1000 - 1s - 784us/step - accuracy: 0.9170 - loss: 0.2506\n",
      "Epoch 211/500\n",
      "1000/1000 - 1s - 749us/step - accuracy: 0.9260 - loss: 0.2541\n",
      "Epoch 212/500\n",
      "1000/1000 - 1s - 752us/step - accuracy: 0.9200 - loss: 0.2533\n",
      "Epoch 213/500\n",
      "1000/1000 - 1s - 1ms/step - accuracy: 0.8770 - loss: 0.3663\n",
      "Epoch 214/500\n",
      "1000/1000 - 1s - 791us/step - accuracy: 0.9280 - loss: 0.2420\n",
      "Epoch 215/500\n",
      "1000/1000 - 1s - 762us/step - accuracy: 0.9260 - loss: 0.2442\n",
      "Epoch 216/500\n",
      "1000/1000 - 1s - 768us/step - accuracy: 0.9280 - loss: 0.2453\n",
      "Epoch 217/500\n",
      "1000/1000 - 1s - 792us/step - accuracy: 0.9210 - loss: 0.2504\n",
      "Epoch 218/500\n",
      "1000/1000 - 1s - 813us/step - accuracy: 0.9120 - loss: 0.2852\n",
      "Epoch 219/500\n",
      "1000/1000 - 1s - 772us/step - accuracy: 0.9300 - loss: 0.2421\n",
      "Epoch 220/500\n",
      "1000/1000 - 1s - 758us/step - accuracy: 0.9320 - loss: 0.2439\n",
      "Epoch 221/500\n",
      "1000/1000 - 1s - 743us/step - accuracy: 0.9240 - loss: 0.2447\n",
      "Epoch 222/500\n",
      "1000/1000 - 1s - 799us/step - accuracy: 0.9030 - loss: 0.3397\n",
      "Epoch 223/500\n",
      "1000/1000 - 1s - 776us/step - accuracy: 0.9300 - loss: 0.2396\n",
      "Epoch 224/500\n",
      "1000/1000 - 1s - 763us/step - accuracy: 0.9310 - loss: 0.2405\n",
      "Epoch 225/500\n",
      "1000/1000 - 1s - 774us/step - accuracy: 0.9280 - loss: 0.2448\n",
      "Epoch 226/500\n",
      "1000/1000 - 1s - 752us/step - accuracy: 0.9010 - loss: 0.3101\n",
      "Epoch 227/500\n",
      "1000/1000 - 1s - 785us/step - accuracy: 0.9090 - loss: 0.3016\n",
      "Epoch 228/500\n",
      "1000/1000 - 1s - 786us/step - accuracy: 0.9350 - loss: 0.2321\n",
      "Epoch 229/500\n",
      "1000/1000 - 1s - 778us/step - accuracy: 0.9370 - loss: 0.2374\n",
      "Epoch 230/500\n",
      "1000/1000 - 1s - 763us/step - accuracy: 0.9230 - loss: 0.2412\n",
      "Epoch 231/500\n",
      "1000/1000 - 1s - 770us/step - accuracy: 0.9270 - loss: 0.2430\n",
      "Epoch 232/500\n",
      "1000/1000 - 1s - 785us/step - accuracy: 0.8870 - loss: 0.3773\n",
      "Epoch 233/500\n",
      "1000/1000 - 1s - 767us/step - accuracy: 0.9370 - loss: 0.2325\n",
      "Epoch 234/500\n",
      "1000/1000 - 1s - 760us/step - accuracy: 0.9320 - loss: 0.2304\n",
      "Epoch 235/500\n",
      "1000/1000 - 1s - 764us/step - accuracy: 0.9310 - loss: 0.2320\n",
      "Epoch 236/500\n",
      "1000/1000 - 1s - 796us/step - accuracy: 0.9270 - loss: 0.2333\n",
      "Epoch 237/500\n",
      "1000/1000 - 1s - 767us/step - accuracy: 0.9090 - loss: 0.3323\n",
      "Epoch 238/500\n",
      "1000/1000 - 1s - 760us/step - accuracy: 0.9360 - loss: 0.2270\n",
      "Epoch 239/500\n",
      "1000/1000 - 1s - 770us/step - accuracy: 0.9300 - loss: 0.2323\n",
      "Epoch 240/500\n",
      "1000/1000 - 1s - 830us/step - accuracy: 0.9410 - loss: 0.2321\n",
      "Epoch 241/500\n",
      "1000/1000 - 1s - 773us/step - accuracy: 0.9090 - loss: 0.2957\n",
      "Epoch 242/500\n",
      "1000/1000 - 1s - 783us/step - accuracy: 0.9320 - loss: 0.2300\n",
      "Epoch 243/500\n",
      "1000/1000 - 1s - 783us/step - accuracy: 0.9310 - loss: 0.2298\n",
      "Epoch 244/500\n",
      "1000/1000 - 1s - 777us/step - accuracy: 0.9140 - loss: 0.2616\n",
      "Epoch 245/500\n",
      "1000/1000 - 1s - 780us/step - accuracy: 0.9340 - loss: 0.2239\n",
      "Epoch 246/500\n",
      "1000/1000 - 1s - 765us/step - accuracy: 0.9340 - loss: 0.2250\n",
      "Epoch 247/500\n",
      "1000/1000 - 1s - 751us/step - accuracy: 0.9230 - loss: 0.2701\n",
      "Epoch 248/500\n",
      "1000/1000 - 1s - 791us/step - accuracy: 0.9150 - loss: 0.3091\n",
      "Epoch 249/500\n",
      "1000/1000 - 1s - 775us/step - accuracy: 0.9390 - loss: 0.2249\n",
      "Epoch 250/500\n",
      "1000/1000 - 1s - 740us/step - accuracy: 0.9390 - loss: 0.2256\n",
      "Epoch 251/500\n",
      "1000/1000 - 1s - 753us/step - accuracy: 0.9260 - loss: 0.2275\n",
      "Epoch 252/500\n",
      "1000/1000 - 1s - 778us/step - accuracy: 0.9310 - loss: 0.2260\n",
      "Epoch 253/500\n",
      "1000/1000 - 1s - 783us/step - accuracy: 0.9140 - loss: 0.2767\n",
      "Epoch 254/500\n",
      "1000/1000 - 1s - 748us/step - accuracy: 0.9390 - loss: 0.2224\n",
      "Epoch 255/500\n",
      "1000/1000 - 1s - 750us/step - accuracy: 0.9330 - loss: 0.2248\n",
      "Epoch 256/500\n",
      "1000/1000 - 1s - 786us/step - accuracy: 0.9330 - loss: 0.2268\n",
      "Epoch 257/500\n",
      "1000/1000 - 1s - 868us/step - accuracy: 0.9360 - loss: 0.2216\n",
      "Epoch 258/500\n",
      "1000/1000 - 1s - 756us/step - accuracy: 0.8970 - loss: 0.4004\n",
      "Epoch 259/500\n",
      "1000/1000 - 1s - 754us/step - accuracy: 0.9430 - loss: 0.2100\n",
      "Epoch 260/500\n",
      "1000/1000 - 1s - 769us/step - accuracy: 0.9400 - loss: 0.2161\n",
      "Epoch 261/500\n",
      "1000/1000 - 1s - 792us/step - accuracy: 0.9400 - loss: 0.2209\n",
      "Epoch 262/500\n",
      "1000/1000 - 1s - 773us/step - accuracy: 0.9370 - loss: 0.2265\n",
      "Epoch 263/500\n",
      "1000/1000 - 1s - 765us/step - accuracy: 0.9320 - loss: 0.2249\n",
      "Epoch 264/500\n",
      "1000/1000 - 1s - 781us/step - accuracy: 0.9390 - loss: 0.2173\n",
      "Epoch 265/500\n",
      "1000/1000 - 1s - 781us/step - accuracy: 0.9230 - loss: 0.2643\n",
      "Epoch 266/500\n",
      "1000/1000 - 1s - 771us/step - accuracy: 0.9360 - loss: 0.2126\n",
      "Epoch 267/500\n",
      "1000/1000 - 1s - 745us/step - accuracy: 0.9320 - loss: 0.2197\n",
      "Epoch 268/500\n",
      "1000/1000 - 1s - 790us/step - accuracy: 0.9330 - loss: 0.2172\n",
      "Epoch 269/500\n",
      "1000/1000 - 1s - 796us/step - accuracy: 0.9400 - loss: 0.2195\n",
      "Epoch 270/500\n",
      "1000/1000 - 1s - 790us/step - accuracy: 0.9000 - loss: 0.3044\n",
      "Epoch 271/500\n",
      "1000/1000 - 1s - 764us/step - accuracy: 0.9390 - loss: 0.2057\n",
      "Epoch 272/500\n",
      "1000/1000 - 1s - 784us/step - accuracy: 0.9430 - loss: 0.2061\n",
      "Epoch 273/500\n",
      "1000/1000 - 1s - 776us/step - accuracy: 0.9410 - loss: 0.2129\n",
      "Epoch 274/500\n",
      "1000/1000 - 1s - 790us/step - accuracy: 0.9360 - loss: 0.2152\n",
      "Epoch 275/500\n",
      "1000/1000 - 1s - 765us/step - accuracy: 0.9230 - loss: 0.2916\n",
      "Epoch 276/500\n",
      "1000/1000 - 1s - 756us/step - accuracy: 0.9400 - loss: 0.2084\n",
      "Epoch 277/500\n",
      "1000/1000 - 1s - 781us/step - accuracy: 0.9300 - loss: 0.2139\n",
      "Epoch 278/500\n",
      "1000/1000 - 1s - 793us/step - accuracy: 0.9350 - loss: 0.2137\n",
      "Epoch 279/500\n",
      "1000/1000 - 1s - 774us/step - accuracy: 0.9390 - loss: 0.2122\n",
      "Epoch 280/500\n",
      "1000/1000 - 1s - 757us/step - accuracy: 0.8990 - loss: 0.3696\n",
      "Epoch 281/500\n",
      "1000/1000 - 1s - 769us/step - accuracy: 0.9560 - loss: 0.2044\n",
      "Epoch 282/500\n",
      "1000/1000 - 1s - 800us/step - accuracy: 0.9440 - loss: 0.2062\n",
      "Epoch 283/500\n",
      "1000/1000 - 1s - 777us/step - accuracy: 0.9360 - loss: 0.2033\n",
      "Epoch 284/500\n",
      "1000/1000 - 1s - 765us/step - accuracy: 0.9150 - loss: 0.3152\n",
      "Epoch 285/500\n",
      "1000/1000 - 1s - 755us/step - accuracy: 0.9420 - loss: 0.2039\n",
      "Epoch 286/500\n",
      "1000/1000 - 1s - 755us/step - accuracy: 0.9450 - loss: 0.1991\n",
      "Epoch 287/500\n",
      "1000/1000 - 1s - 742us/step - accuracy: 0.9340 - loss: 0.2053\n",
      "Epoch 288/500\n",
      "1000/1000 - 1s - 784us/step - accuracy: 0.9420 - loss: 0.2034\n",
      "Epoch 289/500\n",
      "1000/1000 - 1s - 760us/step - accuracy: 0.9410 - loss: 0.2105\n",
      "Epoch 290/500\n",
      "1000/1000 - 1s - 753us/step - accuracy: 0.9470 - loss: 0.2035\n",
      "Epoch 291/500\n",
      "1000/1000 - 1s - 768us/step - accuracy: 0.9340 - loss: 0.2064\n",
      "Epoch 292/500\n",
      "1000/1000 - 1s - 807us/step - accuracy: 0.9000 - loss: 0.4035\n",
      "Epoch 293/500\n",
      "1000/1000 - 1s - 801us/step - accuracy: 0.9490 - loss: 0.1948\n",
      "Epoch 294/500\n",
      "1000/1000 - 1s - 790us/step - accuracy: 0.9480 - loss: 0.1963\n",
      "Epoch 295/500\n",
      "1000/1000 - 1s - 782us/step - accuracy: 0.9450 - loss: 0.1973\n",
      "Epoch 296/500\n",
      "1000/1000 - 1s - 775us/step - accuracy: 0.9400 - loss: 0.2050\n",
      "Epoch 297/500\n",
      "1000/1000 - 1s - 809us/step - accuracy: 0.9410 - loss: 0.2019\n",
      "Epoch 298/500\n",
      "1000/1000 - 1s - 768us/step - accuracy: 0.9120 - loss: 0.3010\n",
      "Epoch 299/500\n",
      "1000/1000 - 1s - 753us/step - accuracy: 0.9340 - loss: 0.2303\n",
      "Epoch 300/500\n",
      "1000/1000 - 1s - 771us/step - accuracy: 0.9490 - loss: 0.1938\n",
      "Epoch 301/500\n",
      "1000/1000 - 1s - 786us/step - accuracy: 0.9460 - loss: 0.1924\n",
      "Epoch 302/500\n",
      "1000/1000 - 1s - 771us/step - accuracy: 0.9430 - loss: 0.1980\n",
      "Epoch 303/500\n",
      "1000/1000 - 1s - 772us/step - accuracy: 0.9440 - loss: 0.1988\n",
      "Epoch 304/500\n",
      "1000/1000 - 1s - 756us/step - accuracy: 0.9370 - loss: 0.2032\n",
      "Epoch 305/500\n",
      "1000/1000 - 1s - 765us/step - accuracy: 0.9350 - loss: 0.2938\n",
      "Epoch 306/500\n",
      "1000/1000 - 1s - 787us/step - accuracy: 0.9480 - loss: 0.1919\n",
      "Epoch 307/500\n",
      "1000/1000 - 1s - 759us/step - accuracy: 0.9480 - loss: 0.1908\n",
      "Epoch 308/500\n",
      "1000/1000 - 1s - 745us/step - accuracy: 0.9420 - loss: 0.1964\n",
      "Epoch 309/500\n",
      "1000/1000 - 1s - 768us/step - accuracy: 0.9410 - loss: 0.1971\n",
      "Epoch 310/500\n",
      "1000/1000 - 1s - 746us/step - accuracy: 0.8940 - loss: 0.4813\n",
      "Epoch 311/500\n",
      "1000/1000 - 1s - 756us/step - accuracy: 0.9550 - loss: 0.1874\n",
      "Epoch 312/500\n",
      "1000/1000 - 1s - 764us/step - accuracy: 0.9540 - loss: 0.1876\n",
      "Epoch 313/500\n",
      "1000/1000 - 1s - 754us/step - accuracy: 0.9430 - loss: 0.1914\n",
      "Epoch 314/500\n",
      "1000/1000 - 1s - 762us/step - accuracy: 0.9460 - loss: 0.1901\n",
      "Epoch 315/500\n",
      "1000/1000 - 1s - 788us/step - accuracy: 0.9440 - loss: 0.1894\n",
      "Epoch 316/500\n",
      "1000/1000 - 1s - 757us/step - accuracy: 0.9500 - loss: 0.1907\n",
      "Epoch 317/500\n",
      "1000/1000 - 1s - 775us/step - accuracy: 0.9440 - loss: 0.1936\n",
      "Epoch 318/500\n",
      "1000/1000 - 1s - 815us/step - accuracy: 0.9230 - loss: 0.2935\n",
      "Epoch 319/500\n",
      "1000/1000 - 1s - 800us/step - accuracy: 0.9540 - loss: 0.1850\n",
      "Epoch 320/500\n",
      "1000/1000 - 1s - 770us/step - accuracy: 0.9570 - loss: 0.1827\n",
      "Epoch 321/500\n",
      "1000/1000 - 1s - 774us/step - accuracy: 0.9540 - loss: 0.1863\n",
      "Epoch 322/500\n",
      "1000/1000 - 1s - 783us/step - accuracy: 0.9480 - loss: 0.1902\n",
      "Epoch 323/500\n",
      "1000/1000 - 1s - 807us/step - accuracy: 0.9430 - loss: 0.1948\n",
      "Epoch 324/500\n",
      "1000/1000 - 1s - 782us/step - accuracy: 0.9520 - loss: 0.2158\n",
      "Epoch 325/500\n",
      "1000/1000 - 1s - 753us/step - accuracy: 0.9450 - loss: 0.1848\n",
      "Epoch 326/500\n",
      "1000/1000 - 1s - 788us/step - accuracy: 0.9420 - loss: 0.1848\n",
      "Epoch 327/500\n",
      "1000/1000 - 1s - 798us/step - accuracy: 0.9520 - loss: 0.1886\n",
      "Epoch 328/500\n",
      "1000/1000 - 1s - 773us/step - accuracy: 0.9510 - loss: 0.1849\n",
      "Epoch 329/500\n",
      "1000/1000 - 1s - 768us/step - accuracy: 0.9470 - loss: 0.1875\n",
      "Epoch 330/500\n",
      "1000/1000 - 1s - 785us/step - accuracy: 0.9360 - loss: 0.2519\n",
      "Epoch 331/500\n",
      "1000/1000 - 1s - 803us/step - accuracy: 0.9530 - loss: 0.1812\n",
      "Epoch 332/500\n",
      "1000/1000 - 1s - 836us/step - accuracy: 0.9520 - loss: 0.1854\n",
      "Epoch 333/500\n",
      "1000/1000 - 1s - 770us/step - accuracy: 0.9460 - loss: 0.1843\n",
      "Epoch 334/500\n",
      "1000/1000 - 1s - 754us/step - accuracy: 0.9500 - loss: 0.1846\n",
      "Epoch 335/500\n",
      "1000/1000 - 1s - 840us/step - accuracy: 0.9500 - loss: 0.1835\n",
      "Epoch 336/500\n",
      "1000/1000 - 1s - 779us/step - accuracy: 0.9410 - loss: 0.2142\n",
      "Epoch 337/500\n",
      "1000/1000 - 1s - 752us/step - accuracy: 0.9550 - loss: 0.1749\n",
      "Epoch 338/500\n",
      "1000/1000 - 1s - 796us/step - accuracy: 0.9510 - loss: 0.1832\n",
      "Epoch 339/500\n",
      "1000/1000 - 1s - 797us/step - accuracy: 0.9480 - loss: 0.1845\n",
      "Epoch 340/500\n",
      "1000/1000 - 1s - 758us/step - accuracy: 0.9550 - loss: 0.1824\n",
      "Epoch 341/500\n",
      "1000/1000 - 1s - 766us/step - accuracy: 0.9320 - loss: 0.2808\n",
      "Epoch 342/500\n",
      "1000/1000 - 1s - 810us/step - accuracy: 0.9610 - loss: 0.1739\n",
      "Epoch 343/500\n",
      "1000/1000 - 1s - 805us/step - accuracy: 0.9530 - loss: 0.1791\n",
      "Epoch 344/500\n",
      "1000/1000 - 1s - 805us/step - accuracy: 0.9530 - loss: 0.1788\n",
      "Epoch 345/500\n",
      "1000/1000 - 1s - 781us/step - accuracy: 0.9500 - loss: 0.1804\n",
      "Epoch 346/500\n",
      "1000/1000 - 1s - 775us/step - accuracy: 0.9360 - loss: 0.2480\n",
      "Epoch 347/500\n",
      "1000/1000 - 1s - 807us/step - accuracy: 0.9510 - loss: 0.2103\n",
      "Epoch 348/500\n",
      "1000/1000 - 1s - 775us/step - accuracy: 0.9600 - loss: 0.1715\n",
      "Epoch 349/500\n",
      "1000/1000 - 1s - 771us/step - accuracy: 0.9580 - loss: 0.1760\n",
      "Epoch 350/500\n",
      "1000/1000 - 1s - 796us/step - accuracy: 0.9510 - loss: 0.1753\n",
      "Epoch 351/500\n",
      "1000/1000 - 1s - 822us/step - accuracy: 0.9520 - loss: 0.1731\n",
      "Epoch 352/500\n",
      "1000/1000 - 1s - 753us/step - accuracy: 0.9500 - loss: 0.1803\n",
      "Epoch 353/500\n",
      "1000/1000 - 1s - 790us/step - accuracy: 0.9600 - loss: 0.1734\n",
      "Epoch 354/500\n",
      "1000/1000 - 1s - 813us/step - accuracy: 0.9550 - loss: 0.1739\n",
      "Epoch 355/500\n",
      "1000/1000 - 1s - 781us/step - accuracy: 0.9200 - loss: 0.3767\n",
      "Epoch 356/500\n",
      "1000/1000 - 1s - 763us/step - accuracy: 0.9610 - loss: 0.1671\n",
      "Epoch 357/500\n",
      "1000/1000 - 1s - 803us/step - accuracy: 0.9600 - loss: 0.1662\n",
      "Epoch 358/500\n",
      "1000/1000 - 1s - 803us/step - accuracy: 0.9560 - loss: 0.1703\n",
      "Epoch 359/500\n",
      "1000/1000 - 1s - 776us/step - accuracy: 0.9520 - loss: 0.1711\n",
      "Epoch 360/500\n",
      "1000/1000 - 1s - 771us/step - accuracy: 0.9530 - loss: 0.1737\n",
      "Epoch 361/500\n",
      "1000/1000 - 1s - 794us/step - accuracy: 0.9500 - loss: 0.1741\n",
      "Epoch 362/500\n",
      "1000/1000 - 1s - 803us/step - accuracy: 0.9540 - loss: 0.1723\n",
      "Epoch 363/500\n",
      "1000/1000 - 1s - 760us/step - accuracy: 0.9480 - loss: 0.2235\n",
      "Epoch 364/500\n",
      "1000/1000 - 1s - 756us/step - accuracy: 0.9510 - loss: 0.2411\n",
      "Epoch 365/500\n",
      "1000/1000 - 1s - 805us/step - accuracy: 0.9650 - loss: 0.1667\n",
      "Epoch 366/500\n",
      "1000/1000 - 1s - 812us/step - accuracy: 0.9600 - loss: 0.1657\n",
      "Epoch 367/500\n",
      "1000/1000 - 1s - 764us/step - accuracy: 0.9560 - loss: 0.1682\n",
      "Epoch 368/500\n",
      "1000/1000 - 1s - 776us/step - accuracy: 0.9590 - loss: 0.1684\n",
      "Epoch 369/500\n",
      "1000/1000 - 1s - 831us/step - accuracy: 0.9590 - loss: 0.1648\n",
      "Epoch 370/500\n",
      "1000/1000 - 1s - 778us/step - accuracy: 0.9650 - loss: 0.1665\n",
      "Epoch 371/500\n",
      "1000/1000 - 1s - 809us/step - accuracy: 0.9320 - loss: 0.2953\n",
      "Epoch 372/500\n",
      "1000/1000 - 1s - 814us/step - accuracy: 0.9690 - loss: 0.1633\n",
      "Epoch 373/500\n",
      "1000/1000 - 1s - 788us/step - accuracy: 0.9640 - loss: 0.1607\n",
      "Epoch 374/500\n",
      "1000/1000 - 1s - 768us/step - accuracy: 0.9660 - loss: 0.1609\n",
      "Epoch 375/500\n",
      "1000/1000 - 1s - 785us/step - accuracy: 0.9610 - loss: 0.1652\n",
      "Epoch 376/500\n",
      "1000/1000 - 1s - 807us/step - accuracy: 0.9630 - loss: 0.1654\n",
      "Epoch 377/500\n",
      "1000/1000 - 1s - 764us/step - accuracy: 0.9620 - loss: 0.1618\n",
      "Epoch 378/500\n",
      "1000/1000 - 1s - 765us/step - accuracy: 0.9310 - loss: 0.2797\n",
      "Epoch 379/500\n",
      "1000/1000 - 1s - 777us/step - accuracy: 0.9590 - loss: 0.1699\n",
      "Epoch 380/500\n",
      "1000/1000 - 1s - 809us/step - accuracy: 0.9700 - loss: 0.1560\n",
      "Epoch 381/500\n",
      "1000/1000 - 1s - 810us/step - accuracy: 0.9630 - loss: 0.1566\n",
      "Epoch 382/500\n",
      "1000/1000 - 1s - 758us/step - accuracy: 0.9640 - loss: 0.1622\n",
      "Epoch 383/500\n",
      "1000/1000 - 1s - 785us/step - accuracy: 0.9600 - loss: 0.1630\n",
      "Epoch 384/500\n",
      "1000/1000 - 1s - 793us/step - accuracy: 0.9630 - loss: 0.1598\n",
      "Epoch 385/500\n",
      "1000/1000 - 1s - 780us/step - accuracy: 0.9640 - loss: 0.1565\n",
      "Epoch 386/500\n",
      "1000/1000 - 1s - 777us/step - accuracy: 0.9360 - loss: 0.2307\n",
      "Epoch 387/500\n",
      "1000/1000 - 1s - 837us/step - accuracy: 0.9670 - loss: 0.1545\n",
      "Epoch 388/500\n",
      "1000/1000 - 1s - 808us/step - accuracy: 0.9660 - loss: 0.1531\n",
      "Epoch 389/500\n",
      "1000/1000 - 1s - 769us/step - accuracy: 0.9680 - loss: 0.1544\n",
      "Epoch 390/500\n",
      "1000/1000 - 1s - 768us/step - accuracy: 0.9600 - loss: 0.1567\n",
      "Epoch 391/500\n",
      "1000/1000 - 1s - 800us/step - accuracy: 0.9650 - loss: 0.1596\n",
      "Epoch 392/500\n",
      "1000/1000 - 1s - 816us/step - accuracy: 0.9340 - loss: 0.3022\n",
      "Epoch 393/500\n",
      "1000/1000 - 1s - 769us/step - accuracy: 0.9690 - loss: 0.1518\n",
      "Epoch 394/500\n",
      "1000/1000 - 1s - 792us/step - accuracy: 0.9680 - loss: 0.1521\n",
      "Epoch 395/500\n",
      "1000/1000 - 1s - 822us/step - accuracy: 0.9600 - loss: 0.1575\n",
      "Epoch 396/500\n",
      "1000/1000 - 1s - 807us/step - accuracy: 0.9650 - loss: 0.1543\n",
      "Epoch 397/500\n",
      "1000/1000 - 1s - 766us/step - accuracy: 0.9670 - loss: 0.1569\n",
      "Epoch 398/500\n",
      "1000/1000 - 1s - 798us/step - accuracy: 0.9610 - loss: 0.1553\n",
      "Epoch 399/500\n",
      "1000/1000 - 1s - 809us/step - accuracy: 0.9340 - loss: 0.2689\n",
      "Epoch 400/500\n",
      "1000/1000 - 1s - 769us/step - accuracy: 0.9740 - loss: 0.1504\n",
      "Epoch 401/500\n",
      "1000/1000 - 1s - 766us/step - accuracy: 0.9640 - loss: 0.1510\n",
      "Epoch 402/500\n",
      "1000/1000 - 1s - 796us/step - accuracy: 0.9670 - loss: 0.1502\n",
      "Epoch 403/500\n",
      "1000/1000 - 1s - 788us/step - accuracy: 0.9640 - loss: 0.1525\n",
      "Epoch 404/500\n",
      "1000/1000 - 1s - 775us/step - accuracy: 0.9660 - loss: 0.1504\n",
      "Epoch 405/500\n",
      "1000/1000 - 1s - 772us/step - accuracy: 0.9620 - loss: 0.1508\n",
      "Epoch 406/500\n",
      "1000/1000 - 1s - 789us/step - accuracy: 0.9630 - loss: 0.1554\n",
      "Epoch 407/500\n",
      "1000/1000 - 1s - 830us/step - accuracy: 0.9660 - loss: 0.1505\n",
      "Epoch 408/500\n",
      "1000/1000 - 1s - 778us/step - accuracy: 0.9530 - loss: 0.1753\n",
      "Epoch 409/500\n",
      "1000/1000 - 1s - 780us/step - accuracy: 0.9620 - loss: 0.1478\n",
      "Epoch 410/500\n",
      "1000/1000 - 1s - 811us/step - accuracy: 0.9660 - loss: 0.1485\n",
      "Epoch 411/500\n",
      "1000/1000 - 1s - 828us/step - accuracy: 0.9600 - loss: 0.1492\n",
      "Epoch 412/500\n",
      "1000/1000 - 1s - 800us/step - accuracy: 0.9590 - loss: 0.1478\n",
      "Epoch 413/500\n",
      "1000/1000 - 1s - 776us/step - accuracy: 0.9570 - loss: 0.2057\n",
      "Epoch 414/500\n",
      "1000/1000 - 1s - 805us/step - accuracy: 0.9520 - loss: 0.1901\n",
      "Epoch 415/500\n",
      "1000/1000 - 1s - 783us/step - accuracy: 0.9750 - loss: 0.1425\n",
      "Epoch 416/500\n",
      "1000/1000 - 1s - 771us/step - accuracy: 0.9710 - loss: 0.1432\n",
      "Epoch 417/500\n",
      "1000/1000 - 1s - 778us/step - accuracy: 0.9730 - loss: 0.1435\n",
      "Epoch 418/500\n",
      "1000/1000 - 1s - 804us/step - accuracy: 0.9630 - loss: 0.1461\n",
      "Epoch 419/500\n",
      "1000/1000 - 1s - 832us/step - accuracy: 0.9640 - loss: 0.1463\n",
      "Epoch 420/500\n",
      "1000/1000 - 1s - 800us/step - accuracy: 0.9690 - loss: 0.1462\n",
      "Epoch 421/500\n",
      "1000/1000 - 1s - 833us/step - accuracy: 0.9640 - loss: 0.1456\n",
      "Epoch 422/500\n",
      "1000/1000 - 1s - 866us/step - accuracy: 0.9420 - loss: 0.2574\n",
      "Epoch 423/500\n",
      "1000/1000 - 1s - 840us/step - accuracy: 0.9650 - loss: 0.1463\n",
      "Epoch 424/500\n",
      "1000/1000 - 1s - 760us/step - accuracy: 0.9720 - loss: 0.1396\n",
      "Epoch 425/500\n",
      "1000/1000 - 1s - 788us/step - accuracy: 0.9650 - loss: 0.1444\n",
      "Epoch 426/500\n",
      "1000/1000 - 1s - 862us/step - accuracy: 0.9690 - loss: 0.1405\n",
      "Epoch 427/500\n",
      "1000/1000 - 1s - 825us/step - accuracy: 0.9660 - loss: 0.1450\n",
      "Epoch 428/500\n",
      "1000/1000 - 1s - 789us/step - accuracy: 0.9660 - loss: 0.1413\n",
      "Epoch 429/500\n",
      "1000/1000 - 1s - 827us/step - accuracy: 0.9610 - loss: 0.1408\n",
      "Epoch 430/500\n",
      "1000/1000 - 1s - 863us/step - accuracy: 0.9650 - loss: 0.1441\n",
      "Epoch 431/500\n",
      "1000/1000 - 1s - 797us/step - accuracy: 0.9670 - loss: 0.1385\n",
      "Epoch 432/500\n",
      "1000/1000 - 1s - 801us/step - accuracy: 0.9690 - loss: 0.1409\n",
      "Epoch 433/500\n",
      "1000/1000 - 1s - 857us/step - accuracy: 0.9550 - loss: 0.2420\n",
      "Epoch 434/500\n",
      "1000/1000 - 1s - 846us/step - accuracy: 0.9750 - loss: 0.1349\n",
      "Epoch 435/500\n",
      "1000/1000 - 1s - 806us/step - accuracy: 0.9690 - loss: 0.1360\n",
      "Epoch 436/500\n",
      "1000/1000 - 1s - 796us/step - accuracy: 0.9660 - loss: 0.1377\n",
      "Epoch 437/500\n",
      "1000/1000 - 1s - 815us/step - accuracy: 0.9720 - loss: 0.1368\n",
      "Epoch 438/500\n",
      "1000/1000 - 1s - 855us/step - accuracy: 0.9640 - loss: 0.1387\n",
      "Epoch 439/500\n",
      "1000/1000 - 1s - 796us/step - accuracy: 0.9750 - loss: 0.1392\n",
      "Epoch 440/500\n",
      "1000/1000 - 1s - 1ms/step - accuracy: 0.9450 - loss: 0.2178\n",
      "Epoch 441/500\n",
      "1000/1000 - 1s - 827us/step - accuracy: 0.9750 - loss: 0.1307\n",
      "Epoch 442/500\n",
      "1000/1000 - 1s - 822us/step - accuracy: 0.9700 - loss: 0.1317\n",
      "Epoch 443/500\n",
      "1000/1000 - 1s - 807us/step - accuracy: 0.9750 - loss: 0.1311\n",
      "Epoch 444/500\n",
      "1000/1000 - 1s - 812us/step - accuracy: 0.9680 - loss: 0.1347\n",
      "Epoch 445/500\n",
      "1000/1000 - 1s - 856us/step - accuracy: 0.9650 - loss: 0.1390\n",
      "Epoch 446/500\n",
      "1000/1000 - 1s - 819us/step - accuracy: 0.9710 - loss: 0.1350\n",
      "Epoch 447/500\n",
      "1000/1000 - 1s - 794us/step - accuracy: 0.9690 - loss: 0.1353\n",
      "Epoch 448/500\n",
      "1000/1000 - 1s - 824us/step - accuracy: 0.9550 - loss: 0.1806\n",
      "Epoch 449/500\n",
      "1000/1000 - 1s - 867us/step - accuracy: 0.9710 - loss: 0.1291\n",
      "Epoch 450/500\n",
      "1000/1000 - 1s - 822us/step - accuracy: 0.9720 - loss: 0.1323\n",
      "Epoch 451/500\n",
      "1000/1000 - 1s - 791us/step - accuracy: 0.9660 - loss: 0.1331\n",
      "Epoch 452/500\n",
      "1000/1000 - 1s - 801us/step - accuracy: 0.9680 - loss: 0.1341\n",
      "Epoch 453/500\n",
      "1000/1000 - 1s - 826us/step - accuracy: 0.9650 - loss: 0.1346\n",
      "Epoch 454/500\n",
      "1000/1000 - 1s - 821us/step - accuracy: 0.9720 - loss: 0.1321\n",
      "Epoch 455/500\n",
      "1000/1000 - 1s - 793us/step - accuracy: 0.9630 - loss: 0.1328\n",
      "Epoch 456/500\n",
      "1000/1000 - 1s - 837us/step - accuracy: 0.9630 - loss: 0.1304\n",
      "Epoch 457/500\n",
      "1000/1000 - 1s - 846us/step - accuracy: 0.9460 - loss: 0.2200\n",
      "Epoch 458/500\n",
      "1000/1000 - 1s - 795us/step - accuracy: 0.9800 - loss: 0.1231\n",
      "Epoch 459/500\n",
      "1000/1000 - 1s - 789us/step - accuracy: 0.9810 - loss: 0.1246\n",
      "Epoch 460/500\n",
      "1000/1000 - 1s - 819us/step - accuracy: 0.9790 - loss: 0.1264\n",
      "Epoch 461/500\n",
      "1000/1000 - 1s - 821us/step - accuracy: 0.9700 - loss: 0.1290\n",
      "Epoch 462/500\n",
      "1000/1000 - 1s - 794us/step - accuracy: 0.9740 - loss: 0.1283\n",
      "Epoch 463/500\n",
      "1000/1000 - 1s - 813us/step - accuracy: 0.9750 - loss: 0.1265\n",
      "Epoch 464/500\n",
      "1000/1000 - 1s - 820us/step - accuracy: 0.9530 - loss: 0.2412\n",
      "Epoch 465/500\n",
      "1000/1000 - 1s - 787us/step - accuracy: 0.9820 - loss: 0.1230\n",
      "Epoch 466/500\n",
      "1000/1000 - 1s - 773us/step - accuracy: 0.9760 - loss: 0.1242\n",
      "Epoch 467/500\n",
      "1000/1000 - 1s - 781us/step - accuracy: 0.9820 - loss: 0.1235\n",
      "Epoch 468/500\n",
      "1000/1000 - 1s - 838us/step - accuracy: 0.9780 - loss: 0.1246\n",
      "Epoch 469/500\n",
      "1000/1000 - 1s - 828us/step - accuracy: 0.9670 - loss: 0.1280\n",
      "Epoch 470/500\n",
      "1000/1000 - 1s - 805us/step - accuracy: 0.9750 - loss: 0.1248\n",
      "Epoch 471/500\n",
      "1000/1000 - 1s - 829us/step - accuracy: 0.9710 - loss: 0.1244\n",
      "Epoch 472/500\n",
      "1000/1000 - 1s - 820us/step - accuracy: 0.9520 - loss: 0.2129\n",
      "Epoch 473/500\n",
      "1000/1000 - 1s - 773us/step - accuracy: 0.9750 - loss: 0.1410\n",
      "Epoch 474/500\n",
      "1000/1000 - 1s - 779us/step - accuracy: 0.9770 - loss: 0.1207\n",
      "Epoch 475/500\n",
      "1000/1000 - 1s - 812us/step - accuracy: 0.9800 - loss: 0.1209\n",
      "Epoch 476/500\n",
      "1000/1000 - 1s - 811us/step - accuracy: 0.9680 - loss: 0.1220\n",
      "Epoch 477/500\n",
      "1000/1000 - 1s - 782us/step - accuracy: 0.9800 - loss: 0.1241\n",
      "Epoch 478/500\n",
      "1000/1000 - 1s - 781us/step - accuracy: 0.9730 - loss: 0.1245\n",
      "Epoch 479/500\n",
      "1000/1000 - 1s - 817us/step - accuracy: 0.9750 - loss: 0.1245\n",
      "Epoch 480/500\n",
      "1000/1000 - 1s - 828us/step - accuracy: 0.9710 - loss: 0.1240\n",
      "Epoch 481/500\n",
      "1000/1000 - 1s - 816us/step - accuracy: 0.9510 - loss: 0.2247\n",
      "Epoch 482/500\n",
      "1000/1000 - 1s - 780us/step - accuracy: 0.9840 - loss: 0.1152\n",
      "Epoch 483/500\n",
      "1000/1000 - 1s - 814us/step - accuracy: 0.9860 - loss: 0.1166\n",
      "Epoch 484/500\n",
      "1000/1000 - 1s - 815us/step - accuracy: 0.9780 - loss: 0.1207\n",
      "Epoch 485/500\n",
      "1000/1000 - 1s - 823us/step - accuracy: 0.9760 - loss: 0.1194\n",
      "Epoch 486/500\n",
      "1000/1000 - 1s - 780us/step - accuracy: 0.9720 - loss: 0.1219\n",
      "Epoch 487/500\n",
      "1000/1000 - 1s - 780us/step - accuracy: 0.9730 - loss: 0.1210\n",
      "Epoch 488/500\n",
      "1000/1000 - 1s - 841us/step - accuracy: 0.9740 - loss: 0.1246\n",
      "Epoch 489/500\n",
      "1000/1000 - 1s - 784us/step - accuracy: 0.9750 - loss: 0.1206\n",
      "Epoch 490/500\n",
      "1000/1000 - 1s - 770us/step - accuracy: 0.9760 - loss: 0.1215\n",
      "Epoch 491/500\n",
      "1000/1000 - 1s - 767us/step - accuracy: 0.9550 - loss: 0.2000\n",
      "Epoch 492/500\n",
      "1000/1000 - 1s - 820us/step - accuracy: 0.9770 - loss: 0.1130\n",
      "Epoch 493/500\n",
      "1000/1000 - 1s - 791us/step - accuracy: 0.9760 - loss: 0.1173\n",
      "Epoch 494/500\n",
      "1000/1000 - 1s - 809us/step - accuracy: 0.9870 - loss: 0.1173\n",
      "Epoch 495/500\n",
      "1000/1000 - 1s - 786us/step - accuracy: 0.9760 - loss: 0.1171\n",
      "Epoch 496/500\n",
      "1000/1000 - 1s - 796us/step - accuracy: 0.9760 - loss: 0.1160\n",
      "Epoch 497/500\n",
      "1000/1000 - 1s - 767us/step - accuracy: 0.9720 - loss: 0.1191\n",
      "Epoch 498/500\n",
      "1000/1000 - 1s - 777us/step - accuracy: 0.9830 - loss: 0.1173\n",
      "Epoch 499/500\n",
      "1000/1000 - 1s - 790us/step - accuracy: 0.9760 - loss: 0.1168\n",
      "Epoch 500/500\n",
      "1000/1000 - 1s - 770us/step - accuracy: 0.9710 - loss: 0.1175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x296d281e270>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X, y, epochs=500, batch_size=batch_size, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP5. 評估模型準確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 98.60%\n"
     ]
    }
   ],
   "source": [
    "# 評估模型的性能\n",
    "scores = model.evaluate(X, y, verbose=0)\n",
    "print(\"Model Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP6. 預測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J'] -> K\n",
      "['H', 'I', 'J'] -> K\n",
      "['E', 'F'] -> G\n",
      "['K', 'L', 'M'] -> N\n",
      "['B'] -> C\n",
      "['C'] -> D\n",
      "['R', 'S'] -> T\n",
      "['A', 'B', 'C'] -> D\n",
      "['C', 'D', 'E'] -> F\n",
      "['N', 'O', 'P'] -> Q\n",
      "['C', 'D'] -> E\n",
      "['L', 'M'] -> N\n",
      "['F', 'G', 'H', 'I', 'J'] -> K\n",
      "['N', 'O', 'P', 'Q'] -> R\n",
      "['C', 'D', 'E', 'F', 'G'] -> H\n",
      "['A', 'B', 'C'] -> D\n",
      "['R', 'S', 'T', 'U', 'V'] -> W\n",
      "['B', 'C', 'D'] -> E\n",
      "['F', 'G'] -> H\n",
      "['K'] -> L\n"
     ]
    }
   ],
   "source": [
    "# 讓我們擷取1~5個字符轉成張量結構 shape:(1,5,1)來進行infer\n",
    "for i in range(20):\n",
    "    pattern_index = numpy.random.randint(len(dataX))\n",
    "    pattern = dataX[pattern_index]\n",
    "    x = pad_sequences([pattern], maxlen=max_len, dtype=\"float32\")\n",
    "    x = numpy.reshape(x, (1, max_len, 1))\n",
    "    x = x / float(len(alphabet))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    print(seq_in, \"->\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = numpy.array([[['L', 'M']]])#要改成數字\n",
    "# print(model.predict(a, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "我們可以看到，雖然這個網絡模型沒有從生成的序列資料中完全學習到英文字母表的順序，但它表現相當的好。如果需要, 我們可以對這個模型進行進一歩的優化與調整，比如更多的訓練循環(more epochs)或更大的網絡(larger network)，或兩者。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 參考:\n",
    "* Jason Brownlee - \"[Understanding Stateful LSTM Recurrent Neural Networks in Python with Keras](https://machinelearningmastery.com/understanding-stateful-lstm-recurrent-neural-networks-python-keras/)\"\n",
    "\n",
    "* Keras官網 - [Recurrent Layer](https://keras.io/layers/recurrent/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
